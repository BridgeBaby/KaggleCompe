{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', 150)\n",
    "import os\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numba import jit\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'specs.csv', 'train.csv', 'train_labels.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "for _, _, files in os.walk('../input/data-science-bowl-2019'):\n",
    "    print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv():\n",
    "    BASE_PATH = '../input/data-science-bowl-2019/'\n",
    "    #train\n",
    "    print('Reading train.csv as DataFrame...')\n",
    "    train = pd.read_csv(BASE_PATH + 'train.csv')\n",
    "    print('Completed, train have {} columns, {} rows.'.format(train.shape[0], train.shape[1]))\n",
    "    #train_lebels\n",
    "    print('Reading train_labels.csv as DataFrame...')\n",
    "    train_labels = pd.read_csv(BASE_PATH + 'train_labels.csv')\n",
    "    print('Completed, train_labels have {} columns, {} rows.'.format(train_labels.shape[0], train_labels.shape[1]))\n",
    "    #test\n",
    "    print('Reading test.csv as DataFrame...')\n",
    "    test = pd.read_csv(BASE_PATH + 'test.csv')\n",
    "    print('Completed, test have {} columns, {} rows.'.format(test.shape[0], test.shape[1]))\n",
    "    #specs\n",
    "    print('Reading specs.csv as DataFrame...')\n",
    "    specs = pd.read_csv(BASE_PATH + 'specs.csv')\n",
    "    print('Completed, specs have {} columns, {} rows.'.format(specs.shape[0], specs.shape[1]))\n",
    "    #sample_submission\n",
    "    print('Reading sample_submission.csv as DataFrame...')\n",
    "    sample_submission = pd.read_csv(BASE_PATH + 'sample_submission.csv')\n",
    "    print('Completed, sample_submission have {} columns, {} rows.'.format(sample_submission.shape[0], sample_submission.shape[1]))\n",
    "    \n",
    "    return train, train_labels, test, specs, sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_encoder(train, test):\n",
    "    print('Encoding feature...')\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    train['world_type'] = list(map(lambda x, y: str(x) + '_' + str(y), train['world'], train['type']))\n",
    "    test['world_type'] = list(map(lambda x, y: str(x) + '_' + str(y), test['world'], test['type']))\n",
    "    \n",
    "    def encoder(feature):\n",
    "        list_ = list(set(train[feature].unique()).union(set(test[feature].unique())))\n",
    "        map_ = dict(zip(list_, np.arange(len(list_))))\n",
    "        labels = dict(zip(np.arange(len(list_)), list_))\n",
    "        return list_, map_, labels\n",
    "    \n",
    "    title_list, title_map, title_labels = encoder('title')\n",
    "    world_list, world_map, world_labels = encoder('world')\n",
    "    eventId_list, _, _ = encoder('event_id')\n",
    "    eventCode_list, _, _ = encoder('event_code')\n",
    "    title_eventCode_list, _, _ = encoder('title_event_code')\n",
    "    world_type_list, _, _ = encoder('world_type')\n",
    "    asses_title_list = list(set(train[train.type == 'Assessment']['title'].unique()).union(set(test[test.type == 'Assessment']['title'].unique())))\n",
    "    attempt_code = dict(zip(asses_title_list, (np.ones(len(asses_title_list)) * 4100).astype(int)))\n",
    "    attempt_code['Bird Measurer (Assessment)'] = 4110\n",
    "\n",
    "    train['title'] = train['title'].map(title_map)\n",
    "    test['title'] = test['title'].map(title_map)\n",
    "    train['world'] = train['world'].map(world_map)\n",
    "    test['world'] = test['world'].map(world_map)\n",
    "    print('Encoding completed.')\n",
    "    return train, test, title_list, title_map, title_labels, world_list, world_map, world_labels, eventId_list, eventCode_list, title_eventCode_list, world_type_list, asses_title_list, attempt_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(df, test_set=False):\n",
    "    #count\n",
    "    type_count = {'Clip': 0, 'Activity': 0, 'Assessment': 0, 'Game': 0}\n",
    "    asses_count = {'acc_all': 0, 'acc_true': 0, 'acc_false': 0}\n",
    "    group_count = {n: 0 for n in np.arange(4)}\n",
    "    title_count = {ti: 0 for ti in title_list}\n",
    "    world_count = {wo: 0 for wo in world_list}\n",
    "    assesTrue_title_count = {at: 0 for at in asses_title_list}\n",
    "    assesFalse_title_count = {af: 0 for af in asses_title_list}\n",
    "    eventId_count = {ei: 0 for ei in eventId_list}\n",
    "    eventCode_count = {ec: 0 for ec in eventCode_list}\n",
    "    title_eventCode_count = {te: 0 for te in title_eventCode_list}\n",
    "    world_type_count = {wt: 0 for wt in world_type_list}\n",
    "    #time count\n",
    "    title_time = {str(ti)+'_t': 0 for ti in title_list}\n",
    "    world_time = {str(wo)+'_t': 0 for wo in world_list}\n",
    "    \n",
    "    features = []\n",
    "    mean_time = []\n",
    "    acc_time = 0\n",
    "    \n",
    "    for i, sess in df.groupby('game_session', sort=False):\n",
    "        title = sess.title.iloc[0]\n",
    "        world = sess.world.iloc[0]\n",
    "        sess_type = sess.type.iloc[0]\n",
    "        time = int(sess.game_time.iloc[-1] / 1000)\n",
    "        \n",
    "        if sess_type != 'Assessment':\n",
    "            acc_time += time\n",
    "        \n",
    "        if (sess_type == 'Assessment') & (test_set or len(sess) > 1):\n",
    "            \n",
    "            feature = type_count.copy()\n",
    "            feature['installation_id'] = sess.installation_id.iloc[0]\n",
    "            feature['title'] = title\n",
    "            feature['true_record'] = assesTrue_title_count[title_labels[title]]\n",
    "            feature['false_record'] = assesFalse_title_count[title_labels[title]]\n",
    "            feature['acc_play_time'] = acc_time\n",
    "            \n",
    "            #time\n",
    "            if mean_time == []:\n",
    "                feature['asses_time_mean'] = 0\n",
    "                feature['asses_time_std'] = 0\n",
    "            else:\n",
    "                feature['asses_time_mean'] = np.mean(mean_time)\n",
    "                feature['asses_time_std'] = np.std(mean_time)\n",
    "            mean_time.append((sess.game_time.iloc[-1] - sess.game_time.iloc[0])/1000)\n",
    "                \n",
    "            #accuracy\n",
    "            attempt_all = sess[sess.event_code == attempt_code[title_labels[title]]]['event_data'].shape[0]\n",
    "            attempt_true = sess[sess.event_code == attempt_code[title_labels[title]]]['event_data'].str.contains('true').sum()\n",
    "            attempt_false = sess[sess.event_code == attempt_code[title_labels[title]]]['event_data'].str.contains('false').sum()\n",
    "            accuracy_rate = attempt_true / attempt_all if attempt_all != 0 else 0\n",
    "            if accuracy_rate == 0:\n",
    "                feature['accuracy_group'] = 0\n",
    "            elif accuracy_rate == 1:\n",
    "                feature['accuracy_group'] = 3\n",
    "            elif accuracy_rate == 0.5:\n",
    "                feature['accuracy_group'] = 2\n",
    "            else:\n",
    "                feature['accuracy_group'] = 1\n",
    "            feature['acc_accuracy'] = asses_count['acc_true'] / asses_count['acc_all'] if asses_count['acc_all'] != 0 else 0\n",
    "            feature.update(group_count)\n",
    "            group_count[feature['accuracy_group']] += 1\n",
    "            feature.update(asses_count)\n",
    "            asses_count['acc_all'] += attempt_all \n",
    "            asses_count['acc_true'] += attempt_true\n",
    "            asses_count['acc_false'] += attempt_false\n",
    "            assesTrue_title_count[title_labels[title]] += attempt_true\n",
    "            assesFalse_title_count[title_labels[title]] += attempt_false\n",
    "            \n",
    "            #Update count\n",
    "            feature.update(title_count)\n",
    "            feature.update(world_count)\n",
    "            feature.update(eventId_count)\n",
    "            feature.update(eventCode_count)\n",
    "            feature.update(title_eventCode_count)\n",
    "            feature.update(world_type_count)\n",
    "            \n",
    "            variety_features = [('var_event_code', eventCode_count),\n",
    "                                ('var_event_id', eventId_count),\n",
    "                                ('var_title', title_count),\n",
    "                                ('var_title_event_code', title_eventCode_count)]\n",
    "            \n",
    "            for name, dict_counts in variety_features:\n",
    "                arr = np.array(list(dict_counts.values()))\n",
    "                feature[name] = np.count_nonzero(arr)\n",
    "            \n",
    "            #Update acctime\n",
    "            feature.update(title_time)\n",
    "            feature.update(world_time)\n",
    "            \n",
    "            if test_set:\n",
    "                features = feature\n",
    "            elif attempt_all != 0:\n",
    "                features.append(feature)\n",
    "                \n",
    "        #count\n",
    "        type_count[sess_type] += 1\n",
    "        title_count[title_labels[title]] += 1\n",
    "        world_count[world_labels[world]] += 1\n",
    "            \n",
    "        def count_updater(dic ,col):\n",
    "            num_of_counter = Counter(sess[col])\n",
    "            for i in num_of_counter.keys():\n",
    "                dic[i] += num_of_counter[i]\n",
    "                \n",
    "        count_updater(eventId_count, 'event_id')\n",
    "        count_updater(eventCode_count, 'event_code')\n",
    "        count_updater(title_eventCode_count, 'title_event_code')\n",
    "        count_updater(world_type_count, 'world_type')\n",
    "        \n",
    "        #acctime\n",
    "        title_time[str(title_labels[title]) + '_t'] += time\n",
    "        world_time[str(world_labels[world]) + '_t'] += time\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(train, test):\n",
    "    all_train = []\n",
    "    all_test = []\n",
    "    print('Getting train_encoder data...')\n",
    "    for ins_id, data in tqdm(train.groupby('installation_id', sort=False), total=train.installation_id.nunique(), desc='installation_id'):\n",
    "        all_train += read_data(data)\n",
    "    print('Completed of train_en.')\n",
    "    print('Getting test_encoder data...')\n",
    "    for ins_id, data in tqdm(test.groupby('installation_id', sort=False), total=test.installation_id.nunique(), desc='installation_id'):\n",
    "        tt = read_data(data, test_set=True)\n",
    "        all_test.append(tt)\n",
    "    print('Completed of test_en.')\n",
    "    train_en = pd.DataFrame(all_train)\n",
    "    test_en = pd.DataFrame(all_test)\n",
    "    \n",
    "    train_ohe = pd.get_dummies(train_en['title'], prefix='title')\n",
    "    test_ohe = pd.get_dummies(test_en['title'], prefix='title')\n",
    "    train_en = pd.concat([train_en, train_ohe], axis=1)\n",
    "    test_en = pd.concat([test_en, test_ohe], axis=1)\n",
    "    return train_en, test_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train_en, test_en):\n",
    "    for df in [train_en, test_en]:\n",
    "        df['installation_session_count'] = df.groupby('installation_id')['Clip'].transform('count')\n",
    "        df['installation_duration_time'] = df.groupby('installation_id')['asses_time_mean'].transform('mean')\n",
    "        df['installation_title_nunique'] = df.groupby('installation_id')['title'].transform('nunique')\n",
    "    train_feat = train_en.loc[(train_en.sum(axis=1) != 0), (train_en.sum(axis=0) != 0)].columns\n",
    "    test_feat = test_en.loc[(test_en.sum(axis=1) != 0), (test_en.sum(axis=0) != 0)].columns\n",
    "    features = [col for col in train_en.columns if col in train_feat or col in test_feat]\n",
    "    return train_en[features], test_en[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train.csv as DataFrame...\n",
      "Completed, train have 11341042 columns, 11 rows.\n",
      "Reading train_labels.csv as DataFrame...\n",
      "Completed, train_labels have 17690 columns, 7 rows.\n",
      "Reading test.csv as DataFrame...\n",
      "Completed, test have 1156414 columns, 11 rows.\n",
      "Reading specs.csv as DataFrame...\n",
      "Completed, specs have 386 columns, 3 rows.\n",
      "Reading sample_submission.csv as DataFrame...\n",
      "Completed, sample_submission have 1000 columns, 2 rows.\n"
     ]
    }
   ],
   "source": [
    "train, train_labels, test, specs, sample_submission = read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove installation_id which never made assessment\n",
      "reduce train to: 8294138 columns\n"
     ]
    }
   ],
   "source": [
    "keep_id = train[train.type == \"Assessment\"][['installation_id']].drop_duplicates()\n",
    "train = pd.merge(train, keep_id, on=\"installation_id\", how=\"inner\")\n",
    "print(f'remove installation_id which never made assessment')\n",
    "print(f'reduce train to: {train.shape[0]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding feature...\n",
      "Encoding completed.\n",
      "Getting train_encoder data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d6346b20dc4b8d84184f22bb73f950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='installation_id', max=4242, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed of train_en.\n",
      "Getting test_encoder data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a807ca98cf0442785e077ca3cf607bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='installation_id', max=1000, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed of test_en.\n"
     ]
    }
   ],
   "source": [
    "train_s, test_s, title_list, title_map, title_labels, world_list, world_map, world_labels, eventId_list, eventCode_list, title_eventCode_list, world_type_list, asses_title_list, attempt_code = feature_encoder(train, test)\n",
    "train_en, test_en = get_train_test(train_s, test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en, test_en = preprocess(train_en, test_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_en.loc[(train_en.sum(axis=1) != 0), (train_en.sum(axis=0) != 0)].columns\n",
    "features = [col for col in features if col not in ['accuracy_group', 'installation_id']]\n",
    "categoricals = ['session_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: FEAT_1: Clip FEAT_2: 27253bdc - Correlation: 0.9999999999999999\n",
      "2: FEAT_1: Costume Box FEAT_2: Costume Box_2000 - Correlation: 1.0\n",
      "3: FEAT_1: Happy Camel FEAT_2: d9c005dd - Correlation: 1.0\n",
      "4: FEAT_1: Happy Camel FEAT_2: Happy Camel_2000 - Correlation: 1.0\n",
      "5: FEAT_1: Crystal Caves - Level 1 FEAT_2: Crystal Caves - Level 1_2000 - Correlation: 1.0\n",
      "6: FEAT_1: Lifting Heavy Things FEAT_2: Lifting Heavy Things_2000 - Correlation: 0.9999999999999999\n",
      "7: FEAT_1: Slop Problem FEAT_2: Slop Problem_2000 - Correlation: 1.0\n",
      "8: FEAT_1: Air Show FEAT_2: 15ba1109 - Correlation: 1.0\n",
      "9: FEAT_1: Air Show FEAT_2: Air Show_2000 - Correlation: 1.0\n",
      "10: FEAT_1: Crystal Caves - Level 3 FEAT_2: Crystal Caves - Level 3_2000 - Correlation: 1.0\n",
      "11: FEAT_1: Heavy, Heavier, Heaviest FEAT_2: Heavy, Heavier, Heaviest_2000 - Correlation: 1.0\n",
      "12: FEAT_1: Bug Measurer (Activity) FEAT_2: c7f7f0e1 - Correlation: 1.0\n",
      "13: FEAT_1: Bug Measurer (Activity) FEAT_2: Bug Measurer (Activity)_2000 - Correlation: 1.0\n",
      "14: FEAT_1: Watering Hole (Activity) FEAT_2: e64e2cfd - Correlation: 0.9999999999999998\n",
      "15: FEAT_1: Watering Hole (Activity) FEAT_2: Watering Hole (Activity)_2000 - Correlation: 0.9999999999999998\n",
      "16: FEAT_1: Fireworks (Activity) FEAT_2: 4901243f - Correlation: 1.0\n",
      "17: FEAT_1: Fireworks (Activity) FEAT_2: Fireworks (Activity)_2000 - Correlation: 1.0\n",
      "18: FEAT_1: Bubble Bath FEAT_2: 1cf54632 - Correlation: 0.9999999999999999\n",
      "19: FEAT_1: Bubble Bath FEAT_2: Bubble Bath_2000 - Correlation: 0.9999999999999999\n",
      "20: FEAT_1: Tree Top City - Level 1 FEAT_2: Tree Top City - Level 1_2000 - Correlation: 0.9999999999999999\n",
      "21: FEAT_1: Magma Peak - Level 2 FEAT_2: Magma Peak - Level 2_2000 - Correlation: 1.0\n",
      "22: FEAT_1: Chow Time FEAT_2: 7d093bf9 - Correlation: 0.9999999999999999\n",
      "23: FEAT_1: Chow Time FEAT_2: Chow Time_2000 - Correlation: 0.9999999999999999\n",
      "24: FEAT_1: Chest Sorter (Assessment) FEAT_2: 5b49460a - Correlation: 0.9999999999999999\n",
      "25: FEAT_1: Chest Sorter (Assessment) FEAT_2: 155f62a4 - Correlation: 0.9999999999999999\n",
      "26: FEAT_1: Chest Sorter (Assessment) FEAT_2: Chest Sorter (Assessment)_2000 - Correlation: 0.9999999999999999\n",
      "27: FEAT_1: Chest Sorter (Assessment) FEAT_2: Chest Sorter (Assessment)_2020 - Correlation: 0.9999999999999999\n",
      "28: FEAT_1: Tree Top City - Level 3 FEAT_2: Tree Top City - Level 3_2000 - Correlation: 1.0\n",
      "29: FEAT_1: Pirate's Tale FEAT_2: Pirate's Tale_2000 - Correlation: 0.9999999999999999\n",
      "30: FEAT_1: Welcome to Lost Lagoon! FEAT_2: NONE - Correlation: 1.0\n",
      "31: FEAT_1: Welcome to Lost Lagoon! FEAT_2: Welcome to Lost Lagoon!_2000 - Correlation: 1.0\n",
      "32: FEAT_1: Welcome to Lost Lagoon! FEAT_2: NONE_Clip - Correlation: 1.0\n",
      "33: FEAT_1: Cart Balancer (Assessment) FEAT_2: 7ad3efc6 - Correlation: 1.0\n",
      "34: FEAT_1: Cart Balancer (Assessment) FEAT_2: 65a38bf7 - Correlation: 0.999978626569043\n",
      "35: FEAT_1: Cart Balancer (Assessment) FEAT_2: Cart Balancer (Assessment)_2020 - Correlation: 0.999978626569043\n",
      "36: FEAT_1: Cart Balancer (Assessment) FEAT_2: Cart Balancer (Assessment)_2000 - Correlation: 1.0\n",
      "37: FEAT_1: Magma Peak - Level 1 FEAT_2: Magma Peak - Level 1_2000 - Correlation: 1.0\n",
      "38: FEAT_1: Treasure Map FEAT_2: Treasure Map_2000 - Correlation: 1.0\n",
      "39: FEAT_1: Crystals Rule FEAT_2: 48349b14 - Correlation: 1.0\n",
      "40: FEAT_1: Crystals Rule FEAT_2: Crystals Rule_2000 - Correlation: 1.0\n",
      "41: FEAT_1: Bird Measurer (Assessment) FEAT_2: f56e0afc - Correlation: 1.0\n",
      "42: FEAT_1: Bird Measurer (Assessment) FEAT_2: Bird Measurer (Assessment)_2000 - Correlation: 1.0\n",
      "43: FEAT_1: Dino Drink FEAT_2: 51311d7a - Correlation: 1.0\n",
      "44: FEAT_1: Dino Drink FEAT_2: Dino Drink_2000 - Correlation: 1.0\n",
      "45: FEAT_1: Dino Dive FEAT_2: 29bdd9ba - Correlation: 1.0\n",
      "46: FEAT_1: Dino Dive FEAT_2: Dino Dive_2000 - Correlation: 1.0\n",
      "47: FEAT_1: Flower Waterer (Activity) FEAT_2: 9b01374f - Correlation: 1.0\n",
      "48: FEAT_1: Flower Waterer (Activity) FEAT_2: Flower Waterer (Activity)_2000 - Correlation: 1.0\n",
      "49: FEAT_1: Bottle Filler (Activity) FEAT_2: d2278a3b - Correlation: 1.0\n",
      "50: FEAT_1: Bottle Filler (Activity) FEAT_2: Bottle Filler (Activity)_2000 - Correlation: 1.0\n",
      "51: FEAT_1: Mushroom Sorter (Assessment) FEAT_2: 3bfd1a65 - Correlation: 1.0\n",
      "52: FEAT_1: Mushroom Sorter (Assessment) FEAT_2: db02c830 - Correlation: 0.9999982205265872\n",
      "53: FEAT_1: Mushroom Sorter (Assessment) FEAT_2: Mushroom Sorter (Assessment)_2000 - Correlation: 1.0\n",
      "54: FEAT_1: Mushroom Sorter (Assessment) FEAT_2: Mushroom Sorter (Assessment)_2025 - Correlation: 0.9999982205265872\n",
      "55: FEAT_1: Sandcastle Builder (Activity) FEAT_2: 77261ab5 - Correlation: 0.9999999999999999\n",
      "56: FEAT_1: Sandcastle Builder (Activity) FEAT_2: Sandcastle Builder (Activity)_2000 - Correlation: 0.9999999999999999\n",
      "57: FEAT_1: Tree Top City - Level 2 FEAT_2: Tree Top City - Level 2_2000 - Correlation: 1.0\n",
      "58: FEAT_1: All Star Sorting FEAT_2: 4b5efe37 - Correlation: 0.9980151285383981\n",
      "59: FEAT_1: All Star Sorting FEAT_2: b7dc8128 - Correlation: 1.0\n",
      "60: FEAT_1: All Star Sorting FEAT_2: All Star Sorting_4010 - Correlation: 0.9980151285383981\n",
      "61: FEAT_1: All Star Sorting FEAT_2: All Star Sorting_2000 - Correlation: 1.0\n",
      "62: FEAT_1: Honey Cake FEAT_2: Honey Cake_2000 - Correlation: 1.0\n",
      "63: FEAT_1: Egg Dropper (Activity) FEAT_2: 9b23e8ee - Correlation: 0.9999999999999999\n",
      "64: FEAT_1: Egg Dropper (Activity) FEAT_2: 736f9581 - Correlation: 0.9999999999999999\n",
      "65: FEAT_1: Egg Dropper (Activity) FEAT_2: Egg Dropper (Activity)_2020 - Correlation: 0.9999999999999999\n",
      "66: FEAT_1: Egg Dropper (Activity) FEAT_2: Egg Dropper (Activity)_2000 - Correlation: 0.9999999999999999\n",
      "67: FEAT_1: Balancing Act FEAT_2: Balancing Act_2000 - Correlation: 1.0\n",
      "68: FEAT_1: Leaf Leader FEAT_2: 8ac7cce4 - Correlation: 1.0\n",
      "69: FEAT_1: Leaf Leader FEAT_2: Leaf Leader_2000 - Correlation: 1.0\n",
      "70: FEAT_1: Pan Balance FEAT_2: 9c5ef70c - Correlation: 1.0\n",
      "71: FEAT_1: Pan Balance FEAT_2: Pan Balance_2000 - Correlation: 1.0\n",
      "72: FEAT_1: Ordering Spheres FEAT_2: Ordering Spheres_2000 - Correlation: 1.0\n",
      "73: FEAT_1: Cauldron Filler (Assessment) FEAT_2: 90d848e0 - Correlation: 1.0\n",
      "74: FEAT_1: Cauldron Filler (Assessment) FEAT_2: Cauldron Filler (Assessment)_2000 - Correlation: 1.0\n",
      "75: FEAT_1: Scrub-A-Dub FEAT_2: 6d90d394 - Correlation: 0.9999999999999999\n",
      "76: FEAT_1: Scrub-A-Dub FEAT_2: Scrub-A-Dub_2000 - Correlation: 0.9999999999999999\n",
      "77: FEAT_1: Chicken Balancer (Activity) FEAT_2: 756e5507 - Correlation: 1.0\n",
      "78: FEAT_1: Chicken Balancer (Activity) FEAT_2: Chicken Balancer (Activity)_2000 - Correlation: 1.0\n",
      "79: FEAT_1: Rulers FEAT_2: Rulers_2000 - Correlation: 1.0\n",
      "80: FEAT_1: 12 Monkeys FEAT_2: 12 Monkeys_2000 - Correlation: 1.0\n",
      "81: FEAT_1: Crystal Caves - Level 2 FEAT_2: Crystal Caves - Level 2_2000 - Correlation: 1.0\n",
      "82: FEAT_1: d2e9262e FEAT_2: 2fb91ec1 - Correlation: 0.9991434495208743\n",
      "83: FEAT_1: d2e9262e FEAT_2: Watering Hole (Activity)_4020 - Correlation: 0.9999999999999998\n",
      "84: FEAT_1: d2e9262e FEAT_2: Watering Hole (Activity)_4025 - Correlation: 0.9991434495208743\n",
      "85: FEAT_1: bb3e370b FEAT_2: Bottle Filler (Activity)_4030 - Correlation: 0.9999999999999999\n",
      "86: FEAT_1: a8876db3 FEAT_2: Cart Balancer (Assessment)_3021 - Correlation: 1.0\n",
      "87: FEAT_1: 88d4a5be FEAT_2: 160654fd - Correlation: 0.998929717261588\n",
      "88: FEAT_1: 88d4a5be FEAT_2: Mushroom Sorter (Assessment)_3120 - Correlation: 1.0\n",
      "89: FEAT_1: 88d4a5be FEAT_2: Mushroom Sorter (Assessment)_3020 - Correlation: 0.998929717261588\n",
      "90: FEAT_1: 4ef8cdd3 FEAT_2: Chow Time_4020 - Correlation: 1.0\n",
      "91: FEAT_1: 63f13dd7 FEAT_2: Chow Time_2020 - Correlation: 1.0\n",
      "92: FEAT_1: 14de4c5d FEAT_2: Air Show_4100 - Correlation: 1.0\n",
      "93: FEAT_1: 611485c5 FEAT_2: Fireworks (Activity)_4080 - Correlation: 1.0\n",
      "94: FEAT_1: 17113b36 FEAT_2: ad2fc29c - Correlation: 0.9988424704659317\n",
      "95: FEAT_1: 17113b36 FEAT_2: e37a2b78 - Correlation: 0.9982548122198927\n",
      "96: FEAT_1: 17113b36 FEAT_2: Bird Measurer (Assessment)_3120 - Correlation: 0.9982548122198927\n",
      "97: FEAT_1: 17113b36 FEAT_2: Bird Measurer (Assessment)_4110 - Correlation: 0.9999999999999998\n",
      "98: FEAT_1: 17113b36 FEAT_2: Bird Measurer (Assessment)_3020 - Correlation: 0.9988424704659317\n",
      "99: FEAT_1: c952eb01 FEAT_2: Watering Hole (Activity)_4070 - Correlation: 1.0\n",
      "100: FEAT_1: 58a0de5c FEAT_2: f5b8c21a - Correlation: 0.9977888184537715\n",
      "101: FEAT_1: 58a0de5c FEAT_2: 9b4001e4 - Correlation: 0.9999159362216189\n",
      "102: FEAT_1: 58a0de5c FEAT_2: Air Show_3021 - Correlation: 0.9999159362216189\n",
      "103: FEAT_1: 58a0de5c FEAT_2: Air Show_3121 - Correlation: 1.0\n",
      "104: FEAT_1: 58a0de5c FEAT_2: Air Show_2030 - Correlation: 0.9977888184537715\n",
      "105: FEAT_1: 33505eae FEAT_2: 2a512369 - Correlation: 0.9994585292841953\n",
      "106: FEAT_1: 33505eae FEAT_2: Leaf Leader_3010 - Correlation: 0.9999999999999998\n",
      "107: FEAT_1: 33505eae FEAT_2: Leaf Leader_3110 - Correlation: 0.9994585292841953\n",
      "108: FEAT_1: b120f2ac FEAT_2: c277e121 - Correlation: 0.9999983835744553\n",
      "109: FEAT_1: b120f2ac FEAT_2: d45ed6a1 - Correlation: 0.9979707847816691\n",
      "110: FEAT_1: b120f2ac FEAT_2: All Star Sorting_2025 - Correlation: 1.0\n",
      "111: FEAT_1: b120f2ac FEAT_2: All Star Sorting_3020 - Correlation: 0.9999983835744553\n",
      "112: FEAT_1: b120f2ac FEAT_2: All Star Sorting_3120 - Correlation: 0.9979707847816691\n",
      "113: FEAT_1: 1af8be29 FEAT_2: 3bf1cf26 - Correlation: 0.9998900847287077\n",
      "114: FEAT_1: 1af8be29 FEAT_2: Happy Camel_3020 - Correlation: 0.9999999999999999\n",
      "115: FEAT_1: 1af8be29 FEAT_2: Happy Camel_3120 - Correlation: 0.9998900847287077\n",
      "116: FEAT_1: 4a09ace1 FEAT_2: Scrub-A-Dub_2083 - Correlation: 1.0\n",
      "117: FEAT_1: e7e44842 FEAT_2: Watering Hole (Activity)_4090 - Correlation: 0.9999999999999999\n",
      "118: FEAT_1: f7e47413 FEAT_2: f71c4741 - Correlation: 0.9999426890770878\n",
      "119: FEAT_1: f7e47413 FEAT_2: Scrub-A-Dub_3110 - Correlation: 1.0\n",
      "120: FEAT_1: f7e47413 FEAT_2: Scrub-A-Dub_3010 - Correlation: 0.9999426890770878\n",
      "121: FEAT_1: 3bb91dda FEAT_2: d06f75b5 - Correlation: 0.9970877409320819\n",
      "122: FEAT_1: 3bb91dda FEAT_2: 895865f3 - Correlation: 0.9962789226264855\n",
      "123: FEAT_1: 3bb91dda FEAT_2: c54cf6c5 - Correlation: 0.9999701603895903\n",
      "124: FEAT_1: 3bb91dda FEAT_2: 8f094001 - Correlation: 0.99601669329561\n",
      "125: FEAT_1: 3bb91dda FEAT_2: Bubble Bath_4045 - Correlation: 0.99601669329561\n",
      "126: FEAT_1: 3bb91dda FEAT_2: Bubble Bath_2025 - Correlation: 0.9999701603895903\n",
      "127: FEAT_1: 3bb91dda FEAT_2: Bubble Bath_2035 - Correlation: 0.9970877409320819\n",
      "128: FEAT_1: 3bb91dda FEAT_2: Bubble Bath_4020 - Correlation: 0.9999999999999998\n",
      "129: FEAT_1: 3bb91dda FEAT_2: Bubble Bath_2030 - Correlation: 0.9962789226264855\n",
      "130: FEAT_1: 0a08139c FEAT_2: 71fe8f75 - Correlation: 0.9999850342981554\n",
      "131: FEAT_1: 0a08139c FEAT_2: Bug Measurer (Activity)_3110 - Correlation: 0.9999850342981554\n",
      "132: FEAT_1: 0a08139c FEAT_2: Bug Measurer (Activity)_3010 - Correlation: 1.0\n",
      "133: FEAT_1: b80e5e84 FEAT_2: 7ab78247 - Correlation: 0.9998336590281085\n",
      "134: FEAT_1: b80e5e84 FEAT_2: Egg Dropper (Activity)_3110 - Correlation: 1.0\n",
      "135: FEAT_1: b80e5e84 FEAT_2: Egg Dropper (Activity)_3010 - Correlation: 0.9998336590281085\n",
      "136: FEAT_1: 84b0e0c8 FEAT_2: ea321fb1 - Correlation: 0.9993007600205109\n",
      "137: FEAT_1: 84b0e0c8 FEAT_2: Chicken Balancer (Activity)_3110 - Correlation: 1.0\n",
      "138: FEAT_1: 84b0e0c8 FEAT_2: Chicken Balancer (Activity)_3010 - Correlation: 0.9993007600205109\n",
      "139: FEAT_1: 0413e89d FEAT_2: 15eb4a7d - Correlation: 0.9997266832893074\n",
      "140: FEAT_1: 0413e89d FEAT_2: Bubble Bath_3110 - Correlation: 0.9997266832893074\n",
      "141: FEAT_1: 0413e89d FEAT_2: Bubble Bath_3010 - Correlation: 1.0\n",
      "142: FEAT_1: 3a4be871 FEAT_2: Flower Waterer (Activity)_4080 - Correlation: 1.0\n",
      "143: FEAT_1: 56817e2b FEAT_2: cb6010f8 - Correlation: 0.9990475739429782\n",
      "144: FEAT_1: 56817e2b FEAT_2: 47026d5f - Correlation: 0.9993683693704368\n",
      "145: FEAT_1: 56817e2b FEAT_2: Chow Time_3021 - Correlation: 0.9993683693704368\n",
      "146: FEAT_1: 56817e2b FEAT_2: Chow Time_2030 - Correlation: 1.0\n",
      "147: FEAT_1: 56817e2b FEAT_2: Chow Time_3121 - Correlation: 0.9990475739429782\n",
      "148: FEAT_1: 731c0cbe FEAT_2: Bird Measurer (Assessment)_4090 - Correlation: 1.0\n",
      "149: FEAT_1: ad148f58 FEAT_2: 85de926c - Correlation: 0.9999995197498746\n",
      "150: FEAT_1: ad148f58 FEAT_2: 4230 - Correlation: 0.9999999999999998\n",
      "151: FEAT_1: ad148f58 FEAT_2: 4235 - Correlation: 0.9999995197498746\n",
      "152: FEAT_1: ad148f58 FEAT_2: Bubble Bath_4230 - Correlation: 0.9999999999999998\n",
      "153: FEAT_1: ad148f58 FEAT_2: Bubble Bath_4235 - Correlation: 0.9999995197498746\n",
      "154: FEAT_1: 67439901 FEAT_2: df4940d3 - Correlation: 0.999935162643595\n",
      "155: FEAT_1: 67439901 FEAT_2: Bottle Filler (Activity)_3010 - Correlation: 1.0\n",
      "156: FEAT_1: 67439901 FEAT_2: Bottle Filler (Activity)_3110 - Correlation: 0.999935162643595\n",
      "157: FEAT_1: bd612267 FEAT_2: Chest Sorter (Assessment)_4070 - Correlation: 0.9999999999999999\n",
      "158: FEAT_1: a8a78786 FEAT_2: c7fe2a55 - Correlation: 0.9981452039350778\n",
      "159: FEAT_1: a8a78786 FEAT_2: 36fa3ebe - Correlation: 0.9979559120623818\n",
      "160: FEAT_1: a8a78786 FEAT_2: Happy Camel_3021 - Correlation: 0.9981452039350778\n",
      "161: FEAT_1: a8a78786 FEAT_2: Happy Camel_3121 - Correlation: 0.9999999999999999\n",
      "162: FEAT_1: a8a78786 FEAT_2: Happy Camel_2030 - Correlation: 0.9979559120623818\n",
      "163: FEAT_1: ec138c1c FEAT_2: Bird Measurer (Assessment)_2020 - Correlation: 0.9999999999999999\n",
      "164: FEAT_1: e79f3763 FEAT_2: Bug Measurer (Activity)_4030 - Correlation: 1.0\n",
      "165: FEAT_1: 6c517a88 FEAT_2: Dino Drink_4070 - Correlation: 1.0\n",
      "166: FEAT_1: c74f40cd FEAT_2: 28ed704e - Correlation: 0.9955185671057012\n",
      "167: FEAT_1: c74f40cd FEAT_2: 83c6c409 - Correlation: 0.9963987221516344\n",
      "168: FEAT_1: c74f40cd FEAT_2: 9d29771f - Correlation: 0.9999553655332928\n",
      "169: FEAT_1: c74f40cd FEAT_2: 3dfd4aa4 - Correlation: 0.996396898906497\n",
      "170: FEAT_1: c74f40cd FEAT_2: Mushroom Sorter (Assessment)_2035 - Correlation: 0.9963987221516344\n",
      "171: FEAT_1: c74f40cd FEAT_2: Mushroom Sorter (Assessment)_3121 - Correlation: 0.9999999999999999\n",
      "172: FEAT_1: c74f40cd FEAT_2: Mushroom Sorter (Assessment)_4025 - Correlation: 0.9955185671057012\n",
      "173: FEAT_1: c74f40cd FEAT_2: Mushroom Sorter (Assessment)_3021 - Correlation: 0.9999553655332928\n",
      "174: FEAT_1: c74f40cd FEAT_2: Mushroom Sorter (Assessment)_2020 - Correlation: 0.996396898906497\n",
      "175: FEAT_1: ca11f653 FEAT_2: daac11b0 - Correlation: 0.9995251307611354\n",
      "176: FEAT_1: ca11f653 FEAT_2: 1f19558b - Correlation: 0.998316427341082\n",
      "177: FEAT_1: ca11f653 FEAT_2: All Star Sorting_3121 - Correlation: 0.998316427341082\n",
      "178: FEAT_1: ca11f653 FEAT_2: All Star Sorting_2030 - Correlation: 1.0\n",
      "179: FEAT_1: ca11f653 FEAT_2: All Star Sorting_3021 - Correlation: 0.9995251307611354\n",
      "180: FEAT_1: c2baf0bd FEAT_2: Happy Camel_2020 - Correlation: 1.0\n",
      "181: FEAT_1: 6043a2b4 FEAT_2: All Star Sorting_4090 - Correlation: 0.9999999999999999\n",
      "182: FEAT_1: 3d0b9317 FEAT_2: Chest Sorter (Assessment)_4040 - Correlation: 1.0\n",
      "183: FEAT_1: dcaede90 FEAT_2: 5a848010 - Correlation: 0.9976195852057889\n",
      "184: FEAT_1: dcaede90 FEAT_2: 2b9272f4 - Correlation: 0.9964451607954699\n",
      "185: FEAT_1: dcaede90 FEAT_2: 37c53127 - Correlation: 0.9965259434878118\n",
      "186: FEAT_1: dcaede90 FEAT_2: 73757a5e - Correlation: 0.9966452709971663\n",
      "187: FEAT_1: dcaede90 FEAT_2: 2050 - Correlation: 0.9965259434878118\n",
      "188: FEAT_1: dcaede90 FEAT_2: 2040 - Correlation: 0.9999999999999998\n",
      "189: FEAT_1: dcaede90 FEAT_2: Scrub-A-Dub_3021 - Correlation: 0.9966452709971663\n",
      "190: FEAT_1: dcaede90 FEAT_2: Scrub-A-Dub_2080 - Correlation: 0.9976195852057889\n",
      "191: FEAT_1: dcaede90 FEAT_2: Scrub-A-Dub_2050 - Correlation: 0.9965259434878118\n",
      "192: FEAT_1: dcaede90 FEAT_2: Scrub-A-Dub_2040 - Correlation: 0.9999999999999998\n",
      "193: FEAT_1: dcaede90 FEAT_2: Scrub-A-Dub_3121 - Correlation: 0.9964451607954699\n",
      "194: FEAT_1: ecc6157f FEAT_2: Cart Balancer (Assessment)_4080 - Correlation: 0.9999999999999999\n",
      "195: FEAT_1: 53c6e11a FEAT_2: Leaf Leader_2075 - Correlation: 0.9999999999999999\n",
      "196: FEAT_1: a1192f43 FEAT_2: 4050 - Correlation: 0.9999999999999999\n",
      "197: FEAT_1: a1192f43 FEAT_2: Crystals Rule_4050 - Correlation: 0.9999999999999999\n",
      "198: FEAT_1: d122731b FEAT_2: Cart Balancer (Assessment)_4100 - Correlation: 0.9999999999999998\n",
      "199: FEAT_1: 1575e76c FEAT_2: Air Show_2020 - Correlation: 1.0\n",
      "200: FEAT_1: de26c3a6 FEAT_2: Flower Waterer (Activity)_4020 - Correlation: 0.9999999999999999\n",
      "201: FEAT_1: c189aaf2 FEAT_2: Happy Camel_2083 - Correlation: 0.9999999999999999\n",
      "202: FEAT_1: a1bbe385 FEAT_2: f28c589a - Correlation: 0.999953679734225\n",
      "203: FEAT_1: a1bbe385 FEAT_2: Air Show_3010 - Correlation: 0.999953679734225\n",
      "204: FEAT_1: a1bbe385 FEAT_2: Air Show_3110 - Correlation: 1.0\n",
      "205: FEAT_1: 5c2f29ca FEAT_2: Cart Balancer (Assessment)_4020 - Correlation: 1.0\n",
      "206: FEAT_1: 562cec5f FEAT_2: Chest Sorter (Assessment)_4025 - Correlation: 1.0\n",
      "207: FEAT_1: 763fc34e FEAT_2: e57dd7af - Correlation: 0.9972721980394412\n",
      "208: FEAT_1: 763fc34e FEAT_2: Leaf Leader_3020 - Correlation: 1.0\n",
      "209: FEAT_1: 763fc34e FEAT_2: Leaf Leader_3120 - Correlation: 0.9972721980394412\n",
      "210: FEAT_1: 9e34ea74 FEAT_2: Egg Dropper (Activity)_4070 - Correlation: 1.0\n",
      "211: FEAT_1: acf5c23f FEAT_2: Cart Balancer (Assessment)_4070 - Correlation: 1.0\n",
      "212: FEAT_1: 6bf9e3e1 FEAT_2: Happy Camel_4040 - Correlation: 0.9999999999999999\n",
      "213: FEAT_1: 56bcd38d FEAT_2: Chicken Balancer (Activity)_4030 - Correlation: 0.9999999999999998\n",
      "214: FEAT_1: 46b50ba8 FEAT_2: Happy Camel_4095 - Correlation: 0.9999999999999998\n",
      "215: FEAT_1: 6f4adc4b FEAT_2: 55115cbd - Correlation: 0.9997831892615398\n",
      "216: FEAT_1: 6f4adc4b FEAT_2: Bubble Bath_3121 - Correlation: 0.9997831892615398\n",
      "217: FEAT_1: 6f4adc4b FEAT_2: Bubble Bath_3021 - Correlation: 1.0\n",
      "218: FEAT_1: 2ec694de FEAT_2: Bug Measurer (Activity)_4080 - Correlation: 0.9999999999999998\n",
      "219: FEAT_1: 0086365d FEAT_2: Pan Balance_4010 - Correlation: 0.9999999999999999\n",
      "220: FEAT_1: 8af75982 FEAT_2: Happy Camel_4020 - Correlation: 1.0\n",
      "221: FEAT_1: 804ee27f FEAT_2: Pan Balance_4020 - Correlation: 1.0\n",
      "222: FEAT_1: e720d930 FEAT_2: 3ddc79c3 - Correlation: 0.9998920962508024\n",
      "223: FEAT_1: e720d930 FEAT_2: 3323d7e9 - Correlation: 0.9998454394844453\n",
      "224: FEAT_1: e720d930 FEAT_2: 7cf1bc53 - Correlation: 0.9979345979643147\n",
      "225: FEAT_1: e720d930 FEAT_2: Crystals Rule_3021 - Correlation: 0.9998920962508024\n",
      "226: FEAT_1: e720d930 FEAT_2: Crystals Rule_2020 - Correlation: 0.9979345979643147\n",
      "227: FEAT_1: e720d930 FEAT_2: Crystals Rule_3121 - Correlation: 1.0\n",
      "228: FEAT_1: e720d930 FEAT_2: Crystals Rule_2030 - Correlation: 0.9998454394844453\n",
      "229: FEAT_1: 45d01abe FEAT_2: 7525289a - Correlation: 0.9981555049446889\n",
      "230: FEAT_1: 45d01abe FEAT_2: Bird Measurer (Assessment)_3021 - Correlation: 1.0\n",
      "231: FEAT_1: 45d01abe FEAT_2: Bird Measurer (Assessment)_3121 - Correlation: 0.9981555049446889\n",
      "232: FEAT_1: 06372577 FEAT_2: Air Show_2060 - Correlation: 1.0\n",
      "233: FEAT_1: 89aace00 FEAT_2: e5734469 - Correlation: 0.9998406115110345\n",
      "234: FEAT_1: 89aace00 FEAT_2: Dino Drink_3120 - Correlation: 1.0\n",
      "235: FEAT_1: 89aace00 FEAT_2: Dino Drink_3020 - Correlation: 0.9998406115110345\n",
      "236: FEAT_1: 7040c096 FEAT_2: Scrub-A-Dub_4010 - Correlation: 1.0\n",
      "237: FEAT_1: 26fd2d99 FEAT_2: 08fd73f3 - Correlation: 0.9995958424673179\n",
      "238: FEAT_1: 26fd2d99 FEAT_2: Scrub-A-Dub_2030 - Correlation: 0.9995958424673179\n",
      "239: FEAT_1: 26fd2d99 FEAT_2: Scrub-A-Dub_2020 - Correlation: 0.9999999999999999\n",
      "240: FEAT_1: a7640a16 FEAT_2: Happy Camel_4070 - Correlation: 1.0\n",
      "241: FEAT_1: 47efca07 FEAT_2: Bottle Filler (Activity)_4090 - Correlation: 1.0\n",
      "242: FEAT_1: e04fb33d FEAT_2: 7423acbc - Correlation: 0.999628997408126\n",
      "243: FEAT_1: e04fb33d FEAT_2: Air Show_3020 - Correlation: 0.999628997408126\n",
      "244: FEAT_1: e04fb33d FEAT_2: Air Show_3120 - Correlation: 1.0\n",
      "245: FEAT_1: 38074c54 FEAT_2: e4f1efe6 - Correlation: 0.9984044689083383\n",
      "246: FEAT_1: 38074c54 FEAT_2: 222660ff - Correlation: 0.9999999999999998\n",
      "247: FEAT_1: 38074c54 FEAT_2: Chest Sorter (Assessment)_2010 - Correlation: 0.9999999999999998\n",
      "248: FEAT_1: 38074c54 FEAT_2: Chest Sorter (Assessment)_2030 - Correlation: 0.9999999999999998\n",
      "249: FEAT_1: 38074c54 FEAT_2: Chest Sorter (Assessment)_3121 - Correlation: 0.9984044689083383\n",
      "250: FEAT_1: 3ee399c3 FEAT_2: Cauldron Filler (Assessment)_4070 - Correlation: 1.0\n",
      "251: FEAT_1: 7da34a02 FEAT_2: Mushroom Sorter (Assessment)_4070 - Correlation: 0.9999999999999998\n",
      "252: FEAT_1: e7561dd2 FEAT_2: Pan Balance_4025 - Correlation: 0.9999999999999998\n",
      "253: FEAT_1: 2dcad279 FEAT_2: 923afab1 - Correlation: 0.9998567985670083\n",
      "254: FEAT_1: 2dcad279 FEAT_2: Cauldron Filler (Assessment)_3010 - Correlation: 0.9998567985670083\n",
      "255: FEAT_1: 2dcad279 FEAT_2: Cauldron Filler (Assessment)_3110 - Correlation: 0.9999999999999999\n",
      "256: FEAT_1: a44b10dc FEAT_2: Flower Waterer (Activity)_4070 - Correlation: 1.0\n",
      "257: FEAT_1: 9e4c8c7b FEAT_2: 363d3849 - Correlation: 0.9992130941883633\n",
      "258: FEAT_1: 9e4c8c7b FEAT_2: All Star Sorting_3110 - Correlation: 0.9999999999999998\n",
      "259: FEAT_1: 9e4c8c7b FEAT_2: All Star Sorting_3010 - Correlation: 0.9992130941883633\n",
      "260: FEAT_1: 00c73085 FEAT_2: Dino Dive_2030 - Correlation: 0.9999999999999999\n",
      "261: FEAT_1: 01ca3a3c FEAT_2: Leaf Leader_4080 - Correlation: 0.9999999999999999\n",
      "262: FEAT_1: 25fa8af4 FEAT_2: Mushroom Sorter (Assessment)_4100 - Correlation: 1.0\n",
      "263: FEAT_1: 4e5fc6f5 FEAT_2: Cart Balancer (Assessment)_4090 - Correlation: 1.0\n",
      "264: FEAT_1: 90efca10 FEAT_2: Bottle Filler (Activity)_4020 - Correlation: 1.0\n",
      "265: FEAT_1: 3afde5dd FEAT_2: e5c9df6f - Correlation: 0.9990910601838011\n",
      "266: FEAT_1: 3afde5dd FEAT_2: b012cd7f - Correlation: 0.9999689260314981\n",
      "267: FEAT_1: 3afde5dd FEAT_2: Leaf Leader_2030 - Correlation: 0.9999689260314981\n",
      "268: FEAT_1: 3afde5dd FEAT_2: Leaf Leader_3121 - Correlation: 0.9990910601838011\n",
      "269: FEAT_1: 3afde5dd FEAT_2: Leaf Leader_3021 - Correlation: 1.0\n",
      "270: FEAT_1: 6088b756 FEAT_2: Dino Dive_2070 - Correlation: 1.0\n",
      "271: FEAT_1: b1d5101d FEAT_2: All Star Sorting_4095 - Correlation: 1.0\n",
      "272: FEAT_1: 4d6737eb FEAT_2: Dino Drink_2070 - Correlation: 1.0\n",
      "273: FEAT_1: fbaf3456 FEAT_2: Mushroom Sorter (Assessment)_4030 - Correlation: 0.9999999999999999\n",
      "274: FEAT_1: 532a2afb FEAT_2: Cauldron Filler (Assessment)_2020 - Correlation: 1.0\n",
      "275: FEAT_1: cfbd47c8 FEAT_2: Chow Time_4030 - Correlation: 1.0\n",
      "276: FEAT_1: 87d743c1 FEAT_2: Dino Dive_4010 - Correlation: 1.0\n",
      "277: FEAT_1: a52b92d5 FEAT_2: a1e4395d - Correlation: 0.9991003891313369\n",
      "278: FEAT_1: a52b92d5 FEAT_2: Mushroom Sorter (Assessment)_3110 - Correlation: 0.9999999999999998\n",
      "279: FEAT_1: a52b92d5 FEAT_2: Mushroom Sorter (Assessment)_3010 - Correlation: 0.9991003891313369\n",
      "280: FEAT_1: 19967db1 FEAT_2: Chow Time_4090 - Correlation: 1.0\n",
      "281: FEAT_1: 37937459 FEAT_2: Sandcastle Builder (Activity)_4090 - Correlation: 0.9999999999999998\n",
      "282: FEAT_1: 84538528 FEAT_2: Sandcastle Builder (Activity)_4020 - Correlation: 1.0\n",
      "283: FEAT_1: 99ea62f3 FEAT_2: Bubble Bath_2083 - Correlation: 1.0\n",
      "284: FEAT_1: 31973d56 FEAT_2: 5de79a6a - Correlation: 0.9973945339840646\n",
      "285: FEAT_1: 31973d56 FEAT_2: Cart Balancer (Assessment)_3020 - Correlation: 0.9973945339840646\n",
      "286: FEAT_1: 31973d56 FEAT_2: Cart Balancer (Assessment)_3120 - Correlation: 1.0\n",
      "287: FEAT_1: 0d1da71f FEAT_2: Chow Time_3110 - Correlation: 1.0\n",
      "288: FEAT_1: 9554a50b FEAT_2: Cauldron Filler (Assessment)_4080 - Correlation: 0.9999999999999999\n",
      "289: FEAT_1: 4c2ec19f FEAT_2: Egg Dropper (Activity)_4025 - Correlation: 1.0\n",
      "290: FEAT_1: 5be391b5 FEAT_2: Dino Drink_4010 - Correlation: 1.0\n",
      "291: FEAT_1: 565a3990 FEAT_2: Bug Measurer (Activity)_4070 - Correlation: 1.0\n",
      "292: FEAT_1: ac92046e FEAT_2: d88e8f25 - Correlation: 0.9999763070332107\n",
      "293: FEAT_1: ac92046e FEAT_2: Scrub-A-Dub_3120 - Correlation: 1.0\n",
      "294: FEAT_1: ac92046e FEAT_2: Scrub-A-Dub_3020 - Correlation: 0.9999763070332107\n",
      "295: FEAT_1: 6077cc36 FEAT_2: Bird Measurer (Assessment)_4080 - Correlation: 0.9999999999999998\n",
      "296: FEAT_1: 08ff79ad FEAT_2: Egg Dropper (Activity)_4090 - Correlation: 1.0\n",
      "297: FEAT_1: 6aeafed4 FEAT_2: Bubble Bath_4090 - Correlation: 1.0\n",
      "298: FEAT_1: f54238ee FEAT_2: Fireworks (Activity)_4090 - Correlation: 1.0\n",
      "299: FEAT_1: 15f99afc FEAT_2: 6cf7d25c - Correlation: 0.9994848234397947\n",
      "300: FEAT_1: 15f99afc FEAT_2: Pan Balance_3110 - Correlation: 1.0\n",
      "301: FEAT_1: 15f99afc FEAT_2: Pan Balance_3010 - Correlation: 0.9994848234397947\n",
      "302: FEAT_1: d2659ab4 FEAT_2: Air Show_2075 - Correlation: 1.0\n",
      "303: FEAT_1: c1cac9a2 FEAT_2: Scrub-A-Dub_2081 - Correlation: 0.9999999999999998\n",
      "304: FEAT_1: 6c930e6e FEAT_2: a5be6304 - Correlation: 0.9962760616821671\n",
      "305: FEAT_1: 6c930e6e FEAT_2: Mushroom Sorter (Assessment)_2030 - Correlation: 0.9999999999999999\n",
      "306: FEAT_1: 6c930e6e FEAT_2: Mushroom Sorter (Assessment)_2010 - Correlation: 0.9962760616821671\n",
      "307: FEAT_1: 461eace6 FEAT_2: Egg Dropper (Activity)_4020 - Correlation: 1.0\n",
      "308: FEAT_1: 2a444e03 FEAT_2: Pan Balance_4030 - Correlation: 1.0\n",
      "309: FEAT_1: 499edb7c FEAT_2: Chicken Balancer (Activity)_4020 - Correlation: 1.0\n",
      "310: FEAT_1: 8b757ab8 FEAT_2: 44cb4907 - Correlation: 0.999835058794711\n",
      "311: FEAT_1: 8b757ab8 FEAT_2: Crystals Rule_3120 - Correlation: 1.0\n",
      "312: FEAT_1: 8b757ab8 FEAT_2: Crystals Rule_3020 - Correlation: 0.999835058794711\n",
      "313: FEAT_1: 4bb2f698 FEAT_2: Chicken Balancer (Activity)_4070 - Correlation: 0.9999999999999998\n",
      "314: FEAT_1: cf82af56 FEAT_2: Scrub-A-Dub_4070 - Correlation: 1.0\n",
      "315: FEAT_1: 3babcb9b FEAT_2: 86c924c4 - Correlation: 0.9988970478897697\n",
      "316: FEAT_1: 3babcb9b FEAT_2: 5154fc30 - Correlation: 0.999986924640935\n",
      "317: FEAT_1: 3babcb9b FEAT_2: Crystals Rule_3110 - Correlation: 1.0\n",
      "318: FEAT_1: 3babcb9b FEAT_2: Crystals Rule_4020 - Correlation: 0.9988970478897697\n",
      "319: FEAT_1: 3babcb9b FEAT_2: Crystals Rule_3010 - Correlation: 0.999986924640935\n",
      "320: FEAT_1: e9c52111 FEAT_2: b7530680 - Correlation: 0.998817689964623\n",
      "321: FEAT_1: e9c52111 FEAT_2: Bottle Filler (Activity)_2030 - Correlation: 1.0\n",
      "322: FEAT_1: e9c52111 FEAT_2: Bottle Filler (Activity)_2020 - Correlation: 0.998817689964623\n",
      "323: FEAT_1: dcb55a27 FEAT_2: Air Show_4110 - Correlation: 1.0\n",
      "324: FEAT_1: a592d54e FEAT_2: 1c178d24 - Correlation: 0.9973125883100831\n",
      "325: FEAT_1: a592d54e FEAT_2: 250513af - Correlation: 0.9973020736885158\n",
      "326: FEAT_1: a592d54e FEAT_2: cf7638f3 - Correlation: 0.9969813738295747\n",
      "327: FEAT_1: a592d54e FEAT_2: Pan Balance_2020 - Correlation: 0.9999999999999999\n",
      "328: FEAT_1: a592d54e FEAT_2: Pan Balance_2030 - Correlation: 0.9973125883100831\n",
      "329: FEAT_1: a592d54e FEAT_2: Pan Balance_3121 - Correlation: 0.9969813738295747\n",
      "330: FEAT_1: a592d54e FEAT_2: Pan Balance_3021 - Correlation: 0.9973020736885158\n",
      "331: FEAT_1: 93edfe2e FEAT_2: Crystals Rule_4090 - Correlation: 1.0\n",
      "332: FEAT_1: 51102b85 FEAT_2: Bird Measurer (Assessment)_4030 - Correlation: 1.0\n",
      "333: FEAT_1: 6f445b57 FEAT_2: Chow Time_4080 - Correlation: 1.0\n",
      "334: FEAT_1: 3ccd3f02 FEAT_2: 3dcdda7f - Correlation: 0.9977337946782758\n",
      "335: FEAT_1: 3ccd3f02 FEAT_2: Chest Sorter (Assessment)_3010 - Correlation: 0.9977337946782758\n",
      "336: FEAT_1: 3ccd3f02 FEAT_2: Chest Sorter (Assessment)_3110 - Correlation: 1.0\n",
      "337: FEAT_1: 9ee1c98c FEAT_2: Sandcastle Builder (Activity)_4021 - Correlation: 0.9999999999999999\n",
      "338: FEAT_1: 05ad839b FEAT_2: Happy Camel_4090 - Correlation: 1.0\n",
      "339: FEAT_1: bdf49a58 FEAT_2: 1375ccb7 - Correlation: 0.9993801763820347\n",
      "340: FEAT_1: bdf49a58 FEAT_2: Bird Measurer (Assessment)_3010 - Correlation: 0.9993801763820347\n",
      "341: FEAT_1: bdf49a58 FEAT_2: Bird Measurer (Assessment)_3110 - Correlation: 1.0\n",
      "342: FEAT_1: d3268efa FEAT_2: b5053438 - Correlation: 0.999576326704631\n",
      "343: FEAT_1: d3268efa FEAT_2: 28520915 - Correlation: 0.9989055023166136\n",
      "344: FEAT_1: d3268efa FEAT_2: Cauldron Filler (Assessment)_3021 - Correlation: 1.0\n",
      "345: FEAT_1: d3268efa FEAT_2: Cauldron Filler (Assessment)_3121 - Correlation: 0.999576326704631\n",
      "346: FEAT_1: d3268efa FEAT_2: Cauldron Filler (Assessment)_2030 - Correlation: 0.9989055023166136\n",
      "347: FEAT_1: 8d7e386c FEAT_2: 69fdac0a - Correlation: 0.9996590210382708\n",
      "348: FEAT_1: 8d7e386c FEAT_2: Happy Camel_3110 - Correlation: 0.9996590210382708\n",
      "349: FEAT_1: 8d7e386c FEAT_2: Happy Camel_3010 - Correlation: 1.0\n",
      "350: FEAT_1: 857f21c0 FEAT_2: Bubble Bath_4040 - Correlation: 1.0\n",
      "351: FEAT_1: d38c2fd7 FEAT_2: Bird Measurer (Assessment)_4035 - Correlation: 0.9999999999999999\n",
      "352: FEAT_1: cc5087a3 FEAT_2: Crystals Rule_4010 - Correlation: 1.0\n",
      "353: FEAT_1: 71e712d8 FEAT_2: a6d66e51 - Correlation: 0.9991849213605334\n",
      "354: FEAT_1: 71e712d8 FEAT_2: 5000 - Correlation: 0.9991849213605334\n",
      "355: FEAT_1: 71e712d8 FEAT_2: 5010 - Correlation: 0.9999999999999998\n",
      "356: FEAT_1: 71e712d8 FEAT_2: Watering Hole (Activity)_5010 - Correlation: 0.9999999999999998\n",
      "357: FEAT_1: 71e712d8 FEAT_2: Watering Hole (Activity)_5000 - Correlation: 0.9991849213605334\n",
      "358: FEAT_1: abc5811c FEAT_2: Happy Camel_4010 - Correlation: 1.0\n",
      "359: FEAT_1: 828e68f9 FEAT_2: Cart Balancer (Assessment)_3110 - Correlation: 1.0\n",
      "360: FEAT_1: b2e5b0f1 FEAT_2: b74258a0 - Correlation: 0.999849464604504\n",
      "361: FEAT_1: b2e5b0f1 FEAT_2: ecaab346 - Correlation: 0.999849464604504\n",
      "362: FEAT_1: b2e5b0f1 FEAT_2: Cart Balancer (Assessment)_2010 - Correlation: 1.0\n",
      "363: FEAT_1: b2e5b0f1 FEAT_2: Cart Balancer (Assessment)_2030 - Correlation: 0.999849464604504\n",
      "364: FEAT_1: b2e5b0f1 FEAT_2: Cart Balancer (Assessment)_3121 - Correlation: 0.999849464604504\n",
      "365: FEAT_1: 85d1b0de FEAT_2: Chicken Balancer (Activity)_4090 - Correlation: 1.0\n",
      "366: FEAT_1: d3f1e122 FEAT_2: Bottle Filler (Activity)_4035 - Correlation: 1.0\n",
      "367: FEAT_1: 3bb91ced FEAT_2: Happy Camel_2081 - Correlation: 1.0\n",
      "368: FEAT_1: 0db6d71d FEAT_2: Chest Sorter (Assessment)_4020 - Correlation: 1.0\n",
      "369: FEAT_1: b2dba42b FEAT_2: 1bb5fbdb - Correlation: 0.9999521729413294\n",
      "370: FEAT_1: b2dba42b FEAT_2: Sandcastle Builder (Activity)_3110 - Correlation: 0.9999521729413294\n",
      "371: FEAT_1: b2dba42b FEAT_2: Sandcastle Builder (Activity)_3010 - Correlation: 1.0\n",
      "372: FEAT_1: 7fd1ac25 FEAT_2: Egg Dropper (Activity)_4080 - Correlation: 1.0\n",
      "373: FEAT_1: 65abac75 FEAT_2: Air Show_4010 - Correlation: 1.0\n",
      "374: FEAT_1: 74e5f8a7 FEAT_2: Dino Drink_4020 - Correlation: 1.0\n",
      "375: FEAT_1: 16667cc5 FEAT_2: Chicken Balancer (Activity)_4080 - Correlation: 0.9999999999999999\n",
      "376: FEAT_1: 795e4a37 FEAT_2: Cart Balancer (Assessment)_3010 - Correlation: 1.0\n",
      "377: FEAT_1: 28f975ea FEAT_2: Air Show_4020 - Correlation: 1.0\n",
      "378: FEAT_1: 7ec0c298 FEAT_2: Chow Time_3010 - Correlation: 0.9999999999999999\n",
      "379: FEAT_1: 49ed92e9 FEAT_2: bd701df8 - Correlation: 0.9993109138888533\n",
      "380: FEAT_1: 49ed92e9 FEAT_2: Watering Hole (Activity)_3110 - Correlation: 0.9993109138888533\n",
      "381: FEAT_1: 49ed92e9 FEAT_2: Watering Hole (Activity)_3010 - Correlation: 1.0\n",
      "382: FEAT_1: 90ea0bac FEAT_2: 5859dfb6 - Correlation: 0.9981052472610569\n",
      "383: FEAT_1: 90ea0bac FEAT_2: Bubble Bath_3120 - Correlation: 0.9981052472610569\n",
      "384: FEAT_1: 90ea0bac FEAT_2: Bubble Bath_3020 - Correlation: 1.0\n",
      "385: FEAT_1: e4d32835 FEAT_2: Pan Balance_4080 - Correlation: 0.9999999999999998\n",
      "386: FEAT_1: 7f0836bf FEAT_2: a29c5338 - Correlation: 0.9986531654717627\n",
      "387: FEAT_1: 7f0836bf FEAT_2: Dino Drink_3110 - Correlation: 1.0\n",
      "388: FEAT_1: 7f0836bf FEAT_2: Dino Drink_3010 - Correlation: 0.9986531654717627\n",
      "389: FEAT_1: 7372e1a5 FEAT_2: Chow Time_4070 - Correlation: 1.0\n",
      "390: FEAT_1: 4d911100 FEAT_2: 16dffff1 - Correlation: 0.9986046680098603\n",
      "391: FEAT_1: 4d911100 FEAT_2: 77ead60d - Correlation: 0.9998475927724766\n",
      "392: FEAT_1: 4d911100 FEAT_2: Dino Drink_3121 - Correlation: 1.0\n",
      "393: FEAT_1: 4d911100 FEAT_2: Dino Drink_2030 - Correlation: 0.9986046680098603\n",
      "394: FEAT_1: 4d911100 FEAT_2: Dino Drink_3021 - Correlation: 0.9998475927724766\n",
      "395: FEAT_1: 262136f4 FEAT_2: Leaf Leader_4020 - Correlation: 1.0\n",
      "396: FEAT_1: d51b1749 FEAT_2: Happy Camel_2080 - Correlation: 1.0\n",
      "397: FEAT_1: 4a4c3d21 FEAT_2: Bird Measurer (Assessment)_4025 - Correlation: 1.0\n",
      "398: FEAT_1: a2df0760 FEAT_2: Happy Camel_4035 - Correlation: 0.9999999999999999\n",
      "399: FEAT_1: 907a054b FEAT_2: c51d8688 - Correlation: 0.9999667370361688\n",
      "400: FEAT_1: 907a054b FEAT_2: Pan Balance_3020 - Correlation: 1.0\n",
      "401: FEAT_1: 907a054b FEAT_2: Pan Balance_3120 - Correlation: 0.9999667370361688\n",
      "402: FEAT_1: 9d4e7b25 FEAT_2: Cart Balancer (Assessment)_4040 - Correlation: 1.0\n",
      "403: FEAT_1: 30df3273 FEAT_2: Sandcastle Builder (Activity)_4080 - Correlation: 1.0\n",
      "404: FEAT_1: e694a35b FEAT_2: Fireworks (Activity)_4020 - Correlation: 1.0\n",
      "405: FEAT_1: 6f8106d9 FEAT_2: Dino Drink_4090 - Correlation: 1.0\n",
      "406: FEAT_1: a16a373e FEAT_2: Bird Measurer (Assessment)_4070 - Correlation: 1.0\n",
      "407: FEAT_1: 02a42007 FEAT_2: Fireworks (Activity)_4030 - Correlation: 1.0\n",
      "408: FEAT_1: e080a381 FEAT_2: Pan Balance_4090 - Correlation: 1.0\n",
      "409: FEAT_1: d3640339 FEAT_2: Dino Dive_4090 - Correlation: 1.0\n",
      "410: FEAT_1: a0faea5d FEAT_2: Bubble Bath_4070 - Correlation: 1.0\n",
      "411: FEAT_1: ab4ec3a4 FEAT_2: Dino Drink_4080 - Correlation: 1.0\n",
      "412: FEAT_1: bc8f2793 FEAT_2: Pan Balance_4035 - Correlation: 0.9999999999999999\n",
      "413: FEAT_1: 5e109ec3 FEAT_2: Cart Balancer (Assessment)_4030 - Correlation: 1.0\n",
      "414: FEAT_1: 598f4598 FEAT_2: Flower Waterer (Activity)_4025 - Correlation: 0.9999999999999998\n",
      "415: FEAT_1: 5290eab1 FEAT_2: 04df9b66 - Correlation: 0.9998190477466209\n",
      "416: FEAT_1: 5290eab1 FEAT_2: Cauldron Filler (Assessment)_3120 - Correlation: 1.0\n",
      "417: FEAT_1: 5290eab1 FEAT_2: Cauldron Filler (Assessment)_3020 - Correlation: 0.9998190477466209\n",
      "418: FEAT_1: d02b7a8e FEAT_2: All Star Sorting_4035 - Correlation: 1.0\n",
      "419: FEAT_1: ea296733 FEAT_2: df4fe8b6 - Correlation: 0.9972489515829078\n",
      "420: FEAT_1: ea296733 FEAT_2: Chest Sorter (Assessment)_3020 - Correlation: 1.0\n",
      "421: FEAT_1: ea296733 FEAT_2: Chest Sorter (Assessment)_3120 - Correlation: 0.9972489515829078\n",
      "422: FEAT_1: 8d84fa81 FEAT_2: Bubble Bath_4010 - Correlation: 1.0\n",
      "423: FEAT_1: 363c86c9 FEAT_2: Bug Measurer (Activity)_4035 - Correlation: 1.0\n",
      "424: FEAT_1: 56cd3b43 FEAT_2: bbfe0445 - Correlation: 0.9996926215355526\n",
      "425: FEAT_1: 56cd3b43 FEAT_2: Flower Waterer (Activity)_3110 - Correlation: 0.9996926215355526\n",
      "426: FEAT_1: 56cd3b43 FEAT_2: Flower Waterer (Activity)_3010 - Correlation: 1.0\n",
      "427: FEAT_1: 9ce586dd FEAT_2: Chest Sorter (Assessment)_4035 - Correlation: 1.0\n",
      "428: FEAT_1: 3b2048ee FEAT_2: Leaf Leader_4095 - Correlation: 1.0\n",
      "429: FEAT_1: a76029ee FEAT_2: Bird Measurer (Assessment)_4040 - Correlation: 0.9999999999999999\n",
      "430: FEAT_1: 119b5b02 FEAT_2: Dino Dive_4080 - Correlation: 1.0\n",
      "431: FEAT_1: b88f38da FEAT_2: beb0a7b9 - Correlation: 0.9999125179829755\n",
      "432: FEAT_1: b88f38da FEAT_2: Fireworks (Activity)_3010 - Correlation: 0.9999125179829755\n",
      "433: FEAT_1: b88f38da FEAT_2: Fireworks (Activity)_3110 - Correlation: 1.0\n",
      "434: FEAT_1: bfc77bd6 FEAT_2: Chest Sorter (Assessment)_4080 - Correlation: 0.9999999999999998\n",
      "435: FEAT_1: 3d8c61b0 FEAT_2: Happy Camel_4030 - Correlation: 0.9999999999999999\n",
      "436: FEAT_1: 1325467d FEAT_2: Sandcastle Builder (Activity)_4070 - Correlation: 1.0\n",
      "437: FEAT_1: 587b5989 FEAT_2: All Star Sorting_4070 - Correlation: 1.0\n",
      "438: FEAT_1: 93b353f2 FEAT_2: Chest Sorter (Assessment)_4100 - Correlation: 0.9999999999999998\n",
      "439: FEAT_1: 3afb49e6 FEAT_2: Chest Sorter (Assessment)_3021 - Correlation: 1.0\n",
      "440: FEAT_1: 29a42aea FEAT_2: Bubble Bath_4080 - Correlation: 1.0\n",
      "441: FEAT_1: 392e14df FEAT_2: Cauldron Filler (Assessment)_4100 - Correlation: 1.0\n",
      "442: FEAT_1: 9e6b7fb5 FEAT_2: Chow Time_4095 - Correlation: 0.9999999999999998\n",
      "443: FEAT_1: 2b058fe3 FEAT_2: Cauldron Filler (Assessment)_2010 - Correlation: 1.0\n",
      "444: FEAT_1: 0d18d96c FEAT_2: Mushroom Sorter (Assessment)_4035 - Correlation: 1.0\n",
      "445: FEAT_1: c6971acf FEAT_2: Dino Drink_2060 - Correlation: 0.9999999999999999\n",
      "446: FEAT_1: f93fc684 FEAT_2: Chow Time_4010 - Correlation: 0.9999999999999999\n",
      "447: FEAT_1: 5f5b2617 FEAT_2: Bottle Filler (Activity)_4080 - Correlation: 1.0\n",
      "448: FEAT_1: 77c76bc5 FEAT_2: Cauldron Filler (Assessment)_4090 - Correlation: 1.0\n",
      "449: FEAT_1: c0415e5c FEAT_2: Dino Dive_4020 - Correlation: 1.0\n",
      "450: FEAT_1: f3cd5473 FEAT_2: Pan Balance_4070 - Correlation: 1.0\n",
      "451: FEAT_1: 5348fd84 FEAT_2: Cauldron Filler (Assessment)_4040 - Correlation: 1.0\n",
      "452: FEAT_1: 1b54d27f FEAT_2: Watering Hole (Activity)_2010 - Correlation: 1.0\n",
      "453: FEAT_1: 1996c610 FEAT_2: 4031 - Correlation: 1.0\n",
      "454: FEAT_1: 1996c610 FEAT_2: Dino Drink_4031 - Correlation: 1.0\n",
      "455: FEAT_1: 5c3d2b2f FEAT_2: Scrub-A-Dub_4020 - Correlation: 1.0\n",
      "456: FEAT_1: 1340b8d7 FEAT_2: 4220 - Correlation: 1.0\n",
      "457: FEAT_1: 1340b8d7 FEAT_2: Bubble Bath_4220 - Correlation: 1.0\n",
      "458: FEAT_1: 1cc7cfca FEAT_2: All Star Sorting_4030 - Correlation: 1.0\n",
      "459: FEAT_1: f50fc6c1 FEAT_2: Watering Hole (Activity)_4021 - Correlation: 1.0\n",
      "460: FEAT_1: ab3136ba FEAT_2: 832735e1 - Correlation: 0.9998637945770242\n",
      "461: FEAT_1: ab3136ba FEAT_2: Dino Dive_3110 - Correlation: 1.0\n",
      "462: FEAT_1: ab3136ba FEAT_2: Dino Dive_3010 - Correlation: 0.9998637945770242\n",
      "463: FEAT_1: 9de5e594 FEAT_2: 28a4eb9a - Correlation: 0.9995923561196808\n",
      "464: FEAT_1: 9de5e594 FEAT_2: Dino Dive_3120 - Correlation: 0.9995923561196808\n",
      "465: FEAT_1: 9de5e594 FEAT_2: Dino Dive_3020 - Correlation: 1.0\n",
      "466: FEAT_1: 022b4259 FEAT_2: Bug Measurer (Activity)_4025 - Correlation: 0.9999999999999998\n",
      "467: FEAT_1: 792530f8 FEAT_2: Dino Drink_4030 - Correlation: 1.0\n",
      "468: FEAT_1: 3393b68b FEAT_2: Bird Measurer (Assessment)_2010 - Correlation: 1.0\n",
      "469: FEAT_1: 8d748b58 FEAT_2: Bug Measurer (Activity)_4090 - Correlation: 0.9999999999999998\n",
      "470: FEAT_1: 5e812b27 FEAT_2: Sandcastle Builder (Activity)_4030 - Correlation: 1.0\n",
      "471: FEAT_1: 5e3ea25a FEAT_2: Crystals Rule_4070 - Correlation: 1.0\n",
      "472: FEAT_1: 5d042115 FEAT_2: Flower Waterer (Activity)_4030 - Correlation: 1.0\n",
      "473: FEAT_1: 92687c59 FEAT_2: Scrub-A-Dub_4090 - Correlation: 1.0\n",
      "474: FEAT_1: 15a43e5b FEAT_2: Bottle Filler (Activity)_4070 - Correlation: 1.0\n",
      "475: FEAT_1: d88ca108 FEAT_2: Air Show_2070 - Correlation: 1.0\n",
      "476: FEAT_1: 7961e599 FEAT_2: 709b1251 - Correlation: 0.9950004881933644\n",
      "477: FEAT_1: 7961e599 FEAT_2: Dino Dive_3121 - Correlation: 0.9950004881933644\n",
      "478: FEAT_1: 7961e599 FEAT_2: Dino Dive_2020 - Correlation: 0.9999999999999999\n",
      "479: FEAT_1: c7128948 FEAT_2: Mushroom Sorter (Assessment)_4040 - Correlation: 1.0\n",
      "480: FEAT_1: 884228c8 FEAT_2: Fireworks (Activity)_4070 - Correlation: 1.0\n",
      "481: FEAT_1: 6f4bd64e FEAT_2: Air Show_4090 - Correlation: 0.9999999999999998\n",
      "482: FEAT_1: fd20ea40 FEAT_2: Leaf Leader_4010 - Correlation: 0.9999999999999998\n",
      "483: FEAT_1: 2dc29e21 FEAT_2: All Star Sorting_4020 - Correlation: 1.0\n",
      "484: FEAT_1: f806dc10 FEAT_2: Dino Drink_2020 - Correlation: 1.0\n",
      "485: FEAT_1: f32856e4 FEAT_2: Leaf Leader_2020 - Correlation: 1.0\n",
      "486: FEAT_1: 67aa2ada FEAT_2: Leaf Leader_4090 - Correlation: 1.0\n",
      "487: FEAT_1: 0ce40006 FEAT_2: Happy Camel_4080 - Correlation: 1.0\n",
      "488: FEAT_1: 29f54413 FEAT_2: Leaf Leader_2060 - Correlation: 0.9999999999999998\n",
      "489: FEAT_1: a8efe47b FEAT_2: Chest Sorter (Assessment)_4030 - Correlation: 1.0\n",
      "490: FEAT_1: 3d63345e FEAT_2: Cart Balancer (Assessment)_4035 - Correlation: 1.0\n",
      "491: FEAT_1: 99abe2bb FEAT_2: Bubble Bath_2080 - Correlation: 1.0\n",
      "492: FEAT_1: ecc36b7f FEAT_2: Bubble Bath_4095 - Correlation: 1.0\n",
      "493: FEAT_1: 46cd75b4 FEAT_2: Chicken Balancer (Activity)_4022 - Correlation: 0.9999999999999998\n",
      "494: FEAT_1: 47f43a44 FEAT_2: Flower Waterer (Activity)_4090 - Correlation: 1.0\n",
      "495: FEAT_1: 7dfe6d8a FEAT_2: Leaf Leader_4070 - Correlation: 0.9999999999999998\n",
      "496: FEAT_1: 86ba578b FEAT_2: Leaf Leader_2070 - Correlation: 1.0\n",
      "497: FEAT_1: e3ff61fb FEAT_2: Dino Dive_3021 - Correlation: 1.0\n",
      "498: FEAT_1: cb1178ad FEAT_2: Chest Sorter (Assessment)_4090 - Correlation: 1.0\n",
      "499: FEAT_1: 2230fab4 FEAT_2: 0330ab6a - Correlation: 0.9998673365188064\n",
      "500: FEAT_1: 2230fab4 FEAT_2: Chow Time_3020 - Correlation: 0.9998673365188064\n",
      "501: FEAT_1: 2230fab4 FEAT_2: Chow Time_3120 - Correlation: 0.9999999999999999\n",
      "502: FEAT_1: 37ee8496 FEAT_2: 30614231 - Correlation: 0.9967763987631819\n",
      "503: FEAT_1: 37ee8496 FEAT_2: Cauldron Filler (Assessment)_4030 - Correlation: 1.0\n",
      "504: FEAT_1: 37ee8496 FEAT_2: Cauldron Filler (Assessment)_4020 - Correlation: 0.9967763987631819\n",
      "505: FEAT_1: c58186bf FEAT_2: Sandcastle Builder (Activity)_4035 - Correlation: 1.0\n",
      "506: FEAT_1: 2c4e6db0 FEAT_2: All Star Sorting_2020 - Correlation: 1.0\n",
      "507: FEAT_1: 9ed8f6da FEAT_2: Dino Drink_2075 - Correlation: 0.9999999999999999\n",
      "508: FEAT_1: 76babcde FEAT_2: Dino Dive_4070 - Correlation: 1.0\n",
      "509: FEAT_1: 13f56524 FEAT_2: Mushroom Sorter (Assessment)_4080 - Correlation: 1.0\n",
      "510: FEAT_1: 37db1c2f FEAT_2: Happy Camel_4045 - Correlation: 1.0\n",
      "511: FEAT_1: 070a5291 FEAT_2: Bird Measurer (Assessment)_4100 - Correlation: 1.0\n",
      "512: FEAT_1: d185d3ea FEAT_2: Chow Time_4035 - Correlation: 1.0\n",
      "513: FEAT_1: 26a5a3dd FEAT_2: All Star Sorting_4080 - Correlation: 1.0\n",
      "514: FEAT_1: a5e9da97 FEAT_2: Pan Balance_4100 - Correlation: 1.0\n",
      "515: FEAT_1: 5f0eb72c FEAT_2: Mushroom Sorter (Assessment)_4020 - Correlation: 0.9999999999999998\n",
      "516: FEAT_1: 8fee50e2 FEAT_2: Bird Measurer (Assessment)_4020 - Correlation: 1.0\n",
      "517: FEAT_1: cdd22e43 FEAT_2: Chicken Balancer (Activity)_4035 - Correlation: 1.0\n",
      "518: FEAT_1: eb2c19cd FEAT_2: Mushroom Sorter (Assessment)_4090 - Correlation: 1.0\n",
      "519: FEAT_1: f6947f54 FEAT_2: Bird Measurer (Assessment)_2030 - Correlation: 1.0\n",
      "520: FEAT_1: 3edf6747 FEAT_2: Cauldron Filler (Assessment)_4035 - Correlation: 0.9999999999999999\n",
      "521: FEAT_1: 1beb320a FEAT_2: Bubble Bath_2020 - Correlation: 1.0\n",
      "522: FEAT_1: 91561152 FEAT_2: Cauldron Filler (Assessment)_4025 - Correlation: 1.0\n",
      "523: FEAT_1: fcfdffb6 FEAT_2: Flower Waterer (Activity)_4022 - Correlation: 1.0\n",
      "524: FEAT_1: bcceccc6 FEAT_2: Air Show_4070 - Correlation: 1.0\n",
      "525: FEAT_1: 7d5c30a2 FEAT_2: Dino Dive_2060 - Correlation: 1.0\n",
      "526: FEAT_1: 3110 FEAT_2: 3010 - Correlation: 0.9999293402893735\n",
      "527: FEAT_1: 3120 FEAT_2: 3020 - Correlation: 0.9998761417908972\n",
      "528: FEAT_1: 3121 FEAT_2: 3021 - Correlation: 0.9999098200487934\n",
      "529: FEAT_1: 2020 FEAT_2: 2030 - Correlation: 0.9959933262816534\n",
      "530: FEAT_1: var_event_id FEAT_2: var_title_event_code - Correlation: 0.9995254184300616\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "to_remove = []\n",
    "for feat_1 in features:\n",
    "    for feat_2 in features:\n",
    "        if feat_1 != feat_2 and feat_1 not in to_remove and feat_2 not in to_remove:\n",
    "            corr = np.corrcoef(train_en[feat_1], train_en[feat_2])[0][1]\n",
    "            if corr > 0.995:\n",
    "                counter += 1\n",
    "                to_remove.append(feat_2)\n",
    "                print('{}: FEAT_1: {} FEAT_2: {} - Correlation: {}'.format(counter, feat_1, feat_2, corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_en['accuracy_group']\n",
    "X = train_en.drop(columns=(to_remove + ['accuracy_group', 'title']), axis=1)\n",
    "test_predict = test_en.drop(columns=(to_remove + ['accuracy_group', 'installation_id', 'title']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "@jit\n",
    "def qwk(a1, a2):\n",
    "    \"\"\"\n",
    "    Source: https://www.kaggle.com/c/data-science-bowl-2019/discussion/114133#latest-660168\n",
    "\n",
    "    :param a1:\n",
    "    :param a2:\n",
    "    :param max_rat:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    max_rat = 3\n",
    "    a1 = np.asarray(a1, dtype=int)\n",
    "    a2 = np.asarray(a2, dtype=int)\n",
    "\n",
    "    hist1 = np.zeros((max_rat + 1, ))\n",
    "    hist2 = np.zeros((max_rat + 1, ))\n",
    "\n",
    "    o = 0\n",
    "    for k in range(a1.shape[0]):\n",
    "        i, j = a1[k], a2[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        o +=  (i - j) * (i - j)\n",
    "\n",
    "    e = 0\n",
    "    for i in range(max_rat + 1):\n",
    "        for j in range(max_rat + 1):\n",
    "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "\n",
    "    e = e / a1.shape[0]\n",
    "\n",
    "    return 1 - o / e\n",
    "\n",
    "\n",
    "def eval_qwk_lgb(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred = y_pred.reshape(len(np.unique(y_true)), -1).argmax(axis=0)\n",
    "    return 'cappa', qwk(y_true, y_pred), True\n",
    "\n",
    "\n",
    "def eval_qwk_lgb_regr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "    y_pred[y_pred <= 1.07765539] = 0\n",
    "    y_pred[np.where(np.logical_and(y_pred > 1.07765539, y_pred <= 1.76235851))] = 1\n",
    "    y_pred[np.where(np.logical_and(y_pred > 1.76235851, y_pred <= 2.24528698))] = 2\n",
    "    y_pred[y_pred > 2.24528698] = 3\n",
    "    # y_pred = y_pred.reshape(len(np.unique(y_true)), -1).argmax(axis=0)\n",
    "    return 'cappa', qwk(y_true, y_pred), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 2000,\n",
    "          'boostin_type': 'gdbt',\n",
    "          'objective': 'regression',\n",
    "          'metric': 'rmse',\n",
    "          'subsample': 0.75,\n",
    "          'subsample': 1,\n",
    "          'learning': 0.04,\n",
    "          'feature_fraction': 0.9,\n",
    "          'max_depth': 15,\n",
    "          'lambda_l1': 1,\n",
    "          'lambda_l2': 1,\n",
    "          #'verbose': 500,\n",
    "          'early_stopping_rounds': 100,\n",
    "          'eval_metric': 'cappa'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n",
      "[1]\ttraining's rmse: 1.21387\ttraining's cappa: 0.204674\tvalid_1's rmse: 1.21702\tvalid_1's cappa: 0.230616\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's rmse: 1.17765\ttraining's cappa: 0.308179\tvalid_1's rmse: 1.18188\tvalid_1's cappa: 0.325176\n",
      "[3]\ttraining's rmse: 1.14728\ttraining's cappa: 0.328405\tvalid_1's rmse: 1.15209\tvalid_1's cappa: 0.340008\n",
      "[4]\ttraining's rmse: 1.12143\ttraining's cappa: 0.337484\tvalid_1's rmse: 1.12674\tvalid_1's cappa: 0.344512\n",
      "[5]\ttraining's rmse: 1.09939\ttraining's cappa: 0.34796\tvalid_1's rmse: 1.10664\tvalid_1's cappa: 0.349442\n",
      "[6]\ttraining's rmse: 1.07961\ttraining's cappa: 0.351975\tvalid_1's rmse: 1.08692\tvalid_1's cappa: 0.348807\n",
      "[7]\ttraining's rmse: 1.06294\ttraining's cappa: 0.418126\tvalid_1's rmse: 1.07284\tvalid_1's cappa: 0.40325\n",
      "[8]\ttraining's rmse: 1.04804\ttraining's cappa: 0.526664\tvalid_1's rmse: 1.05889\tvalid_1's cappa: 0.497801\n",
      "[9]\ttraining's rmse: 1.03533\ttraining's cappa: 0.56433\tvalid_1's rmse: 1.04728\tvalid_1's cappa: 0.54074\n",
      "[10]\ttraining's rmse: 1.02436\ttraining's cappa: 0.583224\tvalid_1's rmse: 1.03753\tvalid_1's cappa: 0.559901\n",
      "[11]\ttraining's rmse: 1.01453\ttraining's cappa: 0.598213\tvalid_1's rmse: 1.02989\tvalid_1's cappa: 0.569812\n",
      "[12]\ttraining's rmse: 1.00506\ttraining's cappa: 0.609987\tvalid_1's rmse: 1.02204\tvalid_1's cappa: 0.577096\n",
      "[13]\ttraining's rmse: 0.996505\ttraining's cappa: 0.618088\tvalid_1's rmse: 1.01518\tvalid_1's cappa: 0.585298\n",
      "[14]\ttraining's rmse: 0.989526\ttraining's cappa: 0.623463\tvalid_1's rmse: 1.01031\tvalid_1's cappa: 0.590353\n",
      "[15]\ttraining's rmse: 0.982696\ttraining's cappa: 0.626922\tvalid_1's rmse: 1.00564\tvalid_1's cappa: 0.589277\n",
      "[16]\ttraining's rmse: 0.9769\ttraining's cappa: 0.630041\tvalid_1's rmse: 1.00165\tvalid_1's cappa: 0.59749\n",
      "[17]\ttraining's rmse: 0.970938\ttraining's cappa: 0.635281\tvalid_1's rmse: 0.997442\tvalid_1's cappa: 0.596558\n",
      "[18]\ttraining's rmse: 0.965489\ttraining's cappa: 0.638281\tvalid_1's rmse: 0.993892\tvalid_1's cappa: 0.598449\n",
      "[19]\ttraining's rmse: 0.960924\ttraining's cappa: 0.639979\tvalid_1's rmse: 0.99237\tvalid_1's cappa: 0.598734\n",
      "[20]\ttraining's rmse: 0.956744\ttraining's cappa: 0.641812\tvalid_1's rmse: 0.990557\tvalid_1's cappa: 0.601551\n",
      "[21]\ttraining's rmse: 0.952864\ttraining's cappa: 0.64549\tvalid_1's rmse: 0.98878\tvalid_1's cappa: 0.603426\n",
      "[22]\ttraining's rmse: 0.948673\ttraining's cappa: 0.649144\tvalid_1's rmse: 0.986741\tvalid_1's cappa: 0.604223\n",
      "[23]\ttraining's rmse: 0.944973\ttraining's cappa: 0.649929\tvalid_1's rmse: 0.984457\tvalid_1's cappa: 0.60588\n",
      "[24]\ttraining's rmse: 0.941567\ttraining's cappa: 0.652224\tvalid_1's rmse: 0.982138\tvalid_1's cappa: 0.607637\n",
      "[25]\ttraining's rmse: 0.93823\ttraining's cappa: 0.655207\tvalid_1's rmse: 0.980287\tvalid_1's cappa: 0.611193\n",
      "[26]\ttraining's rmse: 0.935192\ttraining's cappa: 0.657316\tvalid_1's rmse: 0.978948\tvalid_1's cappa: 0.611204\n",
      "[27]\ttraining's rmse: 0.93257\ttraining's cappa: 0.659963\tvalid_1's rmse: 0.977617\tvalid_1's cappa: 0.610405\n",
      "[28]\ttraining's rmse: 0.929753\ttraining's cappa: 0.660427\tvalid_1's rmse: 0.976507\tvalid_1's cappa: 0.613486\n",
      "[29]\ttraining's rmse: 0.926921\ttraining's cappa: 0.663144\tvalid_1's rmse: 0.975625\tvalid_1's cappa: 0.614938\n",
      "[30]\ttraining's rmse: 0.923934\ttraining's cappa: 0.664986\tvalid_1's rmse: 0.974569\tvalid_1's cappa: 0.616272\n",
      "[31]\ttraining's rmse: 0.921109\ttraining's cappa: 0.667517\tvalid_1's rmse: 0.97281\tvalid_1's cappa: 0.61876\n",
      "[32]\ttraining's rmse: 0.918308\ttraining's cappa: 0.669485\tvalid_1's rmse: 0.971716\tvalid_1's cappa: 0.619695\n",
      "[33]\ttraining's rmse: 0.915806\ttraining's cappa: 0.671748\tvalid_1's rmse: 0.970753\tvalid_1's cappa: 0.620003\n",
      "[34]\ttraining's rmse: 0.91316\ttraining's cappa: 0.673592\tvalid_1's rmse: 0.970118\tvalid_1's cappa: 0.618886\n",
      "[35]\ttraining's rmse: 0.910628\ttraining's cappa: 0.675813\tvalid_1's rmse: 0.968995\tvalid_1's cappa: 0.62002\n",
      "[36]\ttraining's rmse: 0.908158\ttraining's cappa: 0.677687\tvalid_1's rmse: 0.968258\tvalid_1's cappa: 0.620121\n",
      "[37]\ttraining's rmse: 0.905941\ttraining's cappa: 0.679068\tvalid_1's rmse: 0.968128\tvalid_1's cappa: 0.620588\n",
      "[38]\ttraining's rmse: 0.903671\ttraining's cappa: 0.681544\tvalid_1's rmse: 0.967428\tvalid_1's cappa: 0.619831\n",
      "[39]\ttraining's rmse: 0.901345\ttraining's cappa: 0.683126\tvalid_1's rmse: 0.967052\tvalid_1's cappa: 0.621383\n",
      "[40]\ttraining's rmse: 0.89924\ttraining's cappa: 0.684602\tvalid_1's rmse: 0.966661\tvalid_1's cappa: 0.620674\n",
      "[41]\ttraining's rmse: 0.897171\ttraining's cappa: 0.686676\tvalid_1's rmse: 0.966503\tvalid_1's cappa: 0.620064\n",
      "[42]\ttraining's rmse: 0.895028\ttraining's cappa: 0.688506\tvalid_1's rmse: 0.966263\tvalid_1's cappa: 0.619916\n",
      "[43]\ttraining's rmse: 0.892867\ttraining's cappa: 0.689758\tvalid_1's rmse: 0.965587\tvalid_1's cappa: 0.620304\n",
      "[44]\ttraining's rmse: 0.890875\ttraining's cappa: 0.691192\tvalid_1's rmse: 0.965127\tvalid_1's cappa: 0.618967\n",
      "[45]\ttraining's rmse: 0.888856\ttraining's cappa: 0.692303\tvalid_1's rmse: 0.964679\tvalid_1's cappa: 0.621128\n",
      "[46]\ttraining's rmse: 0.887057\ttraining's cappa: 0.693667\tvalid_1's rmse: 0.963942\tvalid_1's cappa: 0.620786\n",
      "[47]\ttraining's rmse: 0.885077\ttraining's cappa: 0.696508\tvalid_1's rmse: 0.963212\tvalid_1's cappa: 0.622468\n",
      "[48]\ttraining's rmse: 0.883148\ttraining's cappa: 0.697624\tvalid_1's rmse: 0.963027\tvalid_1's cappa: 0.624447\n",
      "[49]\ttraining's rmse: 0.881445\ttraining's cappa: 0.699297\tvalid_1's rmse: 0.962533\tvalid_1's cappa: 0.624392\n",
      "[50]\ttraining's rmse: 0.880011\ttraining's cappa: 0.699945\tvalid_1's rmse: 0.962546\tvalid_1's cappa: 0.625294\n",
      "[51]\ttraining's rmse: 0.878146\ttraining's cappa: 0.700621\tvalid_1's rmse: 0.962397\tvalid_1's cappa: 0.625759\n",
      "[52]\ttraining's rmse: 0.876622\ttraining's cappa: 0.701693\tvalid_1's rmse: 0.962229\tvalid_1's cappa: 0.625378\n",
      "[53]\ttraining's rmse: 0.874891\ttraining's cappa: 0.70306\tvalid_1's rmse: 0.961863\tvalid_1's cappa: 0.626579\n",
      "[54]\ttraining's rmse: 0.873087\ttraining's cappa: 0.705264\tvalid_1's rmse: 0.961985\tvalid_1's cappa: 0.626441\n",
      "[55]\ttraining's rmse: 0.87129\ttraining's cappa: 0.708045\tvalid_1's rmse: 0.961796\tvalid_1's cappa: 0.625171\n",
      "[56]\ttraining's rmse: 0.869577\ttraining's cappa: 0.708875\tvalid_1's rmse: 0.961814\tvalid_1's cappa: 0.625147\n",
      "[57]\ttraining's rmse: 0.868073\ttraining's cappa: 0.709729\tvalid_1's rmse: 0.961561\tvalid_1's cappa: 0.6241\n",
      "[58]\ttraining's rmse: 0.866367\ttraining's cappa: 0.710981\tvalid_1's rmse: 0.961415\tvalid_1's cappa: 0.621935\n",
      "[59]\ttraining's rmse: 0.86475\ttraining's cappa: 0.713769\tvalid_1's rmse: 0.961279\tvalid_1's cappa: 0.622383\n",
      "[60]\ttraining's rmse: 0.863133\ttraining's cappa: 0.715116\tvalid_1's rmse: 0.961529\tvalid_1's cappa: 0.622762\n",
      "[61]\ttraining's rmse: 0.861583\ttraining's cappa: 0.716689\tvalid_1's rmse: 0.961282\tvalid_1's cappa: 0.623281\n",
      "[62]\ttraining's rmse: 0.860176\ttraining's cappa: 0.717357\tvalid_1's rmse: 0.96134\tvalid_1's cappa: 0.625782\n",
      "[63]\ttraining's rmse: 0.858723\ttraining's cappa: 0.718068\tvalid_1's rmse: 0.961278\tvalid_1's cappa: 0.625319\n",
      "[64]\ttraining's rmse: 0.857249\ttraining's cappa: 0.720116\tvalid_1's rmse: 0.961301\tvalid_1's cappa: 0.62621\n",
      "[65]\ttraining's rmse: 0.855903\ttraining's cappa: 0.720671\tvalid_1's rmse: 0.960972\tvalid_1's cappa: 0.626253\n",
      "[66]\ttraining's rmse: 0.854568\ttraining's cappa: 0.722455\tvalid_1's rmse: 0.961243\tvalid_1's cappa: 0.625282\n",
      "[67]\ttraining's rmse: 0.853255\ttraining's cappa: 0.723554\tvalid_1's rmse: 0.961036\tvalid_1's cappa: 0.62651\n",
      "[68]\ttraining's rmse: 0.85192\ttraining's cappa: 0.724823\tvalid_1's rmse: 0.961087\tvalid_1's cappa: 0.6252\n",
      "[69]\ttraining's rmse: 0.850473\ttraining's cappa: 0.725797\tvalid_1's rmse: 0.960604\tvalid_1's cappa: 0.625406\n",
      "[70]\ttraining's rmse: 0.848707\ttraining's cappa: 0.727168\tvalid_1's rmse: 0.960967\tvalid_1's cappa: 0.624834\n",
      "[71]\ttraining's rmse: 0.847135\ttraining's cappa: 0.728444\tvalid_1's rmse: 0.96064\tvalid_1's cappa: 0.62582\n",
      "[72]\ttraining's rmse: 0.845989\ttraining's cappa: 0.729229\tvalid_1's rmse: 0.960779\tvalid_1's cappa: 0.624967\n",
      "[73]\ttraining's rmse: 0.844333\ttraining's cappa: 0.730155\tvalid_1's rmse: 0.960942\tvalid_1's cappa: 0.624685\n",
      "[74]\ttraining's rmse: 0.842865\ttraining's cappa: 0.731277\tvalid_1's rmse: 0.960637\tvalid_1's cappa: 0.62554\n",
      "[75]\ttraining's rmse: 0.841477\ttraining's cappa: 0.732268\tvalid_1's rmse: 0.960948\tvalid_1's cappa: 0.626008\n",
      "[76]\ttraining's rmse: 0.840308\ttraining's cappa: 0.732782\tvalid_1's rmse: 0.961174\tvalid_1's cappa: 0.626035\n",
      "[77]\ttraining's rmse: 0.83909\ttraining's cappa: 0.734118\tvalid_1's rmse: 0.961116\tvalid_1's cappa: 0.625635\n",
      "[78]\ttraining's rmse: 0.837778\ttraining's cappa: 0.736048\tvalid_1's rmse: 0.961233\tvalid_1's cappa: 0.625757\n",
      "[79]\ttraining's rmse: 0.83629\ttraining's cappa: 0.73673\tvalid_1's rmse: 0.961242\tvalid_1's cappa: 0.622395\n",
      "[80]\ttraining's rmse: 0.834932\ttraining's cappa: 0.738202\tvalid_1's rmse: 0.961204\tvalid_1's cappa: 0.623442\n",
      "[81]\ttraining's rmse: 0.833737\ttraining's cappa: 0.738988\tvalid_1's rmse: 0.961263\tvalid_1's cappa: 0.622837\n",
      "[82]\ttraining's rmse: 0.832365\ttraining's cappa: 0.739907\tvalid_1's rmse: 0.961322\tvalid_1's cappa: 0.62378\n",
      "[83]\ttraining's rmse: 0.831233\ttraining's cappa: 0.740521\tvalid_1's rmse: 0.96142\tvalid_1's cappa: 0.623873\n",
      "[84]\ttraining's rmse: 0.830234\ttraining's cappa: 0.741586\tvalid_1's rmse: 0.96081\tvalid_1's cappa: 0.624264\n",
      "[85]\ttraining's rmse: 0.829193\ttraining's cappa: 0.742394\tvalid_1's rmse: 0.960988\tvalid_1's cappa: 0.623887\n",
      "[86]\ttraining's rmse: 0.82792\ttraining's cappa: 0.743475\tvalid_1's rmse: 0.96104\tvalid_1's cappa: 0.621027\n",
      "[87]\ttraining's rmse: 0.826465\ttraining's cappa: 0.74467\tvalid_1's rmse: 0.960813\tvalid_1's cappa: 0.622896\n",
      "[88]\ttraining's rmse: 0.825284\ttraining's cappa: 0.745674\tvalid_1's rmse: 0.960742\tvalid_1's cappa: 0.623046\n",
      "[89]\ttraining's rmse: 0.824041\ttraining's cappa: 0.746953\tvalid_1's rmse: 0.960601\tvalid_1's cappa: 0.623374\n",
      "[90]\ttraining's rmse: 0.822898\ttraining's cappa: 0.747624\tvalid_1's rmse: 0.960881\tvalid_1's cappa: 0.622924\n",
      "[91]\ttraining's rmse: 0.821686\ttraining's cappa: 0.748505\tvalid_1's rmse: 0.960955\tvalid_1's cappa: 0.62246\n",
      "[92]\ttraining's rmse: 0.820297\ttraining's cappa: 0.749403\tvalid_1's rmse: 0.960991\tvalid_1's cappa: 0.622026\n",
      "[93]\ttraining's rmse: 0.818922\ttraining's cappa: 0.750274\tvalid_1's rmse: 0.960673\tvalid_1's cappa: 0.623083\n",
      "[94]\ttraining's rmse: 0.818106\ttraining's cappa: 0.750375\tvalid_1's rmse: 0.961518\tvalid_1's cappa: 0.622482\n",
      "[95]\ttraining's rmse: 0.81682\ttraining's cappa: 0.750802\tvalid_1's rmse: 0.961335\tvalid_1's cappa: 0.622439\n",
      "[96]\ttraining's rmse: 0.815516\ttraining's cappa: 0.751808\tvalid_1's rmse: 0.961135\tvalid_1's cappa: 0.622802\n",
      "[97]\ttraining's rmse: 0.814344\ttraining's cappa: 0.753592\tvalid_1's rmse: 0.96115\tvalid_1's cappa: 0.62312\n",
      "[98]\ttraining's rmse: 0.813065\ttraining's cappa: 0.754461\tvalid_1's rmse: 0.961468\tvalid_1's cappa: 0.621505\n",
      "[99]\ttraining's rmse: 0.812\ttraining's cappa: 0.755481\tvalid_1's rmse: 0.961682\tvalid_1's cappa: 0.622783\n",
      "[100]\ttraining's rmse: 0.811216\ttraining's cappa: 0.755661\tvalid_1's rmse: 0.961401\tvalid_1's cappa: 0.622992\n",
      "[101]\ttraining's rmse: 0.810144\ttraining's cappa: 0.756369\tvalid_1's rmse: 0.96148\tvalid_1's cappa: 0.622927\n",
      "[102]\ttraining's rmse: 0.80906\ttraining's cappa: 0.757764\tvalid_1's rmse: 0.96146\tvalid_1's cappa: 0.623105\n",
      "[103]\ttraining's rmse: 0.807917\ttraining's cappa: 0.758089\tvalid_1's rmse: 0.961875\tvalid_1's cappa: 0.621504\n",
      "[104]\ttraining's rmse: 0.807009\ttraining's cappa: 0.758714\tvalid_1's rmse: 0.962089\tvalid_1's cappa: 0.62144\n",
      "[105]\ttraining's rmse: 0.806059\ttraining's cappa: 0.759576\tvalid_1's rmse: 0.962354\tvalid_1's cappa: 0.622548\n",
      "[106]\ttraining's rmse: 0.804859\ttraining's cappa: 0.760475\tvalid_1's rmse: 0.962241\tvalid_1's cappa: 0.622884\n",
      "[107]\ttraining's rmse: 0.803855\ttraining's cappa: 0.761049\tvalid_1's rmse: 0.962529\tvalid_1's cappa: 0.622429\n",
      "[108]\ttraining's rmse: 0.802755\ttraining's cappa: 0.761807\tvalid_1's rmse: 0.962683\tvalid_1's cappa: 0.62298\n",
      "[109]\ttraining's rmse: 0.802113\ttraining's cappa: 0.762579\tvalid_1's rmse: 0.962632\tvalid_1's cappa: 0.621989\n",
      "[110]\ttraining's rmse: 0.800943\ttraining's cappa: 0.763625\tvalid_1's rmse: 0.962797\tvalid_1's cappa: 0.622648\n",
      "[111]\ttraining's rmse: 0.799576\ttraining's cappa: 0.764572\tvalid_1's rmse: 0.962926\tvalid_1's cappa: 0.621832\n",
      "[112]\ttraining's rmse: 0.798512\ttraining's cappa: 0.765457\tvalid_1's rmse: 0.962866\tvalid_1's cappa: 0.620753\n",
      "[113]\ttraining's rmse: 0.797366\ttraining's cappa: 0.767286\tvalid_1's rmse: 0.96267\tvalid_1's cappa: 0.621798\n",
      "[114]\ttraining's rmse: 0.796366\ttraining's cappa: 0.767842\tvalid_1's rmse: 0.963146\tvalid_1's cappa: 0.62241\n",
      "[115]\ttraining's rmse: 0.795159\ttraining's cappa: 0.768541\tvalid_1's rmse: 0.963477\tvalid_1's cappa: 0.621675\n",
      "[116]\ttraining's rmse: 0.793949\ttraining's cappa: 0.769586\tvalid_1's rmse: 0.963467\tvalid_1's cappa: 0.62157\n",
      "[117]\ttraining's rmse: 0.792818\ttraining's cappa: 0.770482\tvalid_1's rmse: 0.963645\tvalid_1's cappa: 0.622019\n",
      "[118]\ttraining's rmse: 0.791765\ttraining's cappa: 0.77175\tvalid_1's rmse: 0.96377\tvalid_1's cappa: 0.621069\n",
      "[119]\ttraining's rmse: 0.790583\ttraining's cappa: 0.772856\tvalid_1's rmse: 0.963903\tvalid_1's cappa: 0.620935\n",
      "[120]\ttraining's rmse: 0.7892\ttraining's cappa: 0.773697\tvalid_1's rmse: 0.963606\tvalid_1's cappa: 0.623151\n",
      "[121]\ttraining's rmse: 0.788128\ttraining's cappa: 0.774279\tvalid_1's rmse: 0.963697\tvalid_1's cappa: 0.623686\n",
      "[122]\ttraining's rmse: 0.787214\ttraining's cappa: 0.775101\tvalid_1's rmse: 0.963906\tvalid_1's cappa: 0.623367\n",
      "[123]\ttraining's rmse: 0.786083\ttraining's cappa: 0.775995\tvalid_1's rmse: 0.963709\tvalid_1's cappa: 0.623731\n",
      "[124]\ttraining's rmse: 0.785166\ttraining's cappa: 0.776458\tvalid_1's rmse: 0.964059\tvalid_1's cappa: 0.623438\n",
      "[125]\ttraining's rmse: 0.784167\ttraining's cappa: 0.777377\tvalid_1's rmse: 0.963995\tvalid_1's cappa: 0.623181\n",
      "[126]\ttraining's rmse: 0.783025\ttraining's cappa: 0.777929\tvalid_1's rmse: 0.964077\tvalid_1's cappa: 0.623973\n",
      "[127]\ttraining's rmse: 0.781878\ttraining's cappa: 0.778608\tvalid_1's rmse: 0.963729\tvalid_1's cappa: 0.624214\n",
      "[128]\ttraining's rmse: 0.780814\ttraining's cappa: 0.779717\tvalid_1's rmse: 0.963919\tvalid_1's cappa: 0.624303\n",
      "[129]\ttraining's rmse: 0.77998\ttraining's cappa: 0.779805\tvalid_1's rmse: 0.963735\tvalid_1's cappa: 0.623714\n",
      "[130]\ttraining's rmse: 0.779168\ttraining's cappa: 0.780411\tvalid_1's rmse: 0.963673\tvalid_1's cappa: 0.624495\n",
      "[131]\ttraining's rmse: 0.778029\ttraining's cappa: 0.781607\tvalid_1's rmse: 0.963627\tvalid_1's cappa: 0.623684\n",
      "[132]\ttraining's rmse: 0.77705\ttraining's cappa: 0.782143\tvalid_1's rmse: 0.963809\tvalid_1's cappa: 0.623972\n",
      "[133]\ttraining's rmse: 0.775733\ttraining's cappa: 0.783212\tvalid_1's rmse: 0.96375\tvalid_1's cappa: 0.622631\n",
      "[134]\ttraining's rmse: 0.774664\ttraining's cappa: 0.78395\tvalid_1's rmse: 0.963786\tvalid_1's cappa: 0.622201\n",
      "[135]\ttraining's rmse: 0.773891\ttraining's cappa: 0.784392\tvalid_1's rmse: 0.963913\tvalid_1's cappa: 0.621617\n",
      "[136]\ttraining's rmse: 0.772719\ttraining's cappa: 0.785562\tvalid_1's rmse: 0.96381\tvalid_1's cappa: 0.621222\n",
      "[137]\ttraining's rmse: 0.7716\ttraining's cappa: 0.786132\tvalid_1's rmse: 0.963815\tvalid_1's cappa: 0.622033\n",
      "[138]\ttraining's rmse: 0.770445\ttraining's cappa: 0.786661\tvalid_1's rmse: 0.96368\tvalid_1's cappa: 0.621965\n",
      "[139]\ttraining's rmse: 0.769373\ttraining's cappa: 0.787137\tvalid_1's rmse: 0.963654\tvalid_1's cappa: 0.622895\n",
      "[140]\ttraining's rmse: 0.768405\ttraining's cappa: 0.78795\tvalid_1's rmse: 0.963572\tvalid_1's cappa: 0.622126\n",
      "[141]\ttraining's rmse: 0.767398\ttraining's cappa: 0.788602\tvalid_1's rmse: 0.963602\tvalid_1's cappa: 0.621848\n",
      "[142]\ttraining's rmse: 0.766123\ttraining's cappa: 0.789976\tvalid_1's rmse: 0.963896\tvalid_1's cappa: 0.621023\n",
      "[143]\ttraining's rmse: 0.765141\ttraining's cappa: 0.791158\tvalid_1's rmse: 0.963691\tvalid_1's cappa: 0.620081\n",
      "[144]\ttraining's rmse: 0.76422\ttraining's cappa: 0.791574\tvalid_1's rmse: 0.963679\tvalid_1's cappa: 0.621082\n",
      "[145]\ttraining's rmse: 0.76308\ttraining's cappa: 0.791821\tvalid_1's rmse: 0.963887\tvalid_1's cappa: 0.620997\n",
      "[146]\ttraining's rmse: 0.762025\ttraining's cappa: 0.792558\tvalid_1's rmse: 0.963791\tvalid_1's cappa: 0.621144\n",
      "[147]\ttraining's rmse: 0.760947\ttraining's cappa: 0.793085\tvalid_1's rmse: 0.963489\tvalid_1's cappa: 0.621675\n",
      "[148]\ttraining's rmse: 0.759867\ttraining's cappa: 0.793904\tvalid_1's rmse: 0.963441\tvalid_1's cappa: 0.621188\n",
      "[149]\ttraining's rmse: 0.758737\ttraining's cappa: 0.794958\tvalid_1's rmse: 0.963718\tvalid_1's cappa: 0.622868\n",
      "[150]\ttraining's rmse: 0.757717\ttraining's cappa: 0.795964\tvalid_1's rmse: 0.963812\tvalid_1's cappa: 0.622563\n",
      "[151]\ttraining's rmse: 0.756812\ttraining's cappa: 0.796393\tvalid_1's rmse: 0.963552\tvalid_1's cappa: 0.623056\n",
      "[152]\ttraining's rmse: 0.755813\ttraining's cappa: 0.79691\tvalid_1's rmse: 0.963472\tvalid_1's cappa: 0.62344\n",
      "[153]\ttraining's rmse: 0.755007\ttraining's cappa: 0.797696\tvalid_1's rmse: 0.963677\tvalid_1's cappa: 0.623322\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's rmse: 0.874891\ttraining's cappa: 0.70306\tvalid_1's rmse: 0.961863\tvalid_1's cappa: 0.626579\n",
      "Fold : 1\n",
      "[1]\ttraining's rmse: 1.21277\ttraining's cappa: 0.232524\tvalid_1's rmse: 1.22301\tvalid_1's cappa: 0.214824\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's rmse: 1.17691\ttraining's cappa: 0.316991\tvalid_1's rmse: 1.18931\tvalid_1's cappa: 0.296507\n",
      "[3]\ttraining's rmse: 1.14612\ttraining's cappa: 0.32009\tvalid_1's rmse: 1.1602\tvalid_1's cappa: 0.310668\n",
      "[4]\ttraining's rmse: 1.11959\ttraining's cappa: 0.334526\tvalid_1's rmse: 1.13804\tvalid_1's cappa: 0.319081\n",
      "[5]\ttraining's rmse: 1.09757\ttraining's cappa: 0.340196\tvalid_1's rmse: 1.11754\tvalid_1's cappa: 0.330348\n",
      "[6]\ttraining's rmse: 1.07836\ttraining's cappa: 0.381723\tvalid_1's rmse: 1.10055\tvalid_1's cappa: 0.357828\n",
      "[7]\ttraining's rmse: 1.062\ttraining's cappa: 0.428503\tvalid_1's rmse: 1.08654\tvalid_1's cappa: 0.394336\n",
      "[8]\ttraining's rmse: 1.04787\ttraining's cappa: 0.527834\tvalid_1's rmse: 1.07355\tvalid_1's cappa: 0.491047\n",
      "[9]\ttraining's rmse: 1.03453\ttraining's cappa: 0.561685\tvalid_1's rmse: 1.06257\tvalid_1's cappa: 0.52126\n",
      "[10]\ttraining's rmse: 1.0226\ttraining's cappa: 0.583884\tvalid_1's rmse: 1.05253\tvalid_1's cappa: 0.532669\n",
      "[11]\ttraining's rmse: 1.01254\ttraining's cappa: 0.598655\tvalid_1's rmse: 1.04409\tvalid_1's cappa: 0.546757\n",
      "[12]\ttraining's rmse: 1.00345\ttraining's cappa: 0.610757\tvalid_1's rmse: 1.03724\tvalid_1's cappa: 0.555787\n",
      "[13]\ttraining's rmse: 0.995692\ttraining's cappa: 0.61728\tvalid_1's rmse: 1.03087\tvalid_1's cappa: 0.563928\n",
      "[14]\ttraining's rmse: 0.988477\ttraining's cappa: 0.622151\tvalid_1's rmse: 1.02556\tvalid_1's cappa: 0.564641\n",
      "[15]\ttraining's rmse: 0.982364\ttraining's cappa: 0.626352\tvalid_1's rmse: 1.02094\tvalid_1's cappa: 0.567821\n",
      "[16]\ttraining's rmse: 0.976404\ttraining's cappa: 0.630337\tvalid_1's rmse: 1.01675\tvalid_1's cappa: 0.57247\n",
      "[17]\ttraining's rmse: 0.97089\ttraining's cappa: 0.634747\tvalid_1's rmse: 1.01389\tvalid_1's cappa: 0.58154\n",
      "[18]\ttraining's rmse: 0.965798\ttraining's cappa: 0.638086\tvalid_1's rmse: 1.01061\tvalid_1's cappa: 0.587223\n",
      "[19]\ttraining's rmse: 0.960999\ttraining's cappa: 0.64218\tvalid_1's rmse: 1.00847\tvalid_1's cappa: 0.589604\n",
      "[20]\ttraining's rmse: 0.956793\ttraining's cappa: 0.643004\tvalid_1's rmse: 1.00581\tvalid_1's cappa: 0.591388\n",
      "[21]\ttraining's rmse: 0.952619\ttraining's cappa: 0.647633\tvalid_1's rmse: 1.00321\tvalid_1's cappa: 0.593821\n",
      "[22]\ttraining's rmse: 0.948874\ttraining's cappa: 0.649279\tvalid_1's rmse: 1.00183\tvalid_1's cappa: 0.593904\n",
      "[23]\ttraining's rmse: 0.945013\ttraining's cappa: 0.652133\tvalid_1's rmse: 1.00004\tvalid_1's cappa: 0.595246\n",
      "[24]\ttraining's rmse: 0.941396\ttraining's cappa: 0.654998\tvalid_1's rmse: 0.998366\tvalid_1's cappa: 0.597273\n",
      "[25]\ttraining's rmse: 0.937894\ttraining's cappa: 0.655895\tvalid_1's rmse: 0.996759\tvalid_1's cappa: 0.599706\n",
      "[26]\ttraining's rmse: 0.934973\ttraining's cappa: 0.657821\tvalid_1's rmse: 0.995527\tvalid_1's cappa: 0.598774\n",
      "[27]\ttraining's rmse: 0.93179\ttraining's cappa: 0.660446\tvalid_1's rmse: 0.99418\tvalid_1's cappa: 0.598654\n",
      "[28]\ttraining's rmse: 0.928941\ttraining's cappa: 0.662128\tvalid_1's rmse: 0.993113\tvalid_1's cappa: 0.601801\n",
      "[29]\ttraining's rmse: 0.925891\ttraining's cappa: 0.664414\tvalid_1's rmse: 0.991734\tvalid_1's cappa: 0.602685\n",
      "[30]\ttraining's rmse: 0.92295\ttraining's cappa: 0.666057\tvalid_1's rmse: 0.990756\tvalid_1's cappa: 0.602833\n",
      "[31]\ttraining's rmse: 0.920209\ttraining's cappa: 0.668293\tvalid_1's rmse: 0.988955\tvalid_1's cappa: 0.604862\n",
      "[32]\ttraining's rmse: 0.917547\ttraining's cappa: 0.669694\tvalid_1's rmse: 0.98806\tvalid_1's cappa: 0.606209\n",
      "[33]\ttraining's rmse: 0.914968\ttraining's cappa: 0.671275\tvalid_1's rmse: 0.987666\tvalid_1's cappa: 0.606653\n",
      "[34]\ttraining's rmse: 0.912486\ttraining's cappa: 0.673481\tvalid_1's rmse: 0.987022\tvalid_1's cappa: 0.609146\n",
      "[35]\ttraining's rmse: 0.909768\ttraining's cappa: 0.676357\tvalid_1's rmse: 0.985966\tvalid_1's cappa: 0.610825\n",
      "[36]\ttraining's rmse: 0.907147\ttraining's cappa: 0.67848\tvalid_1's rmse: 0.984529\tvalid_1's cappa: 0.608748\n",
      "[37]\ttraining's rmse: 0.905243\ttraining's cappa: 0.680487\tvalid_1's rmse: 0.98434\tvalid_1's cappa: 0.610991\n",
      "[38]\ttraining's rmse: 0.902806\ttraining's cappa: 0.683115\tvalid_1's rmse: 0.983753\tvalid_1's cappa: 0.61207\n",
      "[39]\ttraining's rmse: 0.900379\ttraining's cappa: 0.684887\tvalid_1's rmse: 0.982677\tvalid_1's cappa: 0.613461\n",
      "[40]\ttraining's rmse: 0.89826\ttraining's cappa: 0.686684\tvalid_1's rmse: 0.982173\tvalid_1's cappa: 0.61467\n",
      "[41]\ttraining's rmse: 0.896196\ttraining's cappa: 0.688214\tvalid_1's rmse: 0.982106\tvalid_1's cappa: 0.612151\n",
      "[42]\ttraining's rmse: 0.89414\ttraining's cappa: 0.690045\tvalid_1's rmse: 0.981015\tvalid_1's cappa: 0.611912\n",
      "[43]\ttraining's rmse: 0.892212\ttraining's cappa: 0.691274\tvalid_1's rmse: 0.980998\tvalid_1's cappa: 0.612607\n",
      "[44]\ttraining's rmse: 0.890262\ttraining's cappa: 0.692253\tvalid_1's rmse: 0.98062\tvalid_1's cappa: 0.610638\n",
      "[45]\ttraining's rmse: 0.888364\ttraining's cappa: 0.693789\tvalid_1's rmse: 0.980382\tvalid_1's cappa: 0.613288\n",
      "[46]\ttraining's rmse: 0.886478\ttraining's cappa: 0.695712\tvalid_1's rmse: 0.980062\tvalid_1's cappa: 0.613256\n",
      "[47]\ttraining's rmse: 0.884401\ttraining's cappa: 0.697628\tvalid_1's rmse: 0.980248\tvalid_1's cappa: 0.613105\n",
      "[48]\ttraining's rmse: 0.882488\ttraining's cappa: 0.698269\tvalid_1's rmse: 0.980321\tvalid_1's cappa: 0.613377\n",
      "[49]\ttraining's rmse: 0.880815\ttraining's cappa: 0.700314\tvalid_1's rmse: 0.979922\tvalid_1's cappa: 0.612549\n",
      "[50]\ttraining's rmse: 0.87898\ttraining's cappa: 0.701565\tvalid_1's rmse: 0.979448\tvalid_1's cappa: 0.61549\n",
      "[51]\ttraining's rmse: 0.877074\ttraining's cappa: 0.702729\tvalid_1's rmse: 0.97904\tvalid_1's cappa: 0.615791\n",
      "[52]\ttraining's rmse: 0.875289\ttraining's cappa: 0.703827\tvalid_1's rmse: 0.978949\tvalid_1's cappa: 0.616805\n",
      "[53]\ttraining's rmse: 0.87362\ttraining's cappa: 0.705809\tvalid_1's rmse: 0.979499\tvalid_1's cappa: 0.615528\n",
      "[54]\ttraining's rmse: 0.871948\ttraining's cappa: 0.707635\tvalid_1's rmse: 0.979065\tvalid_1's cappa: 0.615016\n",
      "[55]\ttraining's rmse: 0.870429\ttraining's cappa: 0.708844\tvalid_1's rmse: 0.979238\tvalid_1's cappa: 0.614287\n",
      "[56]\ttraining's rmse: 0.868744\ttraining's cappa: 0.710126\tvalid_1's rmse: 0.978695\tvalid_1's cappa: 0.61394\n",
      "[57]\ttraining's rmse: 0.867121\ttraining's cappa: 0.712457\tvalid_1's rmse: 0.978566\tvalid_1's cappa: 0.613592\n",
      "[58]\ttraining's rmse: 0.865488\ttraining's cappa: 0.713977\tvalid_1's rmse: 0.978705\tvalid_1's cappa: 0.613911\n",
      "[59]\ttraining's rmse: 0.863899\ttraining's cappa: 0.714789\tvalid_1's rmse: 0.978392\tvalid_1's cappa: 0.615256\n",
      "[60]\ttraining's rmse: 0.862358\ttraining's cappa: 0.71563\tvalid_1's rmse: 0.979002\tvalid_1's cappa: 0.613828\n",
      "[61]\ttraining's rmse: 0.860684\ttraining's cappa: 0.717523\tvalid_1's rmse: 0.978849\tvalid_1's cappa: 0.613406\n",
      "[62]\ttraining's rmse: 0.858968\ttraining's cappa: 0.718915\tvalid_1's rmse: 0.978674\tvalid_1's cappa: 0.613164\n",
      "[63]\ttraining's rmse: 0.857481\ttraining's cappa: 0.719843\tvalid_1's rmse: 0.978485\tvalid_1's cappa: 0.614323\n",
      "[64]\ttraining's rmse: 0.855999\ttraining's cappa: 0.720627\tvalid_1's rmse: 0.978038\tvalid_1's cappa: 0.614354\n",
      "[65]\ttraining's rmse: 0.854293\ttraining's cappa: 0.72172\tvalid_1's rmse: 0.978087\tvalid_1's cappa: 0.616533\n",
      "[66]\ttraining's rmse: 0.852876\ttraining's cappa: 0.722913\tvalid_1's rmse: 0.978434\tvalid_1's cappa: 0.616585\n",
      "[67]\ttraining's rmse: 0.851209\ttraining's cappa: 0.72394\tvalid_1's rmse: 0.978284\tvalid_1's cappa: 0.615301\n",
      "[68]\ttraining's rmse: 0.84995\ttraining's cappa: 0.725088\tvalid_1's rmse: 0.978666\tvalid_1's cappa: 0.614475\n",
      "[69]\ttraining's rmse: 0.848413\ttraining's cappa: 0.726379\tvalid_1's rmse: 0.978633\tvalid_1's cappa: 0.614002\n",
      "[70]\ttraining's rmse: 0.847149\ttraining's cappa: 0.727502\tvalid_1's rmse: 0.978789\tvalid_1's cappa: 0.614294\n",
      "[71]\ttraining's rmse: 0.845668\ttraining's cappa: 0.729065\tvalid_1's rmse: 0.978879\tvalid_1's cappa: 0.612709\n",
      "[72]\ttraining's rmse: 0.844444\ttraining's cappa: 0.730161\tvalid_1's rmse: 0.978655\tvalid_1's cappa: 0.61147\n",
      "[73]\ttraining's rmse: 0.842884\ttraining's cappa: 0.731032\tvalid_1's rmse: 0.978768\tvalid_1's cappa: 0.612318\n",
      "[74]\ttraining's rmse: 0.841498\ttraining's cappa: 0.732359\tvalid_1's rmse: 0.979218\tvalid_1's cappa: 0.611188\n",
      "[75]\ttraining's rmse: 0.840347\ttraining's cappa: 0.733784\tvalid_1's rmse: 0.979286\tvalid_1's cappa: 0.612456\n",
      "[76]\ttraining's rmse: 0.83897\ttraining's cappa: 0.73503\tvalid_1's rmse: 0.979162\tvalid_1's cappa: 0.611613\n",
      "[77]\ttraining's rmse: 0.837606\ttraining's cappa: 0.736282\tvalid_1's rmse: 0.979105\tvalid_1's cappa: 0.610712\n",
      "[78]\ttraining's rmse: 0.836349\ttraining's cappa: 0.736772\tvalid_1's rmse: 0.978917\tvalid_1's cappa: 0.611385\n",
      "[79]\ttraining's rmse: 0.835084\ttraining's cappa: 0.737631\tvalid_1's rmse: 0.978807\tvalid_1's cappa: 0.612703\n",
      "[80]\ttraining's rmse: 0.833819\ttraining's cappa: 0.738971\tvalid_1's rmse: 0.978652\tvalid_1's cappa: 0.612825\n",
      "[81]\ttraining's rmse: 0.832286\ttraining's cappa: 0.740484\tvalid_1's rmse: 0.978881\tvalid_1's cappa: 0.612576\n",
      "[82]\ttraining's rmse: 0.830884\ttraining's cappa: 0.741358\tvalid_1's rmse: 0.978778\tvalid_1's cappa: 0.613431\n",
      "[83]\ttraining's rmse: 0.829856\ttraining's cappa: 0.742204\tvalid_1's rmse: 0.978688\tvalid_1's cappa: 0.613049\n",
      "[84]\ttraining's rmse: 0.828186\ttraining's cappa: 0.743761\tvalid_1's rmse: 0.978398\tvalid_1's cappa: 0.613886\n",
      "[85]\ttraining's rmse: 0.826854\ttraining's cappa: 0.743989\tvalid_1's rmse: 0.978232\tvalid_1's cappa: 0.614736\n",
      "[86]\ttraining's rmse: 0.825818\ttraining's cappa: 0.745275\tvalid_1's rmse: 0.977915\tvalid_1's cappa: 0.61454\n",
      "[87]\ttraining's rmse: 0.824403\ttraining's cappa: 0.746287\tvalid_1's rmse: 0.977744\tvalid_1's cappa: 0.615285\n",
      "[88]\ttraining's rmse: 0.822972\ttraining's cappa: 0.747538\tvalid_1's rmse: 0.977782\tvalid_1's cappa: 0.615923\n",
      "[89]\ttraining's rmse: 0.821863\ttraining's cappa: 0.748059\tvalid_1's rmse: 0.977952\tvalid_1's cappa: 0.614459\n",
      "[90]\ttraining's rmse: 0.820612\ttraining's cappa: 0.748966\tvalid_1's rmse: 0.978001\tvalid_1's cappa: 0.615765\n",
      "[91]\ttraining's rmse: 0.819204\ttraining's cappa: 0.749879\tvalid_1's rmse: 0.977939\tvalid_1's cappa: 0.61331\n",
      "[92]\ttraining's rmse: 0.818076\ttraining's cappa: 0.749959\tvalid_1's rmse: 0.977883\tvalid_1's cappa: 0.615765\n",
      "[93]\ttraining's rmse: 0.81675\ttraining's cappa: 0.750641\tvalid_1's rmse: 0.977925\tvalid_1's cappa: 0.615397\n",
      "[94]\ttraining's rmse: 0.815514\ttraining's cappa: 0.752108\tvalid_1's rmse: 0.97805\tvalid_1's cappa: 0.615442\n",
      "[95]\ttraining's rmse: 0.814324\ttraining's cappa: 0.753151\tvalid_1's rmse: 0.978248\tvalid_1's cappa: 0.614609\n",
      "[96]\ttraining's rmse: 0.812798\ttraining's cappa: 0.754332\tvalid_1's rmse: 0.978051\tvalid_1's cappa: 0.615187\n",
      "[97]\ttraining's rmse: 0.811471\ttraining's cappa: 0.75567\tvalid_1's rmse: 0.977809\tvalid_1's cappa: 0.615622\n",
      "[98]\ttraining's rmse: 0.810591\ttraining's cappa: 0.756629\tvalid_1's rmse: 0.977653\tvalid_1's cappa: 0.614152\n",
      "[99]\ttraining's rmse: 0.809412\ttraining's cappa: 0.757329\tvalid_1's rmse: 0.977889\tvalid_1's cappa: 0.613883\n",
      "[100]\ttraining's rmse: 0.808371\ttraining's cappa: 0.758303\tvalid_1's rmse: 0.977837\tvalid_1's cappa: 0.614551\n",
      "[101]\ttraining's rmse: 0.807094\ttraining's cappa: 0.760097\tvalid_1's rmse: 0.977982\tvalid_1's cappa: 0.613345\n",
      "[102]\ttraining's rmse: 0.805904\ttraining's cappa: 0.760745\tvalid_1's rmse: 0.977586\tvalid_1's cappa: 0.613592\n",
      "[103]\ttraining's rmse: 0.804938\ttraining's cappa: 0.761021\tvalid_1's rmse: 0.977751\tvalid_1's cappa: 0.614266\n",
      "[104]\ttraining's rmse: 0.8039\ttraining's cappa: 0.761417\tvalid_1's rmse: 0.978024\tvalid_1's cappa: 0.613196\n",
      "[105]\ttraining's rmse: 0.802893\ttraining's cappa: 0.76181\tvalid_1's rmse: 0.978038\tvalid_1's cappa: 0.613002\n",
      "[106]\ttraining's rmse: 0.801602\ttraining's cappa: 0.76265\tvalid_1's rmse: 0.977725\tvalid_1's cappa: 0.614679\n",
      "[107]\ttraining's rmse: 0.800588\ttraining's cappa: 0.763351\tvalid_1's rmse: 0.97795\tvalid_1's cappa: 0.614671\n",
      "[108]\ttraining's rmse: 0.799717\ttraining's cappa: 0.763857\tvalid_1's rmse: 0.977813\tvalid_1's cappa: 0.615315\n",
      "[109]\ttraining's rmse: 0.798262\ttraining's cappa: 0.764938\tvalid_1's rmse: 0.977933\tvalid_1's cappa: 0.614483\n",
      "[110]\ttraining's rmse: 0.796879\ttraining's cappa: 0.766216\tvalid_1's rmse: 0.977864\tvalid_1's cappa: 0.615098\n",
      "[111]\ttraining's rmse: 0.795507\ttraining's cappa: 0.766991\tvalid_1's rmse: 0.977564\tvalid_1's cappa: 0.615525\n",
      "[112]\ttraining's rmse: 0.794321\ttraining's cappa: 0.767344\tvalid_1's rmse: 0.977322\tvalid_1's cappa: 0.615135\n",
      "[113]\ttraining's rmse: 0.793178\ttraining's cappa: 0.76836\tvalid_1's rmse: 0.977398\tvalid_1's cappa: 0.614515\n",
      "[114]\ttraining's rmse: 0.792291\ttraining's cappa: 0.769261\tvalid_1's rmse: 0.977333\tvalid_1's cappa: 0.615105\n",
      "[115]\ttraining's rmse: 0.791333\ttraining's cappa: 0.769572\tvalid_1's rmse: 0.977245\tvalid_1's cappa: 0.615038\n",
      "[116]\ttraining's rmse: 0.790609\ttraining's cappa: 0.770136\tvalid_1's rmse: 0.976879\tvalid_1's cappa: 0.614658\n",
      "[117]\ttraining's rmse: 0.789251\ttraining's cappa: 0.771022\tvalid_1's rmse: 0.976887\tvalid_1's cappa: 0.613386\n",
      "[118]\ttraining's rmse: 0.788155\ttraining's cappa: 0.772207\tvalid_1's rmse: 0.97662\tvalid_1's cappa: 0.613267\n",
      "[119]\ttraining's rmse: 0.787246\ttraining's cappa: 0.773341\tvalid_1's rmse: 0.976388\tvalid_1's cappa: 0.614149\n",
      "[120]\ttraining's rmse: 0.786414\ttraining's cappa: 0.774176\tvalid_1's rmse: 0.976395\tvalid_1's cappa: 0.613985\n",
      "[121]\ttraining's rmse: 0.785064\ttraining's cappa: 0.775309\tvalid_1's rmse: 0.976376\tvalid_1's cappa: 0.6133\n",
      "[122]\ttraining's rmse: 0.784222\ttraining's cappa: 0.775629\tvalid_1's rmse: 0.976339\tvalid_1's cappa: 0.613254\n",
      "[123]\ttraining's rmse: 0.783217\ttraining's cappa: 0.776198\tvalid_1's rmse: 0.97645\tvalid_1's cappa: 0.612701\n",
      "[124]\ttraining's rmse: 0.782056\ttraining's cappa: 0.777231\tvalid_1's rmse: 0.976446\tvalid_1's cappa: 0.612858\n",
      "[125]\ttraining's rmse: 0.781109\ttraining's cappa: 0.778037\tvalid_1's rmse: 0.976568\tvalid_1's cappa: 0.613202\n",
      "[126]\ttraining's rmse: 0.780299\ttraining's cappa: 0.778764\tvalid_1's rmse: 0.976515\tvalid_1's cappa: 0.613495\n",
      "[127]\ttraining's rmse: 0.779197\ttraining's cappa: 0.779493\tvalid_1's rmse: 0.97659\tvalid_1's cappa: 0.613575\n",
      "[128]\ttraining's rmse: 0.778139\ttraining's cappa: 0.780321\tvalid_1's rmse: 0.976644\tvalid_1's cappa: 0.614448\n",
      "[129]\ttraining's rmse: 0.777233\ttraining's cappa: 0.780734\tvalid_1's rmse: 0.977085\tvalid_1's cappa: 0.614777\n",
      "[130]\ttraining's rmse: 0.776502\ttraining's cappa: 0.781031\tvalid_1's rmse: 0.977135\tvalid_1's cappa: 0.614732\n",
      "[131]\ttraining's rmse: 0.775316\ttraining's cappa: 0.78259\tvalid_1's rmse: 0.977099\tvalid_1's cappa: 0.616427\n",
      "[132]\ttraining's rmse: 0.774406\ttraining's cappa: 0.783096\tvalid_1's rmse: 0.976981\tvalid_1's cappa: 0.616248\n",
      "[133]\ttraining's rmse: 0.773464\ttraining's cappa: 0.78391\tvalid_1's rmse: 0.97718\tvalid_1's cappa: 0.615964\n",
      "[134]\ttraining's rmse: 0.772374\ttraining's cappa: 0.7847\tvalid_1's rmse: 0.977339\tvalid_1's cappa: 0.615979\n",
      "[135]\ttraining's rmse: 0.771339\ttraining's cappa: 0.784927\tvalid_1's rmse: 0.977326\tvalid_1's cappa: 0.616973\n",
      "[136]\ttraining's rmse: 0.769741\ttraining's cappa: 0.785983\tvalid_1's rmse: 0.977328\tvalid_1's cappa: 0.616621\n",
      "[137]\ttraining's rmse: 0.768706\ttraining's cappa: 0.78669\tvalid_1's rmse: 0.977988\tvalid_1's cappa: 0.617002\n",
      "[138]\ttraining's rmse: 0.767779\ttraining's cappa: 0.787209\tvalid_1's rmse: 0.978047\tvalid_1's cappa: 0.615785\n",
      "[139]\ttraining's rmse: 0.767132\ttraining's cappa: 0.787659\tvalid_1's rmse: 0.97826\tvalid_1's cappa: 0.615957\n",
      "[140]\ttraining's rmse: 0.765972\ttraining's cappa: 0.78828\tvalid_1's rmse: 0.97824\tvalid_1's cappa: 0.615651\n",
      "[141]\ttraining's rmse: 0.765009\ttraining's cappa: 0.788972\tvalid_1's rmse: 0.97798\tvalid_1's cappa: 0.615882\n",
      "[142]\ttraining's rmse: 0.763913\ttraining's cappa: 0.790103\tvalid_1's rmse: 0.978206\tvalid_1's cappa: 0.616531\n",
      "[143]\ttraining's rmse: 0.763135\ttraining's cappa: 0.790822\tvalid_1's rmse: 0.978464\tvalid_1's cappa: 0.617675\n",
      "[144]\ttraining's rmse: 0.762198\ttraining's cappa: 0.791548\tvalid_1's rmse: 0.978585\tvalid_1's cappa: 0.615845\n",
      "[145]\ttraining's rmse: 0.761187\ttraining's cappa: 0.792265\tvalid_1's rmse: 0.978557\tvalid_1's cappa: 0.61618\n",
      "[146]\ttraining's rmse: 0.76019\ttraining's cappa: 0.793206\tvalid_1's rmse: 0.978629\tvalid_1's cappa: 0.616203\n",
      "[147]\ttraining's rmse: 0.759162\ttraining's cappa: 0.794046\tvalid_1's rmse: 0.978752\tvalid_1's cappa: 0.615038\n",
      "[148]\ttraining's rmse: 0.75808\ttraining's cappa: 0.795548\tvalid_1's rmse: 0.9789\tvalid_1's cappa: 0.613221\n",
      "[149]\ttraining's rmse: 0.757394\ttraining's cappa: 0.79595\tvalid_1's rmse: 0.978749\tvalid_1's cappa: 0.614245\n",
      "[150]\ttraining's rmse: 0.7562\ttraining's cappa: 0.795987\tvalid_1's rmse: 0.97889\tvalid_1's cappa: 0.61396\n",
      "[151]\ttraining's rmse: 0.755574\ttraining's cappa: 0.795869\tvalid_1's rmse: 0.979145\tvalid_1's cappa: 0.615598\n",
      "[152]\ttraining's rmse: 0.754884\ttraining's cappa: 0.796482\tvalid_1's rmse: 0.97949\tvalid_1's cappa: 0.616428\n",
      "[153]\ttraining's rmse: 0.754308\ttraining's cappa: 0.796773\tvalid_1's rmse: 0.979296\tvalid_1's cappa: 0.615448\n",
      "[154]\ttraining's rmse: 0.75306\ttraining's cappa: 0.798088\tvalid_1's rmse: 0.979136\tvalid_1's cappa: 0.615254\n",
      "[155]\ttraining's rmse: 0.751844\ttraining's cappa: 0.798493\tvalid_1's rmse: 0.978985\tvalid_1's cappa: 0.615568\n",
      "[156]\ttraining's rmse: 0.751179\ttraining's cappa: 0.799006\tvalid_1's rmse: 0.979071\tvalid_1's cappa: 0.614671\n",
      "[157]\ttraining's rmse: 0.750377\ttraining's cappa: 0.799508\tvalid_1's rmse: 0.979087\tvalid_1's cappa: 0.615815\n",
      "[158]\ttraining's rmse: 0.749544\ttraining's cappa: 0.800229\tvalid_1's rmse: 0.978945\tvalid_1's cappa: 0.615426\n",
      "[159]\ttraining's rmse: 0.748299\ttraining's cappa: 0.801463\tvalid_1's rmse: 0.978942\tvalid_1's cappa: 0.614067\n",
      "[160]\ttraining's rmse: 0.747237\ttraining's cappa: 0.80203\tvalid_1's rmse: 0.979143\tvalid_1's cappa: 0.613521\n",
      "[161]\ttraining's rmse: 0.746266\ttraining's cappa: 0.802455\tvalid_1's rmse: 0.979157\tvalid_1's cappa: 0.613425\n",
      "[162]\ttraining's rmse: 0.745198\ttraining's cappa: 0.803586\tvalid_1's rmse: 0.979389\tvalid_1's cappa: 0.612597\n",
      "[163]\ttraining's rmse: 0.74417\ttraining's cappa: 0.804848\tvalid_1's rmse: 0.979605\tvalid_1's cappa: 0.61196\n",
      "[164]\ttraining's rmse: 0.74302\ttraining's cappa: 0.805568\tvalid_1's rmse: 0.979919\tvalid_1's cappa: 0.61305\n",
      "[165]\ttraining's rmse: 0.742178\ttraining's cappa: 0.806004\tvalid_1's rmse: 0.979825\tvalid_1's cappa: 0.613243\n",
      "[166]\ttraining's rmse: 0.741168\ttraining's cappa: 0.806789\tvalid_1's rmse: 0.979757\tvalid_1's cappa: 0.613953\n",
      "[167]\ttraining's rmse: 0.740094\ttraining's cappa: 0.808013\tvalid_1's rmse: 0.979946\tvalid_1's cappa: 0.613566\n",
      "[168]\ttraining's rmse: 0.739564\ttraining's cappa: 0.80826\tvalid_1's rmse: 0.979898\tvalid_1's cappa: 0.614112\n",
      "[169]\ttraining's rmse: 0.738466\ttraining's cappa: 0.809028\tvalid_1's rmse: 0.979871\tvalid_1's cappa: 0.613582\n",
      "[170]\ttraining's rmse: 0.737421\ttraining's cappa: 0.80997\tvalid_1's rmse: 0.979964\tvalid_1's cappa: 0.614163\n",
      "[171]\ttraining's rmse: 0.73674\ttraining's cappa: 0.810399\tvalid_1's rmse: 0.980088\tvalid_1's cappa: 0.614678\n",
      "[172]\ttraining's rmse: 0.735932\ttraining's cappa: 0.81079\tvalid_1's rmse: 0.979977\tvalid_1's cappa: 0.614476\n",
      "[173]\ttraining's rmse: 0.735093\ttraining's cappa: 0.811112\tvalid_1's rmse: 0.980308\tvalid_1's cappa: 0.613706\n",
      "[174]\ttraining's rmse: 0.734193\ttraining's cappa: 0.811499\tvalid_1's rmse: 0.98037\tvalid_1's cappa: 0.613535\n",
      "[175]\ttraining's rmse: 0.733189\ttraining's cappa: 0.812528\tvalid_1's rmse: 0.980424\tvalid_1's cappa: 0.612549\n",
      "[176]\ttraining's rmse: 0.732245\ttraining's cappa: 0.813123\tvalid_1's rmse: 0.980556\tvalid_1's cappa: 0.611998\n",
      "[177]\ttraining's rmse: 0.731198\ttraining's cappa: 0.813469\tvalid_1's rmse: 0.980508\tvalid_1's cappa: 0.611871\n",
      "[178]\ttraining's rmse: 0.730556\ttraining's cappa: 0.813649\tvalid_1's rmse: 0.980643\tvalid_1's cappa: 0.611841\n",
      "[179]\ttraining's rmse: 0.729511\ttraining's cappa: 0.814243\tvalid_1's rmse: 0.980968\tvalid_1's cappa: 0.61046\n",
      "[180]\ttraining's rmse: 0.728525\ttraining's cappa: 0.815033\tvalid_1's rmse: 0.981354\tvalid_1's cappa: 0.608853\n",
      "[181]\ttraining's rmse: 0.72765\ttraining's cappa: 0.81573\tvalid_1's rmse: 0.981503\tvalid_1's cappa: 0.608483\n",
      "[182]\ttraining's rmse: 0.727039\ttraining's cappa: 0.816352\tvalid_1's rmse: 0.981757\tvalid_1's cappa: 0.607952\n",
      "[183]\ttraining's rmse: 0.726158\ttraining's cappa: 0.816798\tvalid_1's rmse: 0.981713\tvalid_1's cappa: 0.607318\n",
      "[184]\ttraining's rmse: 0.725236\ttraining's cappa: 0.817417\tvalid_1's rmse: 0.981521\tvalid_1's cappa: 0.606516\n",
      "[185]\ttraining's rmse: 0.724657\ttraining's cappa: 0.818086\tvalid_1's rmse: 0.981326\tvalid_1's cappa: 0.607006\n",
      "[186]\ttraining's rmse: 0.723739\ttraining's cappa: 0.818599\tvalid_1's rmse: 0.981651\tvalid_1's cappa: 0.605749\n",
      "[187]\ttraining's rmse: 0.72298\ttraining's cappa: 0.819118\tvalid_1's rmse: 0.981594\tvalid_1's cappa: 0.605719\n",
      "[188]\ttraining's rmse: 0.721883\ttraining's cappa: 0.819611\tvalid_1's rmse: 0.981416\tvalid_1's cappa: 0.607521\n",
      "[189]\ttraining's rmse: 0.721457\ttraining's cappa: 0.819821\tvalid_1's rmse: 0.981755\tvalid_1's cappa: 0.606832\n",
      "[190]\ttraining's rmse: 0.720421\ttraining's cappa: 0.820238\tvalid_1's rmse: 0.981991\tvalid_1's cappa: 0.607245\n",
      "[191]\ttraining's rmse: 0.7195\ttraining's cappa: 0.821294\tvalid_1's rmse: 0.982193\tvalid_1's cappa: 0.606674\n",
      "[192]\ttraining's rmse: 0.718852\ttraining's cappa: 0.821645\tvalid_1's rmse: 0.982231\tvalid_1's cappa: 0.607118\n",
      "[193]\ttraining's rmse: 0.717873\ttraining's cappa: 0.822273\tvalid_1's rmse: 0.982255\tvalid_1's cappa: 0.607776\n",
      "[194]\ttraining's rmse: 0.716839\ttraining's cappa: 0.822831\tvalid_1's rmse: 0.982206\tvalid_1's cappa: 0.607563\n",
      "[195]\ttraining's rmse: 0.715853\ttraining's cappa: 0.823391\tvalid_1's rmse: 0.982245\tvalid_1's cappa: 0.606434\n",
      "[196]\ttraining's rmse: 0.714938\ttraining's cappa: 0.823792\tvalid_1's rmse: 0.982339\tvalid_1's cappa: 0.606137\n",
      "[197]\ttraining's rmse: 0.714048\ttraining's cappa: 0.824058\tvalid_1's rmse: 0.982346\tvalid_1's cappa: 0.606118\n",
      "[198]\ttraining's rmse: 0.713235\ttraining's cappa: 0.824292\tvalid_1's rmse: 0.982399\tvalid_1's cappa: 0.607475\n",
      "[199]\ttraining's rmse: 0.712229\ttraining's cappa: 0.824951\tvalid_1's rmse: 0.98273\tvalid_1's cappa: 0.60663\n",
      "[200]\ttraining's rmse: 0.711552\ttraining's cappa: 0.825699\tvalid_1's rmse: 0.982664\tvalid_1's cappa: 0.605729\n",
      "[201]\ttraining's rmse: 0.710483\ttraining's cappa: 0.825953\tvalid_1's rmse: 0.9826\tvalid_1's cappa: 0.604748\n",
      "[202]\ttraining's rmse: 0.709753\ttraining's cappa: 0.826082\tvalid_1's rmse: 0.982469\tvalid_1's cappa: 0.605044\n",
      "[203]\ttraining's rmse: 0.708716\ttraining's cappa: 0.82666\tvalid_1's rmse: 0.98239\tvalid_1's cappa: 0.604666\n",
      "[204]\ttraining's rmse: 0.70777\ttraining's cappa: 0.827372\tvalid_1's rmse: 0.982373\tvalid_1's cappa: 0.605386\n",
      "[205]\ttraining's rmse: 0.706844\ttraining's cappa: 0.828204\tvalid_1's rmse: 0.982222\tvalid_1's cappa: 0.60531\n",
      "[206]\ttraining's rmse: 0.705964\ttraining's cappa: 0.82862\tvalid_1's rmse: 0.98218\tvalid_1's cappa: 0.604723\n",
      "[207]\ttraining's rmse: 0.705425\ttraining's cappa: 0.829059\tvalid_1's rmse: 0.982203\tvalid_1's cappa: 0.605795\n",
      "[208]\ttraining's rmse: 0.704653\ttraining's cappa: 0.829544\tvalid_1's rmse: 0.982226\tvalid_1's cappa: 0.60532\n",
      "[209]\ttraining's rmse: 0.703644\ttraining's cappa: 0.830561\tvalid_1's rmse: 0.982592\tvalid_1's cappa: 0.603932\n",
      "[210]\ttraining's rmse: 0.702776\ttraining's cappa: 0.831091\tvalid_1's rmse: 0.982856\tvalid_1's cappa: 0.602712\n",
      "[211]\ttraining's rmse: 0.70194\ttraining's cappa: 0.83177\tvalid_1's rmse: 0.98306\tvalid_1's cappa: 0.602667\n",
      "[212]\ttraining's rmse: 0.700968\ttraining's cappa: 0.83213\tvalid_1's rmse: 0.982889\tvalid_1's cappa: 0.602319\n",
      "[213]\ttraining's rmse: 0.699931\ttraining's cappa: 0.832705\tvalid_1's rmse: 0.982919\tvalid_1's cappa: 0.602019\n",
      "[214]\ttraining's rmse: 0.699071\ttraining's cappa: 0.833699\tvalid_1's rmse: 0.983022\tvalid_1's cappa: 0.602097\n",
      "[215]\ttraining's rmse: 0.698292\ttraining's cappa: 0.833977\tvalid_1's rmse: 0.983293\tvalid_1's cappa: 0.601909\n",
      "[216]\ttraining's rmse: 0.697507\ttraining's cappa: 0.834077\tvalid_1's rmse: 0.983366\tvalid_1's cappa: 0.602645\n",
      "[217]\ttraining's rmse: 0.696598\ttraining's cappa: 0.834323\tvalid_1's rmse: 0.983308\tvalid_1's cappa: 0.603704\n",
      "[218]\ttraining's rmse: 0.695727\ttraining's cappa: 0.834921\tvalid_1's rmse: 0.983303\tvalid_1's cappa: 0.604417\n",
      "[219]\ttraining's rmse: 0.6948\ttraining's cappa: 0.835436\tvalid_1's rmse: 0.983109\tvalid_1's cappa: 0.605402\n",
      "[220]\ttraining's rmse: 0.694032\ttraining's cappa: 0.836228\tvalid_1's rmse: 0.98322\tvalid_1's cappa: 0.605417\n",
      "[221]\ttraining's rmse: 0.693352\ttraining's cappa: 0.836369\tvalid_1's rmse: 0.983291\tvalid_1's cappa: 0.60583\n",
      "[222]\ttraining's rmse: 0.692518\ttraining's cappa: 0.836867\tvalid_1's rmse: 0.983517\tvalid_1's cappa: 0.605596\n",
      "Early stopping, best iteration is:\n",
      "[122]\ttraining's rmse: 0.784222\ttraining's cappa: 0.775629\tvalid_1's rmse: 0.976339\tvalid_1's cappa: 0.613254\n",
      "Fold : 2\n",
      "[1]\ttraining's rmse: 1.2192\ttraining's cappa: 0.255113\tvalid_1's rmse: 1.1979\tvalid_1's cappa: 0.217121\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's rmse: 1.18212\ttraining's cappa: 0.318089\tvalid_1's rmse: 1.16562\tvalid_1's cappa: 0.281121\n",
      "[3]\ttraining's rmse: 1.15075\ttraining's cappa: 0.334264\tvalid_1's rmse: 1.13723\tvalid_1's cappa: 0.299917\n",
      "[4]\ttraining's rmse: 1.12438\ttraining's cappa: 0.343583\tvalid_1's rmse: 1.1143\tvalid_1's cappa: 0.305855\n",
      "[5]\ttraining's rmse: 1.1018\ttraining's cappa: 0.349354\tvalid_1's rmse: 1.09459\tvalid_1's cappa: 0.318822\n",
      "[6]\ttraining's rmse: 1.08202\ttraining's cappa: 0.355119\tvalid_1's rmse: 1.07793\tvalid_1's cappa: 0.321324\n",
      "[7]\ttraining's rmse: 1.06526\ttraining's cappa: 0.432111\tvalid_1's rmse: 1.06368\tvalid_1's cappa: 0.393918\n",
      "[8]\ttraining's rmse: 1.05018\ttraining's cappa: 0.527517\tvalid_1's rmse: 1.05083\tvalid_1's cappa: 0.481915\n",
      "[9]\ttraining's rmse: 1.03722\ttraining's cappa: 0.556968\tvalid_1's rmse: 1.04094\tvalid_1's cappa: 0.511325\n",
      "[10]\ttraining's rmse: 1.02536\ttraining's cappa: 0.577718\tvalid_1's rmse: 1.032\tvalid_1's cappa: 0.531211\n",
      "[11]\ttraining's rmse: 1.01513\ttraining's cappa: 0.598148\tvalid_1's rmse: 1.02354\tvalid_1's cappa: 0.556905\n",
      "[12]\ttraining's rmse: 1.00578\ttraining's cappa: 0.60855\tvalid_1's rmse: 1.01671\tvalid_1's cappa: 0.564481\n",
      "[13]\ttraining's rmse: 0.997986\ttraining's cappa: 0.621059\tvalid_1's rmse: 1.0109\tvalid_1's cappa: 0.574339\n",
      "[14]\ttraining's rmse: 0.99089\ttraining's cappa: 0.625584\tvalid_1's rmse: 1.00581\tvalid_1's cappa: 0.579206\n",
      "[15]\ttraining's rmse: 0.984572\ttraining's cappa: 0.630268\tvalid_1's rmse: 1.0019\tvalid_1's cappa: 0.582272\n",
      "[16]\ttraining's rmse: 0.978559\ttraining's cappa: 0.634408\tvalid_1's rmse: 0.99779\tvalid_1's cappa: 0.583886\n",
      "[17]\ttraining's rmse: 0.972436\ttraining's cappa: 0.639759\tvalid_1's rmse: 0.993958\tvalid_1's cappa: 0.585703\n",
      "[18]\ttraining's rmse: 0.967372\ttraining's cappa: 0.642558\tvalid_1's rmse: 0.990914\tvalid_1's cappa: 0.590537\n",
      "[19]\ttraining's rmse: 0.962354\ttraining's cappa: 0.646307\tvalid_1's rmse: 0.988316\tvalid_1's cappa: 0.589498\n",
      "[20]\ttraining's rmse: 0.957973\ttraining's cappa: 0.647511\tvalid_1's rmse: 0.985909\tvalid_1's cappa: 0.592308\n",
      "[21]\ttraining's rmse: 0.954195\ttraining's cappa: 0.65082\tvalid_1's rmse: 0.983959\tvalid_1's cappa: 0.589735\n",
      "[22]\ttraining's rmse: 0.950298\ttraining's cappa: 0.652403\tvalid_1's rmse: 0.98254\tvalid_1's cappa: 0.592722\n",
      "[23]\ttraining's rmse: 0.946823\ttraining's cappa: 0.655115\tvalid_1's rmse: 0.981651\tvalid_1's cappa: 0.592111\n",
      "[24]\ttraining's rmse: 0.943146\ttraining's cappa: 0.656922\tvalid_1's rmse: 0.980165\tvalid_1's cappa: 0.58988\n",
      "[25]\ttraining's rmse: 0.939742\ttraining's cappa: 0.658091\tvalid_1's rmse: 0.978711\tvalid_1's cappa: 0.591597\n",
      "[26]\ttraining's rmse: 0.935982\ttraining's cappa: 0.661819\tvalid_1's rmse: 0.976998\tvalid_1's cappa: 0.592505\n",
      "[27]\ttraining's rmse: 0.933053\ttraining's cappa: 0.663671\tvalid_1's rmse: 0.97644\tvalid_1's cappa: 0.592751\n",
      "[28]\ttraining's rmse: 0.930141\ttraining's cappa: 0.665433\tvalid_1's rmse: 0.97554\tvalid_1's cappa: 0.594717\n",
      "[29]\ttraining's rmse: 0.926961\ttraining's cappa: 0.668912\tvalid_1's rmse: 0.974899\tvalid_1's cappa: 0.593816\n",
      "[30]\ttraining's rmse: 0.923962\ttraining's cappa: 0.669899\tvalid_1's rmse: 0.974248\tvalid_1's cappa: 0.592945\n",
      "[31]\ttraining's rmse: 0.921241\ttraining's cappa: 0.671463\tvalid_1's rmse: 0.973631\tvalid_1's cappa: 0.593225\n",
      "[32]\ttraining's rmse: 0.918504\ttraining's cappa: 0.673876\tvalid_1's rmse: 0.973147\tvalid_1's cappa: 0.594811\n",
      "[33]\ttraining's rmse: 0.91634\ttraining's cappa: 0.675208\tvalid_1's rmse: 0.973065\tvalid_1's cappa: 0.594816\n",
      "[34]\ttraining's rmse: 0.913793\ttraining's cappa: 0.678008\tvalid_1's rmse: 0.9726\tvalid_1's cappa: 0.591628\n",
      "[35]\ttraining's rmse: 0.911496\ttraining's cappa: 0.679395\tvalid_1's rmse: 0.972631\tvalid_1's cappa: 0.590819\n",
      "[36]\ttraining's rmse: 0.909047\ttraining's cappa: 0.681321\tvalid_1's rmse: 0.971347\tvalid_1's cappa: 0.591642\n",
      "[37]\ttraining's rmse: 0.906697\ttraining's cappa: 0.682571\tvalid_1's rmse: 0.970591\tvalid_1's cappa: 0.590697\n",
      "[38]\ttraining's rmse: 0.904378\ttraining's cappa: 0.68435\tvalid_1's rmse: 0.970116\tvalid_1's cappa: 0.589699\n",
      "[39]\ttraining's rmse: 0.902381\ttraining's cappa: 0.684812\tvalid_1's rmse: 0.970096\tvalid_1's cappa: 0.588854\n",
      "[40]\ttraining's rmse: 0.900128\ttraining's cappa: 0.68746\tvalid_1's rmse: 0.969623\tvalid_1's cappa: 0.589354\n",
      "[41]\ttraining's rmse: 0.897951\ttraining's cappa: 0.689073\tvalid_1's rmse: 0.969558\tvalid_1's cappa: 0.589387\n",
      "[42]\ttraining's rmse: 0.895813\ttraining's cappa: 0.690314\tvalid_1's rmse: 0.969219\tvalid_1's cappa: 0.59147\n",
      "[43]\ttraining's rmse: 0.893424\ttraining's cappa: 0.692084\tvalid_1's rmse: 0.968805\tvalid_1's cappa: 0.591842\n",
      "[44]\ttraining's rmse: 0.891253\ttraining's cappa: 0.693348\tvalid_1's rmse: 0.968469\tvalid_1's cappa: 0.591705\n",
      "[45]\ttraining's rmse: 0.889372\ttraining's cappa: 0.695076\tvalid_1's rmse: 0.968335\tvalid_1's cappa: 0.591231\n",
      "[46]\ttraining's rmse: 0.8876\ttraining's cappa: 0.696912\tvalid_1's rmse: 0.967838\tvalid_1's cappa: 0.589329\n",
      "[47]\ttraining's rmse: 0.885642\ttraining's cappa: 0.699106\tvalid_1's rmse: 0.967676\tvalid_1's cappa: 0.590474\n",
      "[48]\ttraining's rmse: 0.883896\ttraining's cappa: 0.700217\tvalid_1's rmse: 0.967313\tvalid_1's cappa: 0.590262\n",
      "[49]\ttraining's rmse: 0.881919\ttraining's cappa: 0.700802\tvalid_1's rmse: 0.96745\tvalid_1's cappa: 0.590791\n",
      "[50]\ttraining's rmse: 0.879943\ttraining's cappa: 0.702215\tvalid_1's rmse: 0.967488\tvalid_1's cappa: 0.591931\n",
      "[51]\ttraining's rmse: 0.878216\ttraining's cappa: 0.703829\tvalid_1's rmse: 0.967707\tvalid_1's cappa: 0.591911\n",
      "[52]\ttraining's rmse: 0.876697\ttraining's cappa: 0.704824\tvalid_1's rmse: 0.967128\tvalid_1's cappa: 0.592719\n",
      "[53]\ttraining's rmse: 0.875071\ttraining's cappa: 0.706156\tvalid_1's rmse: 0.967087\tvalid_1's cappa: 0.593011\n",
      "[54]\ttraining's rmse: 0.873286\ttraining's cappa: 0.707558\tvalid_1's rmse: 0.967204\tvalid_1's cappa: 0.591974\n",
      "[55]\ttraining's rmse: 0.871371\ttraining's cappa: 0.708925\tvalid_1's rmse: 0.967651\tvalid_1's cappa: 0.594131\n",
      "[56]\ttraining's rmse: 0.869586\ttraining's cappa: 0.711077\tvalid_1's rmse: 0.967851\tvalid_1's cappa: 0.592035\n",
      "[57]\ttraining's rmse: 0.868035\ttraining's cappa: 0.711811\tvalid_1's rmse: 0.967645\tvalid_1's cappa: 0.591434\n",
      "[58]\ttraining's rmse: 0.866659\ttraining's cappa: 0.712965\tvalid_1's rmse: 0.967349\tvalid_1's cappa: 0.59165\n",
      "[59]\ttraining's rmse: 0.864969\ttraining's cappa: 0.714992\tvalid_1's rmse: 0.966911\tvalid_1's cappa: 0.59346\n",
      "[60]\ttraining's rmse: 0.86342\ttraining's cappa: 0.716521\tvalid_1's rmse: 0.967062\tvalid_1's cappa: 0.594581\n",
      "[61]\ttraining's rmse: 0.861878\ttraining's cappa: 0.718189\tvalid_1's rmse: 0.967135\tvalid_1's cappa: 0.595012\n",
      "[62]\ttraining's rmse: 0.860229\ttraining's cappa: 0.719279\tvalid_1's rmse: 0.966488\tvalid_1's cappa: 0.598082\n",
      "[63]\ttraining's rmse: 0.858765\ttraining's cappa: 0.720451\tvalid_1's rmse: 0.96661\tvalid_1's cappa: 0.597633\n",
      "[64]\ttraining's rmse: 0.857197\ttraining's cappa: 0.721649\tvalid_1's rmse: 0.967112\tvalid_1's cappa: 0.596176\n",
      "[65]\ttraining's rmse: 0.855789\ttraining's cappa: 0.722731\tvalid_1's rmse: 0.967105\tvalid_1's cappa: 0.596183\n",
      "[66]\ttraining's rmse: 0.854233\ttraining's cappa: 0.724029\tvalid_1's rmse: 0.967392\tvalid_1's cappa: 0.595509\n",
      "[67]\ttraining's rmse: 0.852756\ttraining's cappa: 0.72546\tvalid_1's rmse: 0.96764\tvalid_1's cappa: 0.594504\n",
      "[68]\ttraining's rmse: 0.851075\ttraining's cappa: 0.726736\tvalid_1's rmse: 0.967758\tvalid_1's cappa: 0.59505\n",
      "[69]\ttraining's rmse: 0.84941\ttraining's cappa: 0.72783\tvalid_1's rmse: 0.967478\tvalid_1's cappa: 0.596216\n",
      "[70]\ttraining's rmse: 0.847927\ttraining's cappa: 0.729418\tvalid_1's rmse: 0.967146\tvalid_1's cappa: 0.5953\n",
      "[71]\ttraining's rmse: 0.846495\ttraining's cappa: 0.730692\tvalid_1's rmse: 0.967255\tvalid_1's cappa: 0.595786\n",
      "[72]\ttraining's rmse: 0.845216\ttraining's cappa: 0.731023\tvalid_1's rmse: 0.967094\tvalid_1's cappa: 0.59566\n",
      "[73]\ttraining's rmse: 0.844118\ttraining's cappa: 0.732066\tvalid_1's rmse: 0.967152\tvalid_1's cappa: 0.595341\n",
      "[74]\ttraining's rmse: 0.842841\ttraining's cappa: 0.732219\tvalid_1's rmse: 0.96726\tvalid_1's cappa: 0.59536\n",
      "[75]\ttraining's rmse: 0.841408\ttraining's cappa: 0.733023\tvalid_1's rmse: 0.966931\tvalid_1's cappa: 0.597068\n",
      "[76]\ttraining's rmse: 0.839851\ttraining's cappa: 0.73459\tvalid_1's rmse: 0.967043\tvalid_1's cappa: 0.595489\n",
      "[77]\ttraining's rmse: 0.838453\ttraining's cappa: 0.735899\tvalid_1's rmse: 0.966927\tvalid_1's cappa: 0.594842\n",
      "[78]\ttraining's rmse: 0.836942\ttraining's cappa: 0.736819\tvalid_1's rmse: 0.966817\tvalid_1's cappa: 0.593257\n",
      "[79]\ttraining's rmse: 0.835656\ttraining's cappa: 0.737173\tvalid_1's rmse: 0.96694\tvalid_1's cappa: 0.592774\n",
      "[80]\ttraining's rmse: 0.834509\ttraining's cappa: 0.738213\tvalid_1's rmse: 0.96705\tvalid_1's cappa: 0.592348\n",
      "[81]\ttraining's rmse: 0.833328\ttraining's cappa: 0.739611\tvalid_1's rmse: 0.96692\tvalid_1's cappa: 0.592921\n",
      "[82]\ttraining's rmse: 0.832099\ttraining's cappa: 0.741144\tvalid_1's rmse: 0.966616\tvalid_1's cappa: 0.593447\n",
      "[83]\ttraining's rmse: 0.83097\ttraining's cappa: 0.741283\tvalid_1's rmse: 0.966433\tvalid_1's cappa: 0.594425\n",
      "[84]\ttraining's rmse: 0.829697\ttraining's cappa: 0.742826\tvalid_1's rmse: 0.96662\tvalid_1's cappa: 0.595822\n",
      "[85]\ttraining's rmse: 0.82835\ttraining's cappa: 0.743591\tvalid_1's rmse: 0.966721\tvalid_1's cappa: 0.59538\n",
      "[86]\ttraining's rmse: 0.826989\ttraining's cappa: 0.744571\tvalid_1's rmse: 0.966603\tvalid_1's cappa: 0.59524\n",
      "[87]\ttraining's rmse: 0.825704\ttraining's cappa: 0.745523\tvalid_1's rmse: 0.966776\tvalid_1's cappa: 0.595761\n",
      "[88]\ttraining's rmse: 0.824623\ttraining's cappa: 0.746021\tvalid_1's rmse: 0.966638\tvalid_1's cappa: 0.595889\n",
      "[89]\ttraining's rmse: 0.823722\ttraining's cappa: 0.746993\tvalid_1's rmse: 0.966444\tvalid_1's cappa: 0.595416\n",
      "[90]\ttraining's rmse: 0.822425\ttraining's cappa: 0.748467\tvalid_1's rmse: 0.966473\tvalid_1's cappa: 0.595624\n",
      "[91]\ttraining's rmse: 0.820807\ttraining's cappa: 0.749961\tvalid_1's rmse: 0.966349\tvalid_1's cappa: 0.595305\n",
      "[92]\ttraining's rmse: 0.819353\ttraining's cappa: 0.751374\tvalid_1's rmse: 0.966508\tvalid_1's cappa: 0.595122\n",
      "[93]\ttraining's rmse: 0.818127\ttraining's cappa: 0.752119\tvalid_1's rmse: 0.967041\tvalid_1's cappa: 0.59701\n",
      "[94]\ttraining's rmse: 0.816785\ttraining's cappa: 0.75272\tvalid_1's rmse: 0.966791\tvalid_1's cappa: 0.596183\n",
      "[95]\ttraining's rmse: 0.8158\ttraining's cappa: 0.753798\tvalid_1's rmse: 0.966901\tvalid_1's cappa: 0.595548\n",
      "[96]\ttraining's rmse: 0.814498\ttraining's cappa: 0.755236\tvalid_1's rmse: 0.967282\tvalid_1's cappa: 0.593501\n",
      "[97]\ttraining's rmse: 0.813128\ttraining's cappa: 0.756311\tvalid_1's rmse: 0.967309\tvalid_1's cappa: 0.594465\n",
      "[98]\ttraining's rmse: 0.811919\ttraining's cappa: 0.75701\tvalid_1's rmse: 0.9677\tvalid_1's cappa: 0.593801\n",
      "[99]\ttraining's rmse: 0.810755\ttraining's cappa: 0.757993\tvalid_1's rmse: 0.967546\tvalid_1's cappa: 0.593507\n",
      "[100]\ttraining's rmse: 0.80958\ttraining's cappa: 0.758759\tvalid_1's rmse: 0.967861\tvalid_1's cappa: 0.592807\n",
      "[101]\ttraining's rmse: 0.808781\ttraining's cappa: 0.759285\tvalid_1's rmse: 0.968123\tvalid_1's cappa: 0.592658\n",
      "[102]\ttraining's rmse: 0.807907\ttraining's cappa: 0.760345\tvalid_1's rmse: 0.968473\tvalid_1's cappa: 0.593303\n",
      "[103]\ttraining's rmse: 0.806923\ttraining's cappa: 0.761032\tvalid_1's rmse: 0.968914\tvalid_1's cappa: 0.59302\n",
      "[104]\ttraining's rmse: 0.805747\ttraining's cappa: 0.761349\tvalid_1's rmse: 0.968739\tvalid_1's cappa: 0.594011\n",
      "[105]\ttraining's rmse: 0.804499\ttraining's cappa: 0.762575\tvalid_1's rmse: 0.969075\tvalid_1's cappa: 0.593229\n",
      "[106]\ttraining's rmse: 0.803217\ttraining's cappa: 0.764271\tvalid_1's rmse: 0.969142\tvalid_1's cappa: 0.593945\n",
      "[107]\ttraining's rmse: 0.802132\ttraining's cappa: 0.765076\tvalid_1's rmse: 0.969673\tvalid_1's cappa: 0.594861\n",
      "[108]\ttraining's rmse: 0.801006\ttraining's cappa: 0.765422\tvalid_1's rmse: 0.969462\tvalid_1's cappa: 0.59445\n",
      "[109]\ttraining's rmse: 0.799987\ttraining's cappa: 0.766072\tvalid_1's rmse: 0.969541\tvalid_1's cappa: 0.593661\n",
      "[110]\ttraining's rmse: 0.7987\ttraining's cappa: 0.76771\tvalid_1's rmse: 0.969466\tvalid_1's cappa: 0.594595\n",
      "[111]\ttraining's rmse: 0.797484\ttraining's cappa: 0.76874\tvalid_1's rmse: 0.969861\tvalid_1's cappa: 0.59487\n",
      "[112]\ttraining's rmse: 0.796598\ttraining's cappa: 0.769309\tvalid_1's rmse: 0.969823\tvalid_1's cappa: 0.593728\n",
      "[113]\ttraining's rmse: 0.795456\ttraining's cappa: 0.769948\tvalid_1's rmse: 0.969616\tvalid_1's cappa: 0.594426\n",
      "[114]\ttraining's rmse: 0.794617\ttraining's cappa: 0.770841\tvalid_1's rmse: 0.969929\tvalid_1's cappa: 0.594861\n",
      "[115]\ttraining's rmse: 0.793662\ttraining's cappa: 0.771671\tvalid_1's rmse: 0.969957\tvalid_1's cappa: 0.594296\n",
      "[116]\ttraining's rmse: 0.7926\ttraining's cappa: 0.772408\tvalid_1's rmse: 0.970108\tvalid_1's cappa: 0.594475\n",
      "[117]\ttraining's rmse: 0.791779\ttraining's cappa: 0.77349\tvalid_1's rmse: 0.970182\tvalid_1's cappa: 0.593822\n",
      "[118]\ttraining's rmse: 0.790393\ttraining's cappa: 0.774104\tvalid_1's rmse: 0.970171\tvalid_1's cappa: 0.593375\n",
      "[119]\ttraining's rmse: 0.789156\ttraining's cappa: 0.775126\tvalid_1's rmse: 0.97036\tvalid_1's cappa: 0.595071\n",
      "[120]\ttraining's rmse: 0.788041\ttraining's cappa: 0.775826\tvalid_1's rmse: 0.970231\tvalid_1's cappa: 0.594319\n",
      "[121]\ttraining's rmse: 0.786893\ttraining's cappa: 0.777018\tvalid_1's rmse: 0.970416\tvalid_1's cappa: 0.593294\n",
      "[122]\ttraining's rmse: 0.7858\ttraining's cappa: 0.778135\tvalid_1's rmse: 0.969993\tvalid_1's cappa: 0.59417\n",
      "[123]\ttraining's rmse: 0.784853\ttraining's cappa: 0.778754\tvalid_1's rmse: 0.970092\tvalid_1's cappa: 0.593546\n",
      "[124]\ttraining's rmse: 0.78366\ttraining's cappa: 0.779608\tvalid_1's rmse: 0.970048\tvalid_1's cappa: 0.593736\n",
      "[125]\ttraining's rmse: 0.782535\ttraining's cappa: 0.78035\tvalid_1's rmse: 0.969897\tvalid_1's cappa: 0.593526\n",
      "[126]\ttraining's rmse: 0.78152\ttraining's cappa: 0.781349\tvalid_1's rmse: 0.969863\tvalid_1's cappa: 0.596123\n",
      "[127]\ttraining's rmse: 0.780359\ttraining's cappa: 0.781852\tvalid_1's rmse: 0.970055\tvalid_1's cappa: 0.596649\n",
      "[128]\ttraining's rmse: 0.779236\ttraining's cappa: 0.782751\tvalid_1's rmse: 0.970418\tvalid_1's cappa: 0.596231\n",
      "[129]\ttraining's rmse: 0.778292\ttraining's cappa: 0.783818\tvalid_1's rmse: 0.970373\tvalid_1's cappa: 0.595308\n",
      "[130]\ttraining's rmse: 0.777644\ttraining's cappa: 0.784503\tvalid_1's rmse: 0.970584\tvalid_1's cappa: 0.595426\n",
      "[131]\ttraining's rmse: 0.77668\ttraining's cappa: 0.784845\tvalid_1's rmse: 0.970593\tvalid_1's cappa: 0.595985\n",
      "[132]\ttraining's rmse: 0.775797\ttraining's cappa: 0.785417\tvalid_1's rmse: 0.970463\tvalid_1's cappa: 0.596168\n",
      "[133]\ttraining's rmse: 0.775022\ttraining's cappa: 0.78594\tvalid_1's rmse: 0.97067\tvalid_1's cappa: 0.595074\n",
      "[134]\ttraining's rmse: 0.773917\ttraining's cappa: 0.786531\tvalid_1's rmse: 0.970946\tvalid_1's cappa: 0.595772\n",
      "[135]\ttraining's rmse: 0.772835\ttraining's cappa: 0.787568\tvalid_1's rmse: 0.971142\tvalid_1's cappa: 0.59451\n",
      "[136]\ttraining's rmse: 0.771729\ttraining's cappa: 0.788307\tvalid_1's rmse: 0.971371\tvalid_1's cappa: 0.594174\n",
      "[137]\ttraining's rmse: 0.770908\ttraining's cappa: 0.788522\tvalid_1's rmse: 0.971616\tvalid_1's cappa: 0.593739\n",
      "[138]\ttraining's rmse: 0.769876\ttraining's cappa: 0.789266\tvalid_1's rmse: 0.971185\tvalid_1's cappa: 0.593475\n",
      "[139]\ttraining's rmse: 0.7687\ttraining's cappa: 0.790223\tvalid_1's rmse: 0.971348\tvalid_1's cappa: 0.593769\n",
      "[140]\ttraining's rmse: 0.767778\ttraining's cappa: 0.790824\tvalid_1's rmse: 0.971308\tvalid_1's cappa: 0.592492\n",
      "[141]\ttraining's rmse: 0.766787\ttraining's cappa: 0.791795\tvalid_1's rmse: 0.971095\tvalid_1's cappa: 0.594021\n",
      "[142]\ttraining's rmse: 0.766158\ttraining's cappa: 0.792555\tvalid_1's rmse: 0.97134\tvalid_1's cappa: 0.592782\n",
      "[143]\ttraining's rmse: 0.765019\ttraining's cappa: 0.793707\tvalid_1's rmse: 0.971352\tvalid_1's cappa: 0.591784\n",
      "[144]\ttraining's rmse: 0.764235\ttraining's cappa: 0.794056\tvalid_1's rmse: 0.971526\tvalid_1's cappa: 0.591793\n",
      "[145]\ttraining's rmse: 0.762929\ttraining's cappa: 0.794876\tvalid_1's rmse: 0.971491\tvalid_1's cappa: 0.592434\n",
      "[146]\ttraining's rmse: 0.761933\ttraining's cappa: 0.795507\tvalid_1's rmse: 0.971507\tvalid_1's cappa: 0.590751\n",
      "[147]\ttraining's rmse: 0.761235\ttraining's cappa: 0.796216\tvalid_1's rmse: 0.971563\tvalid_1's cappa: 0.590027\n",
      "[148]\ttraining's rmse: 0.760415\ttraining's cappa: 0.797025\tvalid_1's rmse: 0.971775\tvalid_1's cappa: 0.590361\n",
      "[149]\ttraining's rmse: 0.759388\ttraining's cappa: 0.797805\tvalid_1's rmse: 0.97218\tvalid_1's cappa: 0.591328\n",
      "[150]\ttraining's rmse: 0.758305\ttraining's cappa: 0.79842\tvalid_1's rmse: 0.972079\tvalid_1's cappa: 0.591165\n",
      "[151]\ttraining's rmse: 0.757568\ttraining's cappa: 0.799234\tvalid_1's rmse: 0.972237\tvalid_1's cappa: 0.591978\n",
      "[152]\ttraining's rmse: 0.756587\ttraining's cappa: 0.800111\tvalid_1's rmse: 0.972744\tvalid_1's cappa: 0.592374\n",
      "[153]\ttraining's rmse: 0.755621\ttraining's cappa: 0.80037\tvalid_1's rmse: 0.972737\tvalid_1's cappa: 0.593188\n",
      "[154]\ttraining's rmse: 0.754741\ttraining's cappa: 0.801077\tvalid_1's rmse: 0.972758\tvalid_1's cappa: 0.594371\n",
      "[155]\ttraining's rmse: 0.753927\ttraining's cappa: 0.801739\tvalid_1's rmse: 0.972653\tvalid_1's cappa: 0.59316\n",
      "[156]\ttraining's rmse: 0.752936\ttraining's cappa: 0.802277\tvalid_1's rmse: 0.972455\tvalid_1's cappa: 0.591731\n",
      "[157]\ttraining's rmse: 0.751956\ttraining's cappa: 0.803073\tvalid_1's rmse: 0.97259\tvalid_1's cappa: 0.590602\n",
      "[158]\ttraining's rmse: 0.750905\ttraining's cappa: 0.803497\tvalid_1's rmse: 0.972881\tvalid_1's cappa: 0.590457\n",
      "[159]\ttraining's rmse: 0.749973\ttraining's cappa: 0.804194\tvalid_1's rmse: 0.97285\tvalid_1's cappa: 0.591289\n",
      "[160]\ttraining's rmse: 0.749213\ttraining's cappa: 0.804498\tvalid_1's rmse: 0.972935\tvalid_1's cappa: 0.591478\n",
      "[161]\ttraining's rmse: 0.748236\ttraining's cappa: 0.805263\tvalid_1's rmse: 0.973407\tvalid_1's cappa: 0.590997\n",
      "[162]\ttraining's rmse: 0.747567\ttraining's cappa: 0.805248\tvalid_1's rmse: 0.973239\tvalid_1's cappa: 0.591485\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's rmse: 0.860229\ttraining's cappa: 0.719279\tvalid_1's rmse: 0.966488\tvalid_1's cappa: 0.598082\n",
      "Fold : 3\n",
      "[1]\ttraining's rmse: 1.21132\ttraining's cappa: 0.157298\tvalid_1's rmse: 1.22333\tvalid_1's cappa: 0.152821\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's rmse: 1.17501\ttraining's cappa: 0.309814\tvalid_1's rmse: 1.18951\tvalid_1's cappa: 0.289566\n",
      "[3]\ttraining's rmse: 1.14382\ttraining's cappa: 0.324661\tvalid_1's rmse: 1.16136\tvalid_1's cappa: 0.30625\n",
      "[4]\ttraining's rmse: 1.1177\ttraining's cappa: 0.337868\tvalid_1's rmse: 1.13741\tvalid_1's cappa: 0.318433\n",
      "[5]\ttraining's rmse: 1.09477\ttraining's cappa: 0.342973\tvalid_1's rmse: 1.11685\tvalid_1's cappa: 0.322675\n",
      "[6]\ttraining's rmse: 1.07509\ttraining's cappa: 0.361328\tvalid_1's rmse: 1.10069\tvalid_1's cappa: 0.335433\n",
      "[7]\ttraining's rmse: 1.05778\ttraining's cappa: 0.436305\tvalid_1's rmse: 1.08588\tvalid_1's cappa: 0.400307\n",
      "[8]\ttraining's rmse: 1.04278\ttraining's cappa: 0.534043\tvalid_1's rmse: 1.0745\tvalid_1's cappa: 0.496378\n",
      "[9]\ttraining's rmse: 1.02975\ttraining's cappa: 0.563435\tvalid_1's rmse: 1.06446\tvalid_1's cappa: 0.532359\n",
      "[10]\ttraining's rmse: 1.01821\ttraining's cappa: 0.58936\tvalid_1's rmse: 1.05552\tvalid_1's cappa: 0.54553\n",
      "[11]\ttraining's rmse: 1.00773\ttraining's cappa: 0.603643\tvalid_1's rmse: 1.04845\tvalid_1's cappa: 0.557057\n",
      "[12]\ttraining's rmse: 0.999036\ttraining's cappa: 0.613676\tvalid_1's rmse: 1.0424\tvalid_1's cappa: 0.559563\n",
      "[13]\ttraining's rmse: 0.99131\ttraining's cappa: 0.622492\tvalid_1's rmse: 1.03635\tvalid_1's cappa: 0.568205\n",
      "[14]\ttraining's rmse: 0.984039\ttraining's cappa: 0.629731\tvalid_1's rmse: 1.03202\tvalid_1's cappa: 0.569506\n",
      "[15]\ttraining's rmse: 0.977605\ttraining's cappa: 0.634494\tvalid_1's rmse: 1.02854\tvalid_1's cappa: 0.575531\n",
      "[16]\ttraining's rmse: 0.972021\ttraining's cappa: 0.638117\tvalid_1's rmse: 1.02542\tvalid_1's cappa: 0.573978\n",
      "[17]\ttraining's rmse: 0.966803\ttraining's cappa: 0.641044\tvalid_1's rmse: 1.02139\tvalid_1's cappa: 0.578885\n",
      "[18]\ttraining's rmse: 0.9611\ttraining's cappa: 0.644862\tvalid_1's rmse: 1.0181\tvalid_1's cappa: 0.58212\n",
      "[19]\ttraining's rmse: 0.95608\ttraining's cappa: 0.648901\tvalid_1's rmse: 1.01604\tvalid_1's cappa: 0.584868\n",
      "[20]\ttraining's rmse: 0.951736\ttraining's cappa: 0.650371\tvalid_1's rmse: 1.01361\tvalid_1's cappa: 0.586151\n",
      "[21]\ttraining's rmse: 0.948058\ttraining's cappa: 0.652028\tvalid_1's rmse: 1.01242\tvalid_1's cappa: 0.585929\n",
      "[22]\ttraining's rmse: 0.944355\ttraining's cappa: 0.653631\tvalid_1's rmse: 1.01131\tvalid_1's cappa: 0.583701\n",
      "[23]\ttraining's rmse: 0.940284\ttraining's cappa: 0.65848\tvalid_1's rmse: 1.00903\tvalid_1's cappa: 0.584743\n",
      "[24]\ttraining's rmse: 0.936591\ttraining's cappa: 0.661063\tvalid_1's rmse: 1.0075\tvalid_1's cappa: 0.588637\n",
      "[25]\ttraining's rmse: 0.933378\ttraining's cappa: 0.663086\tvalid_1's rmse: 1.00597\tvalid_1's cappa: 0.587132\n",
      "[26]\ttraining's rmse: 0.930067\ttraining's cappa: 0.665528\tvalid_1's rmse: 1.00471\tvalid_1's cappa: 0.589138\n",
      "[27]\ttraining's rmse: 0.926852\ttraining's cappa: 0.668464\tvalid_1's rmse: 1.00397\tvalid_1's cappa: 0.588622\n",
      "[28]\ttraining's rmse: 0.924006\ttraining's cappa: 0.668342\tvalid_1's rmse: 1.00377\tvalid_1's cappa: 0.587667\n",
      "[29]\ttraining's rmse: 0.92103\ttraining's cappa: 0.671778\tvalid_1's rmse: 1.0028\tvalid_1's cappa: 0.587539\n",
      "[30]\ttraining's rmse: 0.917957\ttraining's cappa: 0.673155\tvalid_1's rmse: 1.00252\tvalid_1's cappa: 0.586742\n",
      "[31]\ttraining's rmse: 0.915229\ttraining's cappa: 0.67426\tvalid_1's rmse: 1.00184\tvalid_1's cappa: 0.587591\n",
      "[32]\ttraining's rmse: 0.912472\ttraining's cappa: 0.675856\tvalid_1's rmse: 1.00136\tvalid_1's cappa: 0.587937\n",
      "[33]\ttraining's rmse: 0.909669\ttraining's cappa: 0.678251\tvalid_1's rmse: 1.0006\tvalid_1's cappa: 0.587302\n",
      "[34]\ttraining's rmse: 0.907283\ttraining's cappa: 0.67935\tvalid_1's rmse: 1.00055\tvalid_1's cappa: 0.587695\n",
      "[35]\ttraining's rmse: 0.904858\ttraining's cappa: 0.680343\tvalid_1's rmse: 1.00025\tvalid_1's cappa: 0.587202\n",
      "[36]\ttraining's rmse: 0.902269\ttraining's cappa: 0.682279\tvalid_1's rmse: 0.999643\tvalid_1's cappa: 0.588155\n",
      "[37]\ttraining's rmse: 0.899759\ttraining's cappa: 0.684672\tvalid_1's rmse: 0.999047\tvalid_1's cappa: 0.587824\n",
      "[38]\ttraining's rmse: 0.897536\ttraining's cappa: 0.686625\tvalid_1's rmse: 0.998471\tvalid_1's cappa: 0.58858\n",
      "[39]\ttraining's rmse: 0.895141\ttraining's cappa: 0.687591\tvalid_1's rmse: 0.998449\tvalid_1's cappa: 0.589099\n",
      "[40]\ttraining's rmse: 0.89305\ttraining's cappa: 0.690116\tvalid_1's rmse: 0.998045\tvalid_1's cappa: 0.590651\n",
      "[41]\ttraining's rmse: 0.890989\ttraining's cappa: 0.691553\tvalid_1's rmse: 0.997895\tvalid_1's cappa: 0.590923\n",
      "[42]\ttraining's rmse: 0.888944\ttraining's cappa: 0.6934\tvalid_1's rmse: 0.998241\tvalid_1's cappa: 0.589685\n",
      "[43]\ttraining's rmse: 0.886815\ttraining's cappa: 0.694252\tvalid_1's rmse: 0.997902\tvalid_1's cappa: 0.590838\n",
      "[44]\ttraining's rmse: 0.884824\ttraining's cappa: 0.697011\tvalid_1's rmse: 0.99777\tvalid_1's cappa: 0.588798\n",
      "[45]\ttraining's rmse: 0.882962\ttraining's cappa: 0.698845\tvalid_1's rmse: 0.997518\tvalid_1's cappa: 0.589542\n",
      "[46]\ttraining's rmse: 0.881046\ttraining's cappa: 0.701091\tvalid_1's rmse: 0.997077\tvalid_1's cappa: 0.588552\n",
      "[47]\ttraining's rmse: 0.879057\ttraining's cappa: 0.702502\tvalid_1's rmse: 0.996811\tvalid_1's cappa: 0.589151\n",
      "[48]\ttraining's rmse: 0.877187\ttraining's cappa: 0.70448\tvalid_1's rmse: 0.996725\tvalid_1's cappa: 0.588257\n",
      "[49]\ttraining's rmse: 0.875338\ttraining's cappa: 0.705477\tvalid_1's rmse: 0.996533\tvalid_1's cappa: 0.586942\n",
      "[50]\ttraining's rmse: 0.873536\ttraining's cappa: 0.707525\tvalid_1's rmse: 0.996733\tvalid_1's cappa: 0.588236\n",
      "[51]\ttraining's rmse: 0.871718\ttraining's cappa: 0.709455\tvalid_1's rmse: 0.996432\tvalid_1's cappa: 0.588758\n",
      "[52]\ttraining's rmse: 0.870168\ttraining's cappa: 0.709649\tvalid_1's rmse: 0.996005\tvalid_1's cappa: 0.588468\n",
      "[53]\ttraining's rmse: 0.86848\ttraining's cappa: 0.711371\tvalid_1's rmse: 0.996302\tvalid_1's cappa: 0.590406\n",
      "[54]\ttraining's rmse: 0.866882\ttraining's cappa: 0.712243\tvalid_1's rmse: 0.996218\tvalid_1's cappa: 0.592271\n",
      "[55]\ttraining's rmse: 0.865357\ttraining's cappa: 0.71397\tvalid_1's rmse: 0.996094\tvalid_1's cappa: 0.591068\n",
      "[56]\ttraining's rmse: 0.863819\ttraining's cappa: 0.714884\tvalid_1's rmse: 0.99596\tvalid_1's cappa: 0.591075\n",
      "[57]\ttraining's rmse: 0.862125\ttraining's cappa: 0.71649\tvalid_1's rmse: 0.996439\tvalid_1's cappa: 0.591008\n",
      "[58]\ttraining's rmse: 0.860461\ttraining's cappa: 0.717083\tvalid_1's rmse: 0.996338\tvalid_1's cappa: 0.592651\n",
      "[59]\ttraining's rmse: 0.858724\ttraining's cappa: 0.718381\tvalid_1's rmse: 0.996423\tvalid_1's cappa: 0.593023\n",
      "[60]\ttraining's rmse: 0.857318\ttraining's cappa: 0.719718\tvalid_1's rmse: 0.996488\tvalid_1's cappa: 0.591653\n",
      "[61]\ttraining's rmse: 0.855811\ttraining's cappa: 0.720493\tvalid_1's rmse: 0.996418\tvalid_1's cappa: 0.590585\n",
      "[62]\ttraining's rmse: 0.854431\ttraining's cappa: 0.722082\tvalid_1's rmse: 0.996252\tvalid_1's cappa: 0.590421\n",
      "[63]\ttraining's rmse: 0.85274\ttraining's cappa: 0.722999\tvalid_1's rmse: 0.996377\tvalid_1's cappa: 0.590978\n",
      "[64]\ttraining's rmse: 0.851125\ttraining's cappa: 0.724103\tvalid_1's rmse: 0.995982\tvalid_1's cappa: 0.59051\n",
      "[65]\ttraining's rmse: 0.849589\ttraining's cappa: 0.725323\tvalid_1's rmse: 0.995811\tvalid_1's cappa: 0.590719\n",
      "[66]\ttraining's rmse: 0.848193\ttraining's cappa: 0.7258\tvalid_1's rmse: 0.995551\tvalid_1's cappa: 0.590024\n",
      "[67]\ttraining's rmse: 0.846664\ttraining's cappa: 0.726971\tvalid_1's rmse: 0.995839\tvalid_1's cappa: 0.589259\n",
      "[68]\ttraining's rmse: 0.84532\ttraining's cappa: 0.727574\tvalid_1's rmse: 0.995768\tvalid_1's cappa: 0.589295\n",
      "[69]\ttraining's rmse: 0.84367\ttraining's cappa: 0.729298\tvalid_1's rmse: 0.99632\tvalid_1's cappa: 0.587131\n",
      "[70]\ttraining's rmse: 0.842302\ttraining's cappa: 0.730124\tvalid_1's rmse: 0.996868\tvalid_1's cappa: 0.586095\n",
      "[71]\ttraining's rmse: 0.840972\ttraining's cappa: 0.731181\tvalid_1's rmse: 0.996979\tvalid_1's cappa: 0.584936\n",
      "[72]\ttraining's rmse: 0.839513\ttraining's cappa: 0.732085\tvalid_1's rmse: 0.997005\tvalid_1's cappa: 0.585347\n",
      "[73]\ttraining's rmse: 0.838167\ttraining's cappa: 0.732917\tvalid_1's rmse: 0.997077\tvalid_1's cappa: 0.585288\n",
      "[74]\ttraining's rmse: 0.836822\ttraining's cappa: 0.734192\tvalid_1's rmse: 0.997118\tvalid_1's cappa: 0.58445\n",
      "[75]\ttraining's rmse: 0.835457\ttraining's cappa: 0.735037\tvalid_1's rmse: 0.996803\tvalid_1's cappa: 0.583757\n",
      "[76]\ttraining's rmse: 0.834071\ttraining's cappa: 0.735662\tvalid_1's rmse: 0.996855\tvalid_1's cappa: 0.58586\n",
      "[77]\ttraining's rmse: 0.832485\ttraining's cappa: 0.737203\tvalid_1's rmse: 0.996845\tvalid_1's cappa: 0.584907\n",
      "[78]\ttraining's rmse: 0.831399\ttraining's cappa: 0.737653\tvalid_1's rmse: 0.997467\tvalid_1's cappa: 0.583756\n",
      "[79]\ttraining's rmse: 0.829924\ttraining's cappa: 0.739038\tvalid_1's rmse: 0.997396\tvalid_1's cappa: 0.584046\n",
      "[80]\ttraining's rmse: 0.828568\ttraining's cappa: 0.739956\tvalid_1's rmse: 0.997255\tvalid_1's cappa: 0.584466\n",
      "[81]\ttraining's rmse: 0.827288\ttraining's cappa: 0.741343\tvalid_1's rmse: 0.997029\tvalid_1's cappa: 0.584134\n",
      "[82]\ttraining's rmse: 0.826181\ttraining's cappa: 0.742139\tvalid_1's rmse: 0.997169\tvalid_1's cappa: 0.58386\n",
      "[83]\ttraining's rmse: 0.824899\ttraining's cappa: 0.743405\tvalid_1's rmse: 0.996855\tvalid_1's cappa: 0.585022\n",
      "[84]\ttraining's rmse: 0.823447\ttraining's cappa: 0.744177\tvalid_1's rmse: 0.99683\tvalid_1's cappa: 0.584581\n",
      "[85]\ttraining's rmse: 0.822211\ttraining's cappa: 0.745237\tvalid_1's rmse: 0.997285\tvalid_1's cappa: 0.585005\n",
      "[86]\ttraining's rmse: 0.821214\ttraining's cappa: 0.746125\tvalid_1's rmse: 0.997492\tvalid_1's cappa: 0.584716\n",
      "[87]\ttraining's rmse: 0.81979\ttraining's cappa: 0.747006\tvalid_1's rmse: 0.997466\tvalid_1's cappa: 0.585175\n",
      "[88]\ttraining's rmse: 0.818645\ttraining's cappa: 0.747794\tvalid_1's rmse: 0.997069\tvalid_1's cappa: 0.585866\n",
      "[89]\ttraining's rmse: 0.817438\ttraining's cappa: 0.748611\tvalid_1's rmse: 0.997665\tvalid_1's cappa: 0.584804\n",
      "[90]\ttraining's rmse: 0.81622\ttraining's cappa: 0.749551\tvalid_1's rmse: 0.99777\tvalid_1's cappa: 0.586043\n",
      "[91]\ttraining's rmse: 0.815269\ttraining's cappa: 0.750087\tvalid_1's rmse: 0.99777\tvalid_1's cappa: 0.585932\n",
      "[92]\ttraining's rmse: 0.814012\ttraining's cappa: 0.751266\tvalid_1's rmse: 0.997876\tvalid_1's cappa: 0.584741\n",
      "[93]\ttraining's rmse: 0.812638\ttraining's cappa: 0.752067\tvalid_1's rmse: 0.997845\tvalid_1's cappa: 0.585192\n",
      "[94]\ttraining's rmse: 0.811127\ttraining's cappa: 0.75399\tvalid_1's rmse: 0.997739\tvalid_1's cappa: 0.585061\n",
      "[95]\ttraining's rmse: 0.809892\ttraining's cappa: 0.754854\tvalid_1's rmse: 0.997691\tvalid_1's cappa: 0.584802\n",
      "[96]\ttraining's rmse: 0.808757\ttraining's cappa: 0.756111\tvalid_1's rmse: 0.997653\tvalid_1's cappa: 0.584815\n",
      "[97]\ttraining's rmse: 0.807387\ttraining's cappa: 0.75675\tvalid_1's rmse: 0.997786\tvalid_1's cappa: 0.584376\n",
      "[98]\ttraining's rmse: 0.8063\ttraining's cappa: 0.757592\tvalid_1's rmse: 0.997881\tvalid_1's cappa: 0.584539\n",
      "[99]\ttraining's rmse: 0.804962\ttraining's cappa: 0.759201\tvalid_1's rmse: 0.997895\tvalid_1's cappa: 0.584624\n",
      "[100]\ttraining's rmse: 0.803976\ttraining's cappa: 0.760317\tvalid_1's rmse: 0.998106\tvalid_1's cappa: 0.583862\n",
      "[101]\ttraining's rmse: 0.802853\ttraining's cappa: 0.761197\tvalid_1's rmse: 0.99813\tvalid_1's cappa: 0.582294\n",
      "[102]\ttraining's rmse: 0.801859\ttraining's cappa: 0.762183\tvalid_1's rmse: 0.9983\tvalid_1's cappa: 0.581935\n",
      "[103]\ttraining's rmse: 0.800798\ttraining's cappa: 0.763268\tvalid_1's rmse: 0.998196\tvalid_1's cappa: 0.582385\n",
      "[104]\ttraining's rmse: 0.79956\ttraining's cappa: 0.764266\tvalid_1's rmse: 0.998009\tvalid_1's cappa: 0.582074\n",
      "[105]\ttraining's rmse: 0.798465\ttraining's cappa: 0.765016\tvalid_1's rmse: 0.998005\tvalid_1's cappa: 0.58365\n",
      "[106]\ttraining's rmse: 0.797155\ttraining's cappa: 0.766098\tvalid_1's rmse: 0.998034\tvalid_1's cappa: 0.582259\n",
      "[107]\ttraining's rmse: 0.795743\ttraining's cappa: 0.766946\tvalid_1's rmse: 0.99796\tvalid_1's cappa: 0.582418\n",
      "[108]\ttraining's rmse: 0.794339\ttraining's cappa: 0.768653\tvalid_1's rmse: 0.998187\tvalid_1's cappa: 0.582442\n",
      "[109]\ttraining's rmse: 0.79326\ttraining's cappa: 0.769638\tvalid_1's rmse: 0.998328\tvalid_1's cappa: 0.582475\n",
      "[110]\ttraining's rmse: 0.791925\ttraining's cappa: 0.770529\tvalid_1's rmse: 0.998069\tvalid_1's cappa: 0.581903\n",
      "[111]\ttraining's rmse: 0.790847\ttraining's cappa: 0.770935\tvalid_1's rmse: 0.998039\tvalid_1's cappa: 0.582735\n",
      "[112]\ttraining's rmse: 0.789835\ttraining's cappa: 0.772063\tvalid_1's rmse: 0.997973\tvalid_1's cappa: 0.582583\n",
      "[113]\ttraining's rmse: 0.788558\ttraining's cappa: 0.772702\tvalid_1's rmse: 0.998173\tvalid_1's cappa: 0.581838\n",
      "[114]\ttraining's rmse: 0.787649\ttraining's cappa: 0.773382\tvalid_1's rmse: 0.998316\tvalid_1's cappa: 0.582055\n",
      "[115]\ttraining's rmse: 0.786539\ttraining's cappa: 0.773179\tvalid_1's rmse: 0.998244\tvalid_1's cappa: 0.581846\n",
      "[116]\ttraining's rmse: 0.785414\ttraining's cappa: 0.773703\tvalid_1's rmse: 0.998127\tvalid_1's cappa: 0.581346\n",
      "[117]\ttraining's rmse: 0.784077\ttraining's cappa: 0.774754\tvalid_1's rmse: 0.998083\tvalid_1's cappa: 0.58242\n",
      "[118]\ttraining's rmse: 0.783077\ttraining's cappa: 0.775207\tvalid_1's rmse: 0.998091\tvalid_1's cappa: 0.582644\n",
      "[119]\ttraining's rmse: 0.782336\ttraining's cappa: 0.77559\tvalid_1's rmse: 0.997979\tvalid_1's cappa: 0.583452\n",
      "[120]\ttraining's rmse: 0.781264\ttraining's cappa: 0.776635\tvalid_1's rmse: 0.998211\tvalid_1's cappa: 0.58351\n",
      "[121]\ttraining's rmse: 0.780121\ttraining's cappa: 0.777423\tvalid_1's rmse: 0.99843\tvalid_1's cappa: 0.583828\n",
      "[122]\ttraining's rmse: 0.779025\ttraining's cappa: 0.778096\tvalid_1's rmse: 0.998205\tvalid_1's cappa: 0.584129\n",
      "[123]\ttraining's rmse: 0.77789\ttraining's cappa: 0.779168\tvalid_1's rmse: 0.998043\tvalid_1's cappa: 0.583892\n",
      "[124]\ttraining's rmse: 0.776735\ttraining's cappa: 0.780363\tvalid_1's rmse: 0.998149\tvalid_1's cappa: 0.584221\n",
      "[125]\ttraining's rmse: 0.775435\ttraining's cappa: 0.781382\tvalid_1's rmse: 0.99818\tvalid_1's cappa: 0.58468\n",
      "[126]\ttraining's rmse: 0.774264\ttraining's cappa: 0.783049\tvalid_1's rmse: 0.998216\tvalid_1's cappa: 0.584646\n",
      "[127]\ttraining's rmse: 0.773232\ttraining's cappa: 0.783711\tvalid_1's rmse: 0.998235\tvalid_1's cappa: 0.584699\n",
      "[128]\ttraining's rmse: 0.77239\ttraining's cappa: 0.784714\tvalid_1's rmse: 0.998218\tvalid_1's cappa: 0.58521\n",
      "[129]\ttraining's rmse: 0.771103\ttraining's cappa: 0.785706\tvalid_1's rmse: 0.997835\tvalid_1's cappa: 0.585844\n",
      "[130]\ttraining's rmse: 0.770016\ttraining's cappa: 0.786401\tvalid_1's rmse: 0.998173\tvalid_1's cappa: 0.587181\n",
      "[131]\ttraining's rmse: 0.768913\ttraining's cappa: 0.7872\tvalid_1's rmse: 0.998191\tvalid_1's cappa: 0.586959\n",
      "[132]\ttraining's rmse: 0.767922\ttraining's cappa: 0.787702\tvalid_1's rmse: 0.998199\tvalid_1's cappa: 0.584785\n",
      "[133]\ttraining's rmse: 0.766944\ttraining's cappa: 0.788483\tvalid_1's rmse: 0.998171\tvalid_1's cappa: 0.585979\n",
      "[134]\ttraining's rmse: 0.765864\ttraining's cappa: 0.788686\tvalid_1's rmse: 0.998247\tvalid_1's cappa: 0.584809\n",
      "[135]\ttraining's rmse: 0.764888\ttraining's cappa: 0.789759\tvalid_1's rmse: 0.998213\tvalid_1's cappa: 0.586387\n",
      "[136]\ttraining's rmse: 0.763891\ttraining's cappa: 0.790225\tvalid_1's rmse: 0.997962\tvalid_1's cappa: 0.58516\n",
      "[137]\ttraining's rmse: 0.762628\ttraining's cappa: 0.790696\tvalid_1's rmse: 0.998084\tvalid_1's cappa: 0.584689\n",
      "[138]\ttraining's rmse: 0.761764\ttraining's cappa: 0.791375\tvalid_1's rmse: 0.998333\tvalid_1's cappa: 0.585059\n",
      "[139]\ttraining's rmse: 0.760692\ttraining's cappa: 0.791994\tvalid_1's rmse: 0.998362\tvalid_1's cappa: 0.584195\n",
      "[140]\ttraining's rmse: 0.759703\ttraining's cappa: 0.793006\tvalid_1's rmse: 0.998294\tvalid_1's cappa: 0.584485\n",
      "[141]\ttraining's rmse: 0.758899\ttraining's cappa: 0.7936\tvalid_1's rmse: 0.998297\tvalid_1's cappa: 0.585865\n",
      "[142]\ttraining's rmse: 0.758109\ttraining's cappa: 0.794257\tvalid_1's rmse: 0.998359\tvalid_1's cappa: 0.585565\n",
      "[143]\ttraining's rmse: 0.757089\ttraining's cappa: 0.794774\tvalid_1's rmse: 0.998571\tvalid_1's cappa: 0.585966\n",
      "[144]\ttraining's rmse: 0.756156\ttraining's cappa: 0.795007\tvalid_1's rmse: 0.998663\tvalid_1's cappa: 0.585621\n",
      "[145]\ttraining's rmse: 0.755207\ttraining's cappa: 0.796088\tvalid_1's rmse: 0.998438\tvalid_1's cappa: 0.586108\n",
      "[146]\ttraining's rmse: 0.753955\ttraining's cappa: 0.797254\tvalid_1's rmse: 0.99854\tvalid_1's cappa: 0.587477\n",
      "[147]\ttraining's rmse: 0.752845\ttraining's cappa: 0.798167\tvalid_1's rmse: 0.998766\tvalid_1's cappa: 0.587242\n",
      "[148]\ttraining's rmse: 0.751802\ttraining's cappa: 0.798674\tvalid_1's rmse: 0.9986\tvalid_1's cappa: 0.588218\n",
      "[149]\ttraining's rmse: 0.750951\ttraining's cappa: 0.799328\tvalid_1's rmse: 0.998723\tvalid_1's cappa: 0.587734\n",
      "[150]\ttraining's rmse: 0.74999\ttraining's cappa: 0.799662\tvalid_1's rmse: 0.998755\tvalid_1's cappa: 0.589192\n",
      "[151]\ttraining's rmse: 0.749061\ttraining's cappa: 0.800308\tvalid_1's rmse: 0.999195\tvalid_1's cappa: 0.588491\n",
      "[152]\ttraining's rmse: 0.748043\ttraining's cappa: 0.801192\tvalid_1's rmse: 0.99925\tvalid_1's cappa: 0.587596\n",
      "[153]\ttraining's rmse: 0.747353\ttraining's cappa: 0.801242\tvalid_1's rmse: 0.99965\tvalid_1's cappa: 0.586465\n",
      "[154]\ttraining's rmse: 0.746377\ttraining's cappa: 0.802598\tvalid_1's rmse: 0.999541\tvalid_1's cappa: 0.587555\n",
      "[155]\ttraining's rmse: 0.745511\ttraining's cappa: 0.802735\tvalid_1's rmse: 0.999343\tvalid_1's cappa: 0.587517\n",
      "[156]\ttraining's rmse: 0.74461\ttraining's cappa: 0.803681\tvalid_1's rmse: 0.999596\tvalid_1's cappa: 0.589082\n",
      "[157]\ttraining's rmse: 0.743716\ttraining's cappa: 0.804411\tvalid_1's rmse: 0.999737\tvalid_1's cappa: 0.589992\n",
      "[158]\ttraining's rmse: 0.74294\ttraining's cappa: 0.805323\tvalid_1's rmse: 0.999643\tvalid_1's cappa: 0.589592\n",
      "[159]\ttraining's rmse: 0.741908\ttraining's cappa: 0.80616\tvalid_1's rmse: 0.999483\tvalid_1's cappa: 0.589654\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's rmse: 0.858724\ttraining's cappa: 0.718381\tvalid_1's rmse: 0.996423\tvalid_1's cappa: 0.593023\n",
      "Fold : 4\n",
      "[1]\ttraining's rmse: 1.21188\ttraining's cappa: 0.18025\tvalid_1's rmse: 1.22342\tvalid_1's cappa: 0.169278\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's rmse: 1.17492\ttraining's cappa: 0.313721\tvalid_1's rmse: 1.19101\tvalid_1's cappa: 0.279364\n",
      "[3]\ttraining's rmse: 1.14347\ttraining's cappa: 0.329875\tvalid_1's rmse: 1.16398\tvalid_1's cappa: 0.285411\n",
      "[4]\ttraining's rmse: 1.11661\ttraining's cappa: 0.342147\tvalid_1's rmse: 1.14167\tvalid_1's cappa: 0.300798\n",
      "[5]\ttraining's rmse: 1.09373\ttraining's cappa: 0.346108\tvalid_1's rmse: 1.12251\tvalid_1's cappa: 0.303817\n",
      "[6]\ttraining's rmse: 1.07371\ttraining's cappa: 0.363119\tvalid_1's rmse: 1.1072\tvalid_1's cappa: 0.313039\n",
      "[7]\ttraining's rmse: 1.05617\ttraining's cappa: 0.452937\tvalid_1's rmse: 1.09417\tvalid_1's cappa: 0.380509\n",
      "[8]\ttraining's rmse: 1.04112\ttraining's cappa: 0.546847\tvalid_1's rmse: 1.0835\tvalid_1's cappa: 0.480464\n",
      "[9]\ttraining's rmse: 1.02806\ttraining's cappa: 0.571587\tvalid_1's rmse: 1.07456\tvalid_1's cappa: 0.507282\n",
      "[10]\ttraining's rmse: 1.01529\ttraining's cappa: 0.589774\tvalid_1's rmse: 1.06531\tvalid_1's cappa: 0.519687\n",
      "[11]\ttraining's rmse: 1.00533\ttraining's cappa: 0.605791\tvalid_1's rmse: 1.05865\tvalid_1's cappa: 0.536022\n",
      "[12]\ttraining's rmse: 0.995762\ttraining's cappa: 0.618819\tvalid_1's rmse: 1.05172\tvalid_1's cappa: 0.548593\n",
      "[13]\ttraining's rmse: 0.987539\ttraining's cappa: 0.62785\tvalid_1's rmse: 1.04655\tvalid_1's cappa: 0.558556\n",
      "[14]\ttraining's rmse: 0.9804\ttraining's cappa: 0.632905\tvalid_1's rmse: 1.04248\tvalid_1's cappa: 0.564427\n",
      "[15]\ttraining's rmse: 0.973676\ttraining's cappa: 0.636539\tvalid_1's rmse: 1.03874\tvalid_1's cappa: 0.565668\n",
      "[16]\ttraining's rmse: 0.967587\ttraining's cappa: 0.639595\tvalid_1's rmse: 1.03593\tvalid_1's cappa: 0.563031\n",
      "[17]\ttraining's rmse: 0.962399\ttraining's cappa: 0.641262\tvalid_1's rmse: 1.03356\tvalid_1's cappa: 0.562711\n",
      "[18]\ttraining's rmse: 0.957117\ttraining's cappa: 0.64294\tvalid_1's rmse: 1.03119\tvalid_1's cappa: 0.562976\n",
      "[19]\ttraining's rmse: 0.95218\ttraining's cappa: 0.647137\tvalid_1's rmse: 1.02894\tvalid_1's cappa: 0.563157\n",
      "[20]\ttraining's rmse: 0.947923\ttraining's cappa: 0.649359\tvalid_1's rmse: 1.02701\tvalid_1's cappa: 0.562374\n",
      "[21]\ttraining's rmse: 0.944039\ttraining's cappa: 0.652274\tvalid_1's rmse: 1.02535\tvalid_1's cappa: 0.566134\n",
      "[22]\ttraining's rmse: 0.93993\ttraining's cappa: 0.655204\tvalid_1's rmse: 1.02347\tvalid_1's cappa: 0.565632\n",
      "[23]\ttraining's rmse: 0.935626\ttraining's cappa: 0.657706\tvalid_1's rmse: 1.02153\tvalid_1's cappa: 0.571131\n",
      "[24]\ttraining's rmse: 0.931935\ttraining's cappa: 0.658999\tvalid_1's rmse: 1.02084\tvalid_1's cappa: 0.570347\n",
      "[25]\ttraining's rmse: 0.92813\ttraining's cappa: 0.661969\tvalid_1's rmse: 1.01972\tvalid_1's cappa: 0.571638\n",
      "[26]\ttraining's rmse: 0.925222\ttraining's cappa: 0.662569\tvalid_1's rmse: 1.0188\tvalid_1's cappa: 0.572338\n",
      "[27]\ttraining's rmse: 0.921909\ttraining's cappa: 0.665228\tvalid_1's rmse: 1.01748\tvalid_1's cappa: 0.574821\n",
      "[28]\ttraining's rmse: 0.918889\ttraining's cappa: 0.666906\tvalid_1's rmse: 1.01641\tvalid_1's cappa: 0.574711\n",
      "[29]\ttraining's rmse: 0.915516\ttraining's cappa: 0.669297\tvalid_1's rmse: 1.01578\tvalid_1's cappa: 0.577702\n",
      "[30]\ttraining's rmse: 0.912241\ttraining's cappa: 0.670819\tvalid_1's rmse: 1.01562\tvalid_1's cappa: 0.577582\n",
      "[31]\ttraining's rmse: 0.909357\ttraining's cappa: 0.673558\tvalid_1's rmse: 1.01464\tvalid_1's cappa: 0.577531\n",
      "[32]\ttraining's rmse: 0.906917\ttraining's cappa: 0.674231\tvalid_1's rmse: 1.01401\tvalid_1's cappa: 0.578382\n",
      "[33]\ttraining's rmse: 0.904276\ttraining's cappa: 0.677753\tvalid_1's rmse: 1.01337\tvalid_1's cappa: 0.579\n",
      "[34]\ttraining's rmse: 0.901706\ttraining's cappa: 0.680183\tvalid_1's rmse: 1.01336\tvalid_1's cappa: 0.57836\n",
      "[35]\ttraining's rmse: 0.89907\ttraining's cappa: 0.681314\tvalid_1's rmse: 1.01299\tvalid_1's cappa: 0.577624\n",
      "[36]\ttraining's rmse: 0.896771\ttraining's cappa: 0.683505\tvalid_1's rmse: 1.01268\tvalid_1's cappa: 0.580309\n",
      "[37]\ttraining's rmse: 0.894676\ttraining's cappa: 0.685148\tvalid_1's rmse: 1.01254\tvalid_1's cappa: 0.580359\n",
      "[38]\ttraining's rmse: 0.89228\ttraining's cappa: 0.687213\tvalid_1's rmse: 1.01299\tvalid_1's cappa: 0.577168\n",
      "[39]\ttraining's rmse: 0.890115\ttraining's cappa: 0.688051\tvalid_1's rmse: 1.01247\tvalid_1's cappa: 0.5796\n",
      "[40]\ttraining's rmse: 0.888024\ttraining's cappa: 0.690848\tvalid_1's rmse: 1.01204\tvalid_1's cappa: 0.580972\n",
      "[41]\ttraining's rmse: 0.885598\ttraining's cappa: 0.692187\tvalid_1's rmse: 1.01139\tvalid_1's cappa: 0.583336\n",
      "[42]\ttraining's rmse: 0.883462\ttraining's cappa: 0.695032\tvalid_1's rmse: 1.01121\tvalid_1's cappa: 0.582764\n",
      "[43]\ttraining's rmse: 0.88137\ttraining's cappa: 0.696517\tvalid_1's rmse: 1.01097\tvalid_1's cappa: 0.583009\n",
      "[44]\ttraining's rmse: 0.879403\ttraining's cappa: 0.698734\tvalid_1's rmse: 1.01117\tvalid_1's cappa: 0.581508\n",
      "[45]\ttraining's rmse: 0.877401\ttraining's cappa: 0.699789\tvalid_1's rmse: 1.0107\tvalid_1's cappa: 0.582564\n",
      "[46]\ttraining's rmse: 0.875217\ttraining's cappa: 0.702407\tvalid_1's rmse: 1.01051\tvalid_1's cappa: 0.583807\n",
      "[47]\ttraining's rmse: 0.873395\ttraining's cappa: 0.704288\tvalid_1's rmse: 1.01026\tvalid_1's cappa: 0.58294\n",
      "[48]\ttraining's rmse: 0.871756\ttraining's cappa: 0.705916\tvalid_1's rmse: 1.01042\tvalid_1's cappa: 0.582467\n",
      "[49]\ttraining's rmse: 0.869935\ttraining's cappa: 0.707576\tvalid_1's rmse: 1.01068\tvalid_1's cappa: 0.580326\n",
      "[50]\ttraining's rmse: 0.868314\ttraining's cappa: 0.708793\tvalid_1's rmse: 1.01048\tvalid_1's cappa: 0.578952\n",
      "[51]\ttraining's rmse: 0.866505\ttraining's cappa: 0.710205\tvalid_1's rmse: 1.01008\tvalid_1's cappa: 0.579162\n",
      "[52]\ttraining's rmse: 0.864819\ttraining's cappa: 0.711906\tvalid_1's rmse: 1.00953\tvalid_1's cappa: 0.580345\n",
      "[53]\ttraining's rmse: 0.863281\ttraining's cappa: 0.713183\tvalid_1's rmse: 1.00992\tvalid_1's cappa: 0.579988\n",
      "[54]\ttraining's rmse: 0.861455\ttraining's cappa: 0.714665\tvalid_1's rmse: 1.00989\tvalid_1's cappa: 0.578728\n",
      "[55]\ttraining's rmse: 0.859747\ttraining's cappa: 0.715694\tvalid_1's rmse: 1.00989\tvalid_1's cappa: 0.581394\n",
      "[56]\ttraining's rmse: 0.858053\ttraining's cappa: 0.717287\tvalid_1's rmse: 1.01017\tvalid_1's cappa: 0.580431\n",
      "[57]\ttraining's rmse: 0.856417\ttraining's cappa: 0.718757\tvalid_1's rmse: 1.00999\tvalid_1's cappa: 0.581384\n",
      "[58]\ttraining's rmse: 0.854843\ttraining's cappa: 0.719669\tvalid_1's rmse: 1.00987\tvalid_1's cappa: 0.58045\n",
      "[59]\ttraining's rmse: 0.853149\ttraining's cappa: 0.720636\tvalid_1's rmse: 1.01025\tvalid_1's cappa: 0.580488\n",
      "[60]\ttraining's rmse: 0.851488\ttraining's cappa: 0.722705\tvalid_1's rmse: 1.0103\tvalid_1's cappa: 0.58045\n",
      "[61]\ttraining's rmse: 0.850022\ttraining's cappa: 0.723199\tvalid_1's rmse: 1.01035\tvalid_1's cappa: 0.581498\n",
      "[62]\ttraining's rmse: 0.848587\ttraining's cappa: 0.723687\tvalid_1's rmse: 1.01029\tvalid_1's cappa: 0.57968\n",
      "[63]\ttraining's rmse: 0.847032\ttraining's cappa: 0.724619\tvalid_1's rmse: 1.01004\tvalid_1's cappa: 0.579659\n",
      "[64]\ttraining's rmse: 0.845469\ttraining's cappa: 0.726274\tvalid_1's rmse: 1.0102\tvalid_1's cappa: 0.582693\n",
      "[65]\ttraining's rmse: 0.843727\ttraining's cappa: 0.727921\tvalid_1's rmse: 1.00989\tvalid_1's cappa: 0.581834\n",
      "[66]\ttraining's rmse: 0.842254\ttraining's cappa: 0.729313\tvalid_1's rmse: 1.00981\tvalid_1's cappa: 0.583368\n",
      "[67]\ttraining's rmse: 0.840781\ttraining's cappa: 0.730513\tvalid_1's rmse: 1.0099\tvalid_1's cappa: 0.583669\n",
      "[68]\ttraining's rmse: 0.839404\ttraining's cappa: 0.732089\tvalid_1's rmse: 1.00981\tvalid_1's cappa: 0.584572\n",
      "[69]\ttraining's rmse: 0.837855\ttraining's cappa: 0.733517\tvalid_1's rmse: 1.0095\tvalid_1's cappa: 0.584414\n",
      "[70]\ttraining's rmse: 0.836586\ttraining's cappa: 0.7343\tvalid_1's rmse: 1.00969\tvalid_1's cappa: 0.584284\n",
      "[71]\ttraining's rmse: 0.835282\ttraining's cappa: 0.735192\tvalid_1's rmse: 1.00995\tvalid_1's cappa: 0.583173\n",
      "[72]\ttraining's rmse: 0.83381\ttraining's cappa: 0.736329\tvalid_1's rmse: 1.0103\tvalid_1's cappa: 0.583098\n",
      "[73]\ttraining's rmse: 0.83229\ttraining's cappa: 0.738276\tvalid_1's rmse: 1.01056\tvalid_1's cappa: 0.582337\n",
      "[74]\ttraining's rmse: 0.830892\ttraining's cappa: 0.739064\tvalid_1's rmse: 1.01053\tvalid_1's cappa: 0.58275\n",
      "[75]\ttraining's rmse: 0.829445\ttraining's cappa: 0.740303\tvalid_1's rmse: 1.01024\tvalid_1's cappa: 0.583628\n",
      "[76]\ttraining's rmse: 0.828166\ttraining's cappa: 0.741212\tvalid_1's rmse: 1.01018\tvalid_1's cappa: 0.583165\n",
      "[77]\ttraining's rmse: 0.826849\ttraining's cappa: 0.742469\tvalid_1's rmse: 1.01047\tvalid_1's cappa: 0.582386\n",
      "[78]\ttraining's rmse: 0.825428\ttraining's cappa: 0.742824\tvalid_1's rmse: 1.01089\tvalid_1's cappa: 0.580707\n",
      "[79]\ttraining's rmse: 0.824146\ttraining's cappa: 0.743397\tvalid_1's rmse: 1.01076\tvalid_1's cappa: 0.58147\n",
      "[80]\ttraining's rmse: 0.822596\ttraining's cappa: 0.744644\tvalid_1's rmse: 1.0109\tvalid_1's cappa: 0.581715\n",
      "[81]\ttraining's rmse: 0.821343\ttraining's cappa: 0.746326\tvalid_1's rmse: 1.01094\tvalid_1's cappa: 0.580199\n",
      "[82]\ttraining's rmse: 0.820219\ttraining's cappa: 0.746811\tvalid_1's rmse: 1.01095\tvalid_1's cappa: 0.580564\n",
      "[83]\ttraining's rmse: 0.818939\ttraining's cappa: 0.747453\tvalid_1's rmse: 1.01079\tvalid_1's cappa: 0.581554\n",
      "[84]\ttraining's rmse: 0.817634\ttraining's cappa: 0.749\tvalid_1's rmse: 1.01085\tvalid_1's cappa: 0.581977\n",
      "[85]\ttraining's rmse: 0.816255\ttraining's cappa: 0.749905\tvalid_1's rmse: 1.01098\tvalid_1's cappa: 0.581984\n",
      "[86]\ttraining's rmse: 0.815266\ttraining's cappa: 0.75069\tvalid_1's rmse: 1.01097\tvalid_1's cappa: 0.581987\n",
      "[87]\ttraining's rmse: 0.813956\ttraining's cappa: 0.751067\tvalid_1's rmse: 1.0111\tvalid_1's cappa: 0.579822\n",
      "[88]\ttraining's rmse: 0.812745\ttraining's cappa: 0.752023\tvalid_1's rmse: 1.01095\tvalid_1's cappa: 0.580946\n",
      "[89]\ttraining's rmse: 0.811459\ttraining's cappa: 0.753688\tvalid_1's rmse: 1.01093\tvalid_1's cappa: 0.58002\n",
      "[90]\ttraining's rmse: 0.810503\ttraining's cappa: 0.754268\tvalid_1's rmse: 1.01095\tvalid_1's cappa: 0.580666\n",
      "[91]\ttraining's rmse: 0.809081\ttraining's cappa: 0.754499\tvalid_1's rmse: 1.01099\tvalid_1's cappa: 0.580806\n",
      "[92]\ttraining's rmse: 0.807765\ttraining's cappa: 0.755405\tvalid_1's rmse: 1.01092\tvalid_1's cappa: 0.580372\n",
      "[93]\ttraining's rmse: 0.806542\ttraining's cappa: 0.756377\tvalid_1's rmse: 1.01096\tvalid_1's cappa: 0.579338\n",
      "[94]\ttraining's rmse: 0.805038\ttraining's cappa: 0.757986\tvalid_1's rmse: 1.01101\tvalid_1's cappa: 0.579004\n",
      "[95]\ttraining's rmse: 0.803851\ttraining's cappa: 0.758678\tvalid_1's rmse: 1.01101\tvalid_1's cappa: 0.578518\n",
      "[96]\ttraining's rmse: 0.802608\ttraining's cappa: 0.759846\tvalid_1's rmse: 1.01081\tvalid_1's cappa: 0.578875\n",
      "[97]\ttraining's rmse: 0.801596\ttraining's cappa: 0.760509\tvalid_1's rmse: 1.0105\tvalid_1's cappa: 0.579748\n",
      "[98]\ttraining's rmse: 0.800413\ttraining's cappa: 0.761653\tvalid_1's rmse: 1.01093\tvalid_1's cappa: 0.579043\n",
      "[99]\ttraining's rmse: 0.79936\ttraining's cappa: 0.762288\tvalid_1's rmse: 1.01078\tvalid_1's cappa: 0.57934\n",
      "[100]\ttraining's rmse: 0.798004\ttraining's cappa: 0.763629\tvalid_1's rmse: 1.01072\tvalid_1's cappa: 0.579346\n",
      "[101]\ttraining's rmse: 0.796854\ttraining's cappa: 0.764936\tvalid_1's rmse: 1.0108\tvalid_1's cappa: 0.580659\n",
      "[102]\ttraining's rmse: 0.795446\ttraining's cappa: 0.766152\tvalid_1's rmse: 1.01055\tvalid_1's cappa: 0.580436\n",
      "[103]\ttraining's rmse: 0.794253\ttraining's cappa: 0.767336\tvalid_1's rmse: 1.01043\tvalid_1's cappa: 0.579367\n",
      "[104]\ttraining's rmse: 0.792809\ttraining's cappa: 0.767639\tvalid_1's rmse: 1.01028\tvalid_1's cappa: 0.57879\n",
      "[105]\ttraining's rmse: 0.791734\ttraining's cappa: 0.768618\tvalid_1's rmse: 1.0104\tvalid_1's cappa: 0.578444\n",
      "[106]\ttraining's rmse: 0.790582\ttraining's cappa: 0.769021\tvalid_1's rmse: 1.01041\tvalid_1's cappa: 0.577866\n",
      "[107]\ttraining's rmse: 0.789305\ttraining's cappa: 0.769678\tvalid_1's rmse: 1.01053\tvalid_1's cappa: 0.578109\n",
      "[108]\ttraining's rmse: 0.788538\ttraining's cappa: 0.770369\tvalid_1's rmse: 1.01047\tvalid_1's cappa: 0.578022\n",
      "[109]\ttraining's rmse: 0.787379\ttraining's cappa: 0.772064\tvalid_1's rmse: 1.01068\tvalid_1's cappa: 0.579045\n",
      "[110]\ttraining's rmse: 0.78639\ttraining's cappa: 0.772208\tvalid_1's rmse: 1.01104\tvalid_1's cappa: 0.578135\n",
      "[111]\ttraining's rmse: 0.785306\ttraining's cappa: 0.772411\tvalid_1's rmse: 1.01103\tvalid_1's cappa: 0.579384\n",
      "[112]\ttraining's rmse: 0.784028\ttraining's cappa: 0.773479\tvalid_1's rmse: 1.01068\tvalid_1's cappa: 0.57995\n",
      "[113]\ttraining's rmse: 0.782587\ttraining's cappa: 0.774127\tvalid_1's rmse: 1.01095\tvalid_1's cappa: 0.579483\n",
      "[114]\ttraining's rmse: 0.781778\ttraining's cappa: 0.775334\tvalid_1's rmse: 1.01104\tvalid_1's cappa: 0.580294\n",
      "[115]\ttraining's rmse: 0.78064\ttraining's cappa: 0.775797\tvalid_1's rmse: 1.01102\tvalid_1's cappa: 0.580349\n",
      "[116]\ttraining's rmse: 0.779335\ttraining's cappa: 0.776961\tvalid_1's rmse: 1.01106\tvalid_1's cappa: 0.578975\n",
      "[117]\ttraining's rmse: 0.778418\ttraining's cappa: 0.777802\tvalid_1's rmse: 1.01094\tvalid_1's cappa: 0.578615\n",
      "[118]\ttraining's rmse: 0.777287\ttraining's cappa: 0.778254\tvalid_1's rmse: 1.01063\tvalid_1's cappa: 0.579354\n",
      "[119]\ttraining's rmse: 0.776375\ttraining's cappa: 0.778436\tvalid_1's rmse: 1.01062\tvalid_1's cappa: 0.578735\n",
      "[120]\ttraining's rmse: 0.77548\ttraining's cappa: 0.779011\tvalid_1's rmse: 1.0106\tvalid_1's cappa: 0.580638\n",
      "[121]\ttraining's rmse: 0.774509\ttraining's cappa: 0.77984\tvalid_1's rmse: 1.01057\tvalid_1's cappa: 0.581931\n",
      "[122]\ttraining's rmse: 0.77335\ttraining's cappa: 0.781345\tvalid_1's rmse: 1.01081\tvalid_1's cappa: 0.580929\n",
      "[123]\ttraining's rmse: 0.77208\ttraining's cappa: 0.78227\tvalid_1's rmse: 1.01094\tvalid_1's cappa: 0.579599\n",
      "[124]\ttraining's rmse: 0.771137\ttraining's cappa: 0.783158\tvalid_1's rmse: 1.0111\tvalid_1's cappa: 0.578342\n",
      "[125]\ttraining's rmse: 0.769827\ttraining's cappa: 0.783997\tvalid_1's rmse: 1.01078\tvalid_1's cappa: 0.579154\n",
      "[126]\ttraining's rmse: 0.768859\ttraining's cappa: 0.785083\tvalid_1's rmse: 1.01088\tvalid_1's cappa: 0.578839\n",
      "[127]\ttraining's rmse: 0.767925\ttraining's cappa: 0.785818\tvalid_1's rmse: 1.0107\tvalid_1's cappa: 0.579097\n",
      "[128]\ttraining's rmse: 0.766903\ttraining's cappa: 0.786482\tvalid_1's rmse: 1.01081\tvalid_1's cappa: 0.578325\n",
      "[129]\ttraining's rmse: 0.765687\ttraining's cappa: 0.786934\tvalid_1's rmse: 1.01093\tvalid_1's cappa: 0.577406\n",
      "[130]\ttraining's rmse: 0.764631\ttraining's cappa: 0.787915\tvalid_1's rmse: 1.01099\tvalid_1's cappa: 0.578371\n",
      "[131]\ttraining's rmse: 0.763792\ttraining's cappa: 0.788221\tvalid_1's rmse: 1.01085\tvalid_1's cappa: 0.577676\n",
      "[132]\ttraining's rmse: 0.762703\ttraining's cappa: 0.789061\tvalid_1's rmse: 1.01099\tvalid_1's cappa: 0.577505\n",
      "[133]\ttraining's rmse: 0.76176\ttraining's cappa: 0.789915\tvalid_1's rmse: 1.01115\tvalid_1's cappa: 0.577805\n",
      "[134]\ttraining's rmse: 0.761005\ttraining's cappa: 0.790384\tvalid_1's rmse: 1.011\tvalid_1's cappa: 0.578161\n",
      "[135]\ttraining's rmse: 0.759858\ttraining's cappa: 0.7909\tvalid_1's rmse: 1.01121\tvalid_1's cappa: 0.57859\n",
      "[136]\ttraining's rmse: 0.759078\ttraining's cappa: 0.791188\tvalid_1's rmse: 1.01126\tvalid_1's cappa: 0.578303\n",
      "[137]\ttraining's rmse: 0.757997\ttraining's cappa: 0.791544\tvalid_1's rmse: 1.01141\tvalid_1's cappa: 0.577985\n",
      "[138]\ttraining's rmse: 0.75694\ttraining's cappa: 0.792109\tvalid_1's rmse: 1.01173\tvalid_1's cappa: 0.577792\n",
      "[139]\ttraining's rmse: 0.755914\ttraining's cappa: 0.792687\tvalid_1's rmse: 1.01173\tvalid_1's cappa: 0.577363\n",
      "[140]\ttraining's rmse: 0.754861\ttraining's cappa: 0.793422\tvalid_1's rmse: 1.01145\tvalid_1's cappa: 0.578375\n",
      "[141]\ttraining's rmse: 0.754\ttraining's cappa: 0.794179\tvalid_1's rmse: 1.01176\tvalid_1's cappa: 0.57779\n",
      "[142]\ttraining's rmse: 0.752992\ttraining's cappa: 0.79522\tvalid_1's rmse: 1.01169\tvalid_1's cappa: 0.577826\n",
      "[143]\ttraining's rmse: 0.752356\ttraining's cappa: 0.79563\tvalid_1's rmse: 1.01161\tvalid_1's cappa: 0.578231\n",
      "[144]\ttraining's rmse: 0.75128\ttraining's cappa: 0.795822\tvalid_1's rmse: 1.01153\tvalid_1's cappa: 0.577412\n",
      "[145]\ttraining's rmse: 0.750126\ttraining's cappa: 0.796265\tvalid_1's rmse: 1.01166\tvalid_1's cappa: 0.576596\n",
      "[146]\ttraining's rmse: 0.749064\ttraining's cappa: 0.797502\tvalid_1's rmse: 1.01194\tvalid_1's cappa: 0.57686\n",
      "[147]\ttraining's rmse: 0.748068\ttraining's cappa: 0.798096\tvalid_1's rmse: 1.01163\tvalid_1's cappa: 0.576498\n",
      "[148]\ttraining's rmse: 0.747161\ttraining's cappa: 0.798662\tvalid_1's rmse: 1.01169\tvalid_1's cappa: 0.576257\n",
      "[149]\ttraining's rmse: 0.746219\ttraining's cappa: 0.79915\tvalid_1's rmse: 1.01183\tvalid_1's cappa: 0.574983\n",
      "[150]\ttraining's rmse: 0.745167\ttraining's cappa: 0.799644\tvalid_1's rmse: 1.01178\tvalid_1's cappa: 0.575146\n",
      "[151]\ttraining's rmse: 0.744114\ttraining's cappa: 0.800463\tvalid_1's rmse: 1.01184\tvalid_1's cappa: 0.575435\n",
      "[152]\ttraining's rmse: 0.743068\ttraining's cappa: 0.80115\tvalid_1's rmse: 1.01187\tvalid_1's cappa: 0.575801\n",
      "[153]\ttraining's rmse: 0.742089\ttraining's cappa: 0.801606\tvalid_1's rmse: 1.01208\tvalid_1's cappa: 0.575557\n",
      "[154]\ttraining's rmse: 0.741095\ttraining's cappa: 0.802254\tvalid_1's rmse: 1.01216\tvalid_1's cappa: 0.575148\n",
      "[155]\ttraining's rmse: 0.740492\ttraining's cappa: 0.802553\tvalid_1's rmse: 1.01221\tvalid_1's cappa: 0.575032\n",
      "[156]\ttraining's rmse: 0.739505\ttraining's cappa: 0.803259\tvalid_1's rmse: 1.01206\tvalid_1's cappa: 0.575345\n",
      "[157]\ttraining's rmse: 0.738838\ttraining's cappa: 0.803878\tvalid_1's rmse: 1.0122\tvalid_1's cappa: 0.574447\n",
      "[158]\ttraining's rmse: 0.737896\ttraining's cappa: 0.804607\tvalid_1's rmse: 1.01227\tvalid_1's cappa: 0.574294\n",
      "[159]\ttraining's rmse: 0.737072\ttraining's cappa: 0.804956\tvalid_1's rmse: 1.01237\tvalid_1's cappa: 0.573599\n",
      "[160]\ttraining's rmse: 0.735829\ttraining's cappa: 0.805759\tvalid_1's rmse: 1.01242\tvalid_1's cappa: 0.574493\n",
      "[161]\ttraining's rmse: 0.7351\ttraining's cappa: 0.806198\tvalid_1's rmse: 1.0125\tvalid_1's cappa: 0.57362\n",
      "[162]\ttraining's rmse: 0.733983\ttraining's cappa: 0.807257\tvalid_1's rmse: 1.01236\tvalid_1's cappa: 0.572984\n",
      "[163]\ttraining's rmse: 0.732985\ttraining's cappa: 0.807752\tvalid_1's rmse: 1.01225\tvalid_1's cappa: 0.573944\n",
      "[164]\ttraining's rmse: 0.732031\ttraining's cappa: 0.809241\tvalid_1's rmse: 1.0125\tvalid_1's cappa: 0.574225\n",
      "[165]\ttraining's rmse: 0.731001\ttraining's cappa: 0.810266\tvalid_1's rmse: 1.01232\tvalid_1's cappa: 0.573816\n",
      "[166]\ttraining's rmse: 0.730372\ttraining's cappa: 0.811084\tvalid_1's rmse: 1.01221\tvalid_1's cappa: 0.575123\n",
      "[167]\ttraining's rmse: 0.729519\ttraining's cappa: 0.811528\tvalid_1's rmse: 1.01221\tvalid_1's cappa: 0.574292\n",
      "[168]\ttraining's rmse: 0.728847\ttraining's cappa: 0.812157\tvalid_1's rmse: 1.01238\tvalid_1's cappa: 0.57258\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's rmse: 0.839404\ttraining's cappa: 0.732089\tvalid_1's rmse: 1.00981\tvalid_1's cappa: 0.584572\n"
     ]
    }
   ],
   "source": [
    "n_fold = 5\n",
    "models = []\n",
    "KFold = GroupKFold(n_splits=n_fold)\n",
    "for i, (train_idx, val_idx) in enumerate(KFold.split(X, y, X['installation_id'])):\n",
    "    X_r = X.drop(columns=['installation_id'], axis=1)\n",
    "    X_train, y_train, X_val, y_val = X_r.iloc[train_idx], y.iloc[train_idx], X_r.iloc[val_idx], y.iloc[val_idx]\n",
    "    print(f'Fold : {i}')\n",
    "    model = lgb.LGBMRegressor()\n",
    "    model = model.set_params(**params)\n",
    "    model.fit(X=X_train, y=y_train,\n",
    "              eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "              eval_metric=eval_qwk_lgb_regr,\n",
    "              early_stopping_rounds=params['early_stopping_rounds'])\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import scipy as sp\n",
    "class OptimizedRounder(object):\n",
    "    \"\"\"\n",
    "    An optimizer for rounding thresholds\n",
    "    to maximize Quadratic Weighted Kappa (QWK) score\n",
    "    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        \"\"\"\n",
    "        Get loss according to\n",
    "        using current coefficients\n",
    "        \n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "        return -qwk(y, X_p)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Optimize rounding thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        \"\"\"\n",
    "        Make predictions with specified thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        \"\"\"\n",
    "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "\n",
    "    def coefficients(self):\n",
    "        \"\"\"\n",
    "        Return the optimized coefficients\n",
    "        \"\"\"\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>installation_duration_time</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true_record</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>acc_accuracy</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>4070</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clip</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>3120</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>false_record</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>3121</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>asses_time_mean</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>4020</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature  importance\n",
       "402  installation_duration_time          90\n",
       "4                   true_record          76\n",
       "9                  acc_accuracy          63\n",
       "348                        4070          36\n",
       "0                          Clip          35\n",
       "335                        3120          34\n",
       "5                  false_record          33\n",
       "336                        3121          31\n",
       "7               asses_time_mean          30\n",
       "337                        4020          29"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = list(zip(X_r.columns, list(model.feature_importances_)))\n",
    "dt = pd.DataFrame(feature_importance,  columns=['feature' ,'importance'])\n",
    "dt.sort_values(by=['importance'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.69 s, sys: 284 ms, total: 3.98 s\n",
      "Wall time: 2.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pr_sum = np.zeros((y.shape))\n",
    "for model in models:\n",
    "    pr = model.predict(X_r)\n",
    "    pr_sum += pr\n",
    "pr1 = pr_sum / len(models)\n",
    "optR = OptimizedRounder()\n",
    "optR.fit(pr1.reshape(-1,), y)\n",
    "coefficients = optR.coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96609687, 1.70854351, 2.23756297])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7167347829413321"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_preds = optR.predict(pr1.reshape(-1, ), coefficients)\n",
    "qwk(y, opt_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 724 ms, sys: 4 ms, total: 728 ms\n",
      "Wall time: 475 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pr_sum = np.zeros((test_predict.shape[0]))\n",
    "for model in models:\n",
    "    pr = model.predict(test_predict)\n",
    "    pr_sum += pr\n",
    "y_pred = pr_sum / len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred <= coefficients[0]] = 0\n",
    "y_pred[np.where(np.logical_and(y_pred > coefficients[0], y_pred <= coefficients[1]))] = 1\n",
    "y_pred[np.where(np.logical_and(y_pred > coefficients[1], y_pred <= coefficients[2]))] = 2\n",
    "y_pred[y_pred > coefficients[2]] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['accuracy_group'] = y_pred.astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "24a3cd62cedf4172b2d662389de73f75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d87b987cb6d34dc484768df8b7348709",
       "placeholder": "​",
       "style": "IPY_MODEL_f8c00239741446f581ba8eac883dec3e",
       "value": " 4242/4242 [13:02&lt;00:00,  5.42it/s]"
      }
     },
     "430cf2b7dbc546f59ff272070123a7e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a038e83d02f47eaa8b60062c8e15874": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "52be8aeb01114294a11733300c33ac55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "550963c3edec4eb690e7f0cc1f56863a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "installation_id: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4a038e83d02f47eaa8b60062c8e15874",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e94d7c16e76f4a91bf8d650c588f680e",
       "value": 1000
      }
     },
     "586223925d9648c19f648a55a1a26ade": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63c58c2d216e4724b422c570b9d50852": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7a807ca98cf0442785e077ca3cf607bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_550963c3edec4eb690e7f0cc1f56863a",
        "IPY_MODEL_8b8ef238974a44db98ddd8095887e447"
       ],
       "layout": "IPY_MODEL_430cf2b7dbc546f59ff272070123a7e7"
      }
     },
     "8b8ef238974a44db98ddd8095887e447": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bbd9c9722d8a4e51ab61197e2f24071e",
       "placeholder": "​",
       "style": "IPY_MODEL_52be8aeb01114294a11733300c33ac55",
       "value": " 1000/1000 [07:47&lt;00:00,  2.14it/s]"
      }
     },
     "955112c8da95417cbefb02d2a4ef9fdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "installation_id: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_586223925d9648c19f648a55a1a26ade",
       "max": 4242,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_daf670cb98ab4336a5e15c378fa0f339",
       "value": 4242
      }
     },
     "bbd9c9722d8a4e51ab61197e2f24071e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d87b987cb6d34dc484768df8b7348709": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "daf670cb98ab4336a5e15c378fa0f339": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "e4d6346b20dc4b8d84184f22bb73f950": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_955112c8da95417cbefb02d2a4ef9fdb",
        "IPY_MODEL_24a3cd62cedf4172b2d662389de73f75"
       ],
       "layout": "IPY_MODEL_63c58c2d216e4724b422c570b9d50852"
      }
     },
     "e94d7c16e76f4a91bf8d650c588f680e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f8c00239741446f581ba8eac883dec3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
