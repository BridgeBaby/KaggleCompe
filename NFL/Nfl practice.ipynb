{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "38108510-9e82-4b61-a278-07ce5ce08bdf",
    "_uuid": "cd653f4d-0cd1-4b02-8a00-538f60aa9651"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaggle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5fae9b54aa76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkaggle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompetitions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnflrush\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kaggle'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from kaggle.competitions import nflrush\n",
    "import tqdm\n",
    "import re\n",
    "from string import punctuation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "mpl.rcParams['figure.figsize'] = [15, 10]\n",
    "pd.set_option('max_columns', 100)\n",
    "\n",
    "env = nflrush.make_env()\n",
    "\n",
    "train = pd.read_csv('/input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})\n",
    "\n",
    "train.head()\n",
    "\n",
    "train['DefendersInTheBox_vs_Distance'] = train['DefendersInTheBox'] / train['Distance']\n",
    "\n",
    "cat_features = []\n",
    "for col in train.columns:\n",
    "    if train[col].dtype =='object':\n",
    "        cat_features.append((col, len(train[col].unique())))\n",
    "\n",
    "train['StadiumType'].value_counts()\n",
    "\n",
    "def clean_StadiumType(txt):\n",
    "    if pd.isna(txt):\n",
    "        return np.nan\n",
    "    txt = txt.lower()\n",
    "    txt = ''.join([c for c in txt if c not in punctuation])\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    txt = txt.strip()\n",
    "    txt = txt.replace('outside', 'outdoor')\n",
    "    txt = txt.replace('outdor', 'outdoor')\n",
    "    txt = txt.replace('outddors', 'outdoor')\n",
    "    txt = txt.replace('outdoors', 'outdoor')\n",
    "    txt = txt.replace('oudoor', 'outdoor')\n",
    "    txt = txt.replace('indoors', 'indoor')\n",
    "    txt = txt.replace('ourdoor', 'outdoor')\n",
    "    txt = txt.replace('retractable', 'rtr.')\n",
    "    return txt\n",
    "\n",
    "train['StadiumType'] = train['StadiumType'].apply(clean_StadiumType)\n",
    "\n",
    "def transform_StadiumType(txt):\n",
    "    if pd.isna(txt):\n",
    "        return np.nan\n",
    "    if 'outdoor' in txt or 'open' in txt:\n",
    "        return 1\n",
    "    if 'indoor' in txt or 'closed' in txt:\n",
    "        return 0\n",
    "    return np.nan\n",
    "\n",
    "train['StadiumType'] = train['StadiumType'].apply(transform_StadiumType)\n",
    "\n",
    "Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', \n",
    "        'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', \n",
    "        'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', \n",
    "        'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', \n",
    "        'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n",
    "\n",
    "train['Turf'] = train['Turf'].map(Turf)\n",
    "train['Turf'] = train['Turf'] == 'Natural'\n",
    "\n",
    "train[(train['PossessionTeam']!=train['HomeTeamAbbr']) & (train['PossessionTeam']!=train['VisitorTeamAbbr'])][['PossessionTeam', 'HomeTeamAbbr', 'VisitorTeamAbbr']]\n",
    "\n",
    "sorted(train['HomeTeamAbbr'].unique()) == sorted(train['VisitorTeamAbbr'].unique())\n",
    "\n",
    "diff_abbr = []\n",
    "for x,y  in zip(sorted(train['HomeTeamAbbr'].unique()), sorted(train['PossessionTeam'].unique())):\n",
    "    if x!=y:\n",
    "        print(x + \" \" + y)\n",
    "\n",
    "map_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\n",
    "for x in train['PossessionTeam'].unique():\n",
    "    map_abbr[x] = x\n",
    "\n",
    "train['PossessionTeam'] = train['PossessionTeam'].map(map_abbr)\n",
    "train['HomeTeamAbbr'] = train['HomeTeamAbbr'].map(map_abbr)\n",
    "train['VisitorTeamAbbr'] = train['VisitorTeamAbbr'].map(map_abbr)\n",
    "\n",
    "train['HomePossesion'] = train['PossessionTeam'] == train['HomeTeamAbbr']\n",
    "\n",
    "train['Field_eq_Possession'] = train['FieldPosition'] == train['PossessionTeam']\n",
    "train['HomeField'] = train['FieldPosition'] == train['HomeTeamAbbr']\n",
    "\n",
    "train['HomeField'].value_counts()\n",
    "\n",
    "offense_type = train['OffenseFormation'].unique()\n",
    "train['OffenseFormation'].value_counts()\n",
    "\n",
    "train = pd.concat([train.drop(['OffenseFormation'], axis=1), pd.get_dummies(train['OffenseFormation'], prefix='Formation')], axis=1)\n",
    "dummy_col = train.columns\n",
    "\n",
    "train['GameClock'].value_counts()\n",
    "\n",
    "def GameClock_to_Second(txt):\n",
    "    txt = txt.split(':')\n",
    "    txt = int(txt[0]) * 60 + int(txt[1]) + int(txt[2]) / 60\n",
    "    return txt\n",
    "\n",
    "train['GameClock'] = train['GameClock'].apply(GameClock_to_Second)\n",
    "\n",
    "sns.distplot(train['GameClock']);\n",
    "\n",
    "train['PlayerHeight'] = train['PlayerHeight'] \\\n",
    "    .apply(lambda x: int(x.split('-')[0])*12 + int(x.split('-')[1]))\n",
    "\n",
    "train['PlayerBMI'] = 703*(train['PlayerWeight']/(train['PlayerHeight'])**2)\n",
    "\n",
    "train['TimeHandoff']\n",
    "\n",
    "train['TimeHandoff'] = train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "train['TimeSnap'] = train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "\n",
    "train['TimeDelta'] = train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n",
    "\n",
    "train['PlayerBirthDate'] = train['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "\n",
    "seconds_in_year = 60*60*24*365.25\n",
    "train['PlayerAge'] = train.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n",
    "\n",
    "train = train.drop(['TimeHandoff', 'TimeSnap', 'PlayerBirthDate'], axis=1)\n",
    "\n",
    "train['WindSpeed'].value_counts()\n",
    "\n",
    "train['WindSpeed'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "\n",
    "train['WindSpeed'] = train['WindSpeed'] \\\n",
    "    .apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "\n",
    "train['WindSpeed'] = train['WindSpeed'] \\\n",
    "    .apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "\n",
    "def str_to_float(txt):\n",
    "    try:\n",
    "        return float(txt)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "train['WindSpeed'] = train['WindSpeed'].apply(str_to_float)\n",
    "\n",
    "train['WindDirection'].value_counts()\n",
    "\n",
    "def clean_WindDirection(txt):\n",
    "    if pd.isna(txt):\n",
    "        return np.nan\n",
    "    txt = txt.lower()\n",
    "    txt = ''.join([c for c in txt if c not in punctuation])\n",
    "    txt = txt.replace('from', '')\n",
    "    txt = txt.replace(' ', '')\n",
    "    txt = txt.replace('north', 'n')\n",
    "    txt = txt.replace('south', 's')\n",
    "    txt = txt.replace('west', 'w')\n",
    "    txt = txt.replace('east', 'e')\n",
    "    return txt\n",
    "\n",
    "train['WindDirection'] = train['WindDirection'].apply(clean_WindDirection)\n",
    "\n",
    "train['WindDirection'].value_counts()\n",
    "\n",
    "def transform_WindDirection(txt):\n",
    "    if pd.isna(txt):\n",
    "        return np.nan\n",
    "    \n",
    "    if txt=='n':\n",
    "        return 0\n",
    "    if txt=='nne' or txt=='nen':\n",
    "        return 1/8\n",
    "    if txt=='ne':\n",
    "        return 2/8\n",
    "    if txt=='ene' or txt=='nee':\n",
    "        return 3/8\n",
    "    if txt=='e':\n",
    "        return 4/8\n",
    "    if txt=='ese' or txt=='see':\n",
    "        return 5/8\n",
    "    if txt=='se':\n",
    "        return 6/8\n",
    "    if txt=='ses' or txt=='sse':\n",
    "        return 7/8\n",
    "    if txt=='s':\n",
    "        return 8/8\n",
    "    if txt=='ssw' or txt=='sws':\n",
    "        return 9/8\n",
    "    if txt=='sw':\n",
    "        return 10/8\n",
    "    if txt=='sww' or txt=='wsw':\n",
    "        return 11/8\n",
    "    if txt=='w':\n",
    "        return 12/8\n",
    "    if txt=='wnw' or txt=='nww':\n",
    "        return 13/8\n",
    "    if txt=='nw':\n",
    "        return 14/8\n",
    "    if txt=='nwn' or txt=='nnw':\n",
    "        return 15/8\n",
    "    return np.nan\n",
    "\n",
    "train['WindDirection'] = train['WindDirection'].apply(transform_WindDirection)\n",
    "\n",
    "train['PlayDirection'].value_counts()\n",
    "\n",
    "train['PlayDirection'] = train['PlayDirection'].apply(lambda x: x.strip() == 'right')\n",
    "\n",
    "train['Team'] = train['Team'].apply(lambda x: x.strip() == 'home')\n",
    "\n",
    "train['GameWeather'].unique()\n",
    "\n",
    "train['GameWeather'] = train['GameWeather'].str.lower()\n",
    "indoor = 'indoor'\n",
    "train['GameWeather'] = train['GameWeather'].apply(lambda x: indoor if not pd.isna(x) and indoor in x else x)\n",
    "train['GameWeather'] = train['GameWeather'].apply(lambda x: x.replace('coudy', 'cloudy') \\\n",
    "                                                      .replace('clouidy', 'cloudy') \\\n",
    "                                                      .replace('party', 'partly') if not pd.isna(x) else x)\n",
    "train['GameWeather'] = train['GameWeather'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n",
    "train['GameWeather'] = train['GameWeather'].apply(lambda x: x.replace('skies', '').replace('mostly', '').strip() if not pd.isna(x) else x)\n",
    "\n",
    "train['GameWeather'].unique()\n",
    "\n",
    "from collections import Counter\n",
    "weather_count = Counter()\n",
    "for weather in train['GameWeather']:\n",
    "    if pd.isna(weather):\n",
    "        continue\n",
    "    for word in weather.split():\n",
    "        weather_count[word] += 1\n",
    "        \n",
    "weather_count.most_common()[:15]\n",
    "\n",
    "def map_weather(txt):\n",
    "    ans = 1\n",
    "    if pd.isna(txt):\n",
    "        return 0\n",
    "    if 'partly' in txt:\n",
    "        ans *= 0.5\n",
    "    if 'climate controlled' in txt or 'indoor' in txt:\n",
    "        return ans*3\n",
    "    if 'sunny' in txt or 'sun' in txt:\n",
    "        return ans*2\n",
    "    if 'clear' in txt:\n",
    "        return ans\n",
    "    if 'cloudy' in txt:\n",
    "        return -ans\n",
    "    if 'rain' in txt or 'rainy' in txt:\n",
    "        return -2*ans\n",
    "    if 'snow' in txt:\n",
    "        return -3*ans\n",
    "    return 0\n",
    "\n",
    "train['GameWeather'] = train['GameWeather'].apply(map_weather)\n",
    "\n",
    "train['IsRusher'] = train['NflId'] == train['NflIdRusher']\n",
    "\n",
    "train.drop(['NflId', 'NflIdRusher'], axis=1, inplace=True)\n",
    "\n",
    "train['X'] = train.apply(lambda row: row['X'] if row['PlayDirection'] else 120-row['X'], axis=1)\n",
    "\n",
    "def new_orientation(angle, play_direction):\n",
    "    if play_direction == 0:\n",
    "        new_angle = 360.0 - angle\n",
    "        if new_angle == 360.0:\n",
    "            new_angle = 0.0\n",
    "        return new_angle\n",
    "    else:\n",
    "        return angle\n",
    "    \n",
    "train['Orientation'] = train.apply(lambda row: new_orientation(row['Orientation'], row['PlayDirection']), axis=1)\n",
    "train['Dir'] = train.apply(lambda row: new_orientation(row['Dir'], row['PlayDirection']), axis=1)\n",
    "\n",
    "train['YardsLeft'] = train.apply(lambda row: 100-row['YardLine'] if row['HomeField'] else row['YardLine'], axis=1)\n",
    "train['YardsLeft'] = train.apply(lambda row: row['YardsLeft'] if row['PlayDirection'] else 100-row['YardsLeft'], axis=1)\n",
    "\n",
    "((train['YardsLeft']<train['Yards']) | (train['YardsLeft']-100>train['Yards'])).mean()\n",
    "\n",
    "train.drop(train.index[(train['YardsLeft']<train['Yards']) | (train['YardsLeft']-100>train['Yards'])], inplace=True)\n",
    "\n",
    "train = train.sort_values(by=['PlayId', 'Team', 'IsRusher', 'JerseyNumber']).reset_index()\n",
    "\n",
    "train.drop(['GameId', 'PlayId', 'index', 'IsRusher', 'Team'], axis=1, inplace=True)\n",
    "\n",
    "cat_features = []\n",
    "for col in train.columns:\n",
    "    if train[col].dtype =='object':\n",
    "        cat_features.append(col)\n",
    "        \n",
    "train = train.drop(cat_features, axis=1)\n",
    "\n",
    "train.fillna(-999, inplace=True)\n",
    "\n",
    "players_col = []\n",
    "for col in train.columns:\n",
    "    if train[col][:22].std()!=0:\n",
    "        players_col.append(col)\n",
    "\n",
    "X_train = np.array(train[players_col]).reshape(-1, len(players_col)*22)\n",
    "\n",
    "play_col = train.drop(players_col+['Yards'], axis=1).columns\n",
    "X_play_col = np.zeros(shape=(X_train.shape[0], len(play_col)))\n",
    "for i, col in enumerate(play_col):\n",
    "    X_play_col[:, i] = train[col][::22]\n",
    "\n",
    "X_train = np.concatenate([X_train, X_play_col], axis=1)\n",
    "y_train = np.zeros(shape=(X_train.shape[0], 199))\n",
    "for i, yard in enumerate(train['Yards'][::22]):\n",
    "    y_train[i, yard+99:] = np.ones(shape=(1, 100-yard))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "class RAdam(keras.optimizers.Optimizer):\n",
    "    \"\"\"RAdam optimizer.\n",
    "    # Arguments\n",
    "        learning_rate: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        weight_decay: float >= 0. Weight decay for each param.\n",
    "        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n",
    "            algorithm from the paper \"On the Convergence of Adam and\n",
    "            Beyond\".\n",
    "        total_steps: int >= 0. Total number of training steps. Enable warmup by setting a positive value.\n",
    "        warmup_proportion: 0 < warmup_proportion < 1. The proportion of increasing steps.\n",
    "        min_lr: float >= 0. Minimum learning rate after warmup.\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980v8)\n",
    "        - [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n",
    "        - [On The Variance Of The Adaptive Learning Rate And Beyond](https://arxiv.org/pdf/1908.03265v1.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=None, decay=0., weight_decay=0., amsgrad=False,\n",
    "                 total_steps=0, warmup_proportion=0.1, min_lr=0., **kwargs):\n",
    "        learning_rate = kwargs.pop('lr', learning_rate)\n",
    "        super(RAdam, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.weight_decay = K.variable(weight_decay, name='weight_decay')\n",
    "            self.total_steps = K.variable(total_steps, name='total_steps')\n",
    "            self.warmup_proportion = K.variable(warmup_proportion, name='warmup_proportion')\n",
    "            self.min_lr = K.variable(min_lr, name='min_lr')\n",
    "        if epsilon is None:\n",
    "            epsilon = K.epsilon()\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "        self.initial_weight_decay = weight_decay\n",
    "        self.initial_total_steps = total_steps\n",
    "        self.amsgrad = amsgrad\n",
    "\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        lr = self.lr\n",
    "\n",
    "        if self.initial_decay > 0:\n",
    "            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "\n",
    "        if self.initial_total_steps > 0:\n",
    "            warmup_steps = self.total_steps * self.warmup_proportion\n",
    "            decay_steps = K.maximum(self.total_steps - warmup_steps, 1)\n",
    "            decay_rate = (self.min_lr - lr) / decay_steps\n",
    "            lr = K.switch(\n",
    "                t <= warmup_steps,\n",
    "                lr * (t / warmup_steps),\n",
    "                lr + decay_rate * K.minimum(t - warmup_steps, decay_steps),\n",
    "            )\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='m_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='v_' + str(i)) for (i, p) in enumerate(params)]\n",
    "\n",
    "        if self.amsgrad:\n",
    "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='vhat_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        else:\n",
    "            vhats = [K.zeros(1, name='vhat_' + str(i)) for i in range(len(params))]\n",
    "\n",
    "        self.weights = [self.iterations] + ms + vs + vhats\n",
    "\n",
    "        beta_1_t = K.pow(self.beta_1, t)\n",
    "        beta_2_t = K.pow(self.beta_2, t)\n",
    "\n",
    "        sma_inf = 2.0 / (1.0 - self.beta_2) - 1.0\n",
    "        sma_t = sma_inf - 2.0 * t * beta_2_t / (1.0 - beta_2_t)\n",
    "\n",
    "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "\n",
    "            m_corr_t = m_t / (1.0 - beta_1_t)\n",
    "            if self.amsgrad:\n",
    "                vhat_t = K.maximum(vhat, v_t)\n",
    "                v_corr_t = K.sqrt(vhat_t / (1.0 - beta_2_t))\n",
    "                self.updates.append(K.update(vhat, vhat_t))\n",
    "            else:\n",
    "                v_corr_t = K.sqrt(v_t / (1.0 - beta_2_t))\n",
    "\n",
    "            r_t = K.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n",
    "                         (sma_t - 2.0) / (sma_inf - 2.0) *\n",
    "                         sma_inf / sma_t)\n",
    "\n",
    "            p_t = K.switch(sma_t >= 5, r_t * m_corr_t / (v_corr_t + self.epsilon), m_corr_t)\n",
    "\n",
    "            if self.initial_weight_decay > 0:\n",
    "                p_t += self.weight_decay * p\n",
    "\n",
    "            p_t = p - lr * p_t\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self.learning_rate\n",
    "\n",
    "    @lr.setter\n",
    "    def lr(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'learning_rate': float(K.get_value(self.learning_rate)),\n",
    "            'beta_1': float(K.get_value(self.beta_1)),\n",
    "            'beta_2': float(K.get_value(self.beta_2)),\n",
    "            'decay': float(K.get_value(self.decay)),\n",
    "            'weight_decay': float(K.get_value(self.weight_decay)),\n",
    "            'epsilon': self.epsilon,\n",
    "            'amsgrad': self.amsgrad,\n",
    "            'total_steps': float(K.get_value(self.total_steps)),\n",
    "            'warmup_proportion': float(K.get_value(self.warmup_proportion)),\n",
    "            'min_lr': float(K.get_value(self.min_lr)),\n",
    "        }\n",
    "        base_config = super(RAdam, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "def crps(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - K.cumsum(y_pred, axis=1)), axis=1)\n",
    "\n",
    "def get_model():\n",
    "    x = keras.layers.Input(shape=[X_train.shape[1]])\n",
    "    fc1 = keras.layers.Dense(units=450, input_shape=[X_train.shape[1]])(x)\n",
    "    act1 = keras.layers.PReLU()(fc1)\n",
    "    bn1 = keras.layers.BatchNormalization()(act1)\n",
    "    dp1 = keras.layers.Dropout(0.55)(bn1)\n",
    "    concat1 = keras.layers.Concatenate()([x, dp1])\n",
    "    fc2 = keras.layers.Dense(units=600)(concat1)\n",
    "    act2 = keras.layers.PReLU()(fc2)\n",
    "    bn2 = keras.layers.BatchNormalization()(act2)\n",
    "    dp2 = keras.layers.Dropout(0.55)(bn2)\n",
    "    concat2 = keras.layers.Concatenate()([concat1, dp2])\n",
    "    fc3 = keras.layers.Dense(units=400)(concat2)\n",
    "    act3 = keras.layers.PReLU()(fc3)\n",
    "    bn3 = keras.layers.BatchNormalization()(act3)\n",
    "    dp3 = keras.layers.Dropout(0.55)(bn3)\n",
    "    concat3 = keras.layers.Concatenate([concat2, dp3])\n",
    "    output = keras.layers.Dense(units=199, activation='softmax')(concat2)\n",
    "    model = keras.models.Model(inputs=[x], outputs=[output])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val):\n",
    "    model = get_model()\n",
    "    model.compile(optimizer=RAdam(warmup_proportion=0.1, min_lr=1e-7), loss=crps)\n",
    "    er = EarlyStopping(patience=20, min_delta=1e-4, restore_best_weights=True, monitor='val_loss')\n",
    "    model.fit(X_train, y_train, epochs=200, callbacks=[er], validation_data=[X_val, y_val], batch_size=batch_size)\n",
    "    return model\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=4, n_repeats=6)\n",
    "\n",
    "models = []\n",
    "\n",
    "for tr_idx, vl_idx in rkf.split(X_train, y_train):\n",
    "    \n",
    "    x_tr, y_tr = X_train[tr_idx], y_train[tr_idx]\n",
    "    x_vl, y_vl = X_train[vl_idx], y_train[vl_idx]\n",
    "    \n",
    "    model = train_model(x_tr, y_tr, x_vl, y_vl)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "452992db-53ef-48c5-b6ae-69701828795d",
    "_uuid": "0cc26ceb-2d89-4c00-acbc-ba6017ec9ce8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "37e9bc68-92f8-42fd-93c9-687fc51b9bec",
    "_uuid": "2d649a3a-42c2-4259-b49b-46cbe665b07d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ec5dd9a9-576e-4107-a062-8c70b4c2ca84",
    "_uuid": "50a07e6f-6db8-497a-b978-b1756fc053cc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5c53e220-5183-4ab3-b909-1af55b631216",
    "_uuid": "033ef5b3-e90b-457d-89dd-7559e2497d44"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c0c2f4ca-a764-4e32-ae79-5ce11e4180ad",
    "_uuid": "07325be2-0e97-474d-9fb6-144efe06f447"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
